# Deep learning for predicting rate-induced tipping

## 用于预测速率诱导小费的深度学习

Link: https://www.nature.com/articles/s42256-024-00937-0

<p>Nature Machine Intelligence, Published online: 28 November 2024; <a href="https://www.nature.com/articles/s42256-024-00937-0">doi:10.1038/s42256-024-00937-0</a></p>Rate- and noise-induced transitions pose key tipping risks for ecosystems and climate subsystems, yet no predictive theory existed before. This study introduces deep learning as an effective prediction tool for these tipping events.


---
# Empowering the Sustainable Development of High‐End Alloys via Interpretive Machine Learning

## 通过解释性机器学习增强高端合金的可持续发展能力

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202404478?af=R

Advanced Materials, Volume 36, Issue 48, November 27, 2024.


---
# Analytic Continuation by Feature Learning

## 通过特征学习进行分析延续

Link: https://arxiv.org/abs/2411.17728

arXiv:2411.17728v1 Announce Type: new 
Abstract: Analytic continuation aims to reconstruct real-time spectral functions from imaginary-time Green's functions; however, this process is notoriously ill-posed and challenging to solve. We propose a novel neural network architecture, named the Feature Learning Network (FL-net), to enhance the prediction accuracy of spectral functions, achieving an improvement of at least $20\%$ over traditional methods, such as the Maximum Entropy Method (MEM), and previous neural network approaches. Furthermore, we develop an analytical method to evaluate the robustness of the proposed network. Using this method, we demonstrate that increasing the hidden dimensionality of FL-net, while leading to lower loss, results in decreased robustness. Overall, our model provides valuable insights into effectively addressing the complex challenges associated with analytic continuation.


---
# Learning Mean First Passage Time: Chemical Short-Range Order and Kinetics of Diffusive Relaxation

## 学习平均首次通过时间: 化学短程有序和扩散弛豫动力学

Link: https://arxiv.org/abs/2411.17839

arXiv:2411.17839v1 Announce Type: new 
Abstract: Long-timescale processes pose significant challenges in atomistic simulations, particularly for phenomena such as diffusion and phase transitions. We present a deep reinforcement learning (DRL)-based computational framework, combined with a temporal difference (TD) learning method, to simulate long-timescale atomic processes of diffusive relaxation. We apply it to study the emergence of chemical short-range order (SRO) in medium- and high-entropy alloys (MEAs/HEAs), which plays a crucial role in unlocking unique material properties, and find that the proposed method effectively maps the relationship between time, temperature, and SRO change. By accelerating both the sampling of lower-energy states and the simulation of transition kinetics, we identify the thermodynamic limit and the role of kinetic trapping in the SRO. Furthermore, learning the mean first passage time to a given, target SRO relaxation allows capturing realistic timescales in diffusive atomistic rearrangements. This method offers valuable guidelines for optimizing material processing and extends atomistic simulations to previously inaccessible timescales, facilitating the study of slow, thermally activated processes essential for understanding and engineering material properties.


---
# PyMatterSim: a Python Data Analysis Library for Computer Simulations of Materials Science, Physics, Chemistry, and Beyond

## PyMatterSim: 一个Python数据分析库，用于材料科学，物理，化学等的计算机模拟

Link: https://arxiv.org/abs/2411.17970

arXiv:2411.17970v1 Announce Type: new 
Abstract: Computer simulation has become one of the most important tools in scientific research in many disciplines. Benefiting from the dynamical trajectories regulated by versatile interatomic interactions, various material properties can be quantitatively characterized at the atomic scale. This greatly deepens our understanding of Nature and provides incredible insights supplementing experimental observations. Hitherto, a plethora of literature discusses the computational discoveries in studying glasses in which positional disorder is inherent in their configurations. Motivated by active research and knowledge sharing, we developed a data analysis library in Python for computational materials science research. We hope to help promote scientific progress and narrow some technical gaps for the wide communities. The toolkit mainly focuses on physical analyses of glassy properties from the open-source simulator LAMMPS. Nevertheless, the code design renders high flexibility, with functionalities extendable to other computational tools. The library provides data-driven insights for different subjects and can be incorporated into advanced machine-learning workflows. The scope of the data analysis methodologies applies not only to materials science but also to physics, chemistry, and beyond.


---
# Disentangling morphology and conductance in amorphous graphene

## 非晶石墨烯的解缠结形貌和电导

Link: https://arxiv.org/abs/2411.18041

arXiv:2411.18041v1 Announce Type: new 
Abstract: Amorphous graphene or amorphous monolayer carbon (AMC) is a family of carbon films that exhibit a surprising sensitivity of electronic conductance to morphology. We combine deep learning-enhanced simulation techniques with percolation theory to analyze three morphologically distinct mesoscale AMCs. Our approach avoids the pitfalls of applying periodic boundary conditions to these fundamentally aperiodic systems or equating crystalline inclusions with conducting sites. We reproduce the previously reported dependence of charge conductance on morphology and explore the limitations of partial morphology descriptors in witnessing conductance properties. Finally, we perform crystallinity analysis of conductance networks along the electronic energy spectrum and show that they metamorphose from being localized on crystallites at band edges to localized on defects around the Fermi energy opening the possibility of control through gate voltage.


---
# Advancing Natural Orbital Functional Calculations Through Deep Learning-Inspired Techniques for Large-Scale Strongly Correlated Electron Systems

## 通过深度学习技术推进大规模强相关电子系统的自然轨道功能计算

Link: https://arxiv.org/abs/2411.18493

arXiv:2411.18493v1 Announce Type: new 
Abstract: Natural orbital functional (NOF) theory offers a promising approach for studying strongly correlated systems at an affordable computational cost, with an accuracy comparable to highly demanding wavefunction-based methods. However, its widespread adoption in cases involving a large number of correlated electrons has been limited by the extensive iterations required for convergence. In this work, we present a disruptive approach that embeds the techniques used for optimization in deep learning within the NOF calculation, representing a substantial advance in the scale of accessible systems. The revamped procedure is based on the adaptive momentum technique for orbital optimization, alternated with the optimization of the occupation numbers, significantly improving the computational feasibility of challenging calculations. We demonstrate this with three examples that involve a large number of electrons: (i) the symmetric dissociation of a large hydrogen cluster, (ii) an analysis of occupancies distribution in fullerenes, and (iii) a study of the singlet-triplet energy gap in linear acenes. Notably, the first example serves as an ideal model for a strongly correlated Mott insulator, featuring 1000 electrons and illustrating a metal-to-insulator transition, surpassing the largest calculations of strongly correlated electrons reported to date. We anticipate that this work will enable the practical application of NOFs to increasingly complex and intriguing systems, leveraging the method's inherent scalability and accuracy.


---
# Deciphering Acoustic Emission with Machine Learning

## 用机器学习破译声发射

Link: https://arxiv.org/abs/2411.17755

arXiv:2411.17755v1 Announce Type: cross 
Abstract: Acoustic emission signals have been shown to accompany avalanche-like events in materials, such as dislocation avalanches in crystalline solids, collapse of voids in porous matter or domain wall movement in ferroics. The data provided by acoustic emission measurements is tremendously rich, but it is rather challenging to precisely connect it to the characteristics of the triggering avalanche. In our work we propose a machine learning based method with which one can infer microscopic details of dislocation avalanches in micropillar compression tests from merely acoustic emission data. As it is demonstrated in the paper, this approach is suitable for the prediction of the force-time response as it can provide outstanding prediction for the temporal location of avalanches and can also predict the magnitude of individual deformation events. Various descriptors (including frequency dependent and independent ones) are utilised in our machine learning approach and their importance in the prediction is analysed. The transferability of the method to other specimen sizes is also demonstrated and the possible application in more generic settings is discussed.


---
# Probabilistic Forecasting of Radiation Exposure for Spaceflight

## 航天辐射暴露的概率预测

Link: https://arxiv.org/abs/2411.17703

arXiv:2411.17703v1 Announce Type: new 
Abstract: Extended human presence beyond low-Earth orbit (BLEO) during missions to the Moon and Mars will pose significant challenges in the near future. A primary health risk associated with these missions is radiation exposure, primarily from galatic cosmic rays (GCRs) and solar proton events (SPEs). While GCRs present a more consistent, albeit modulated threat, SPEs are harder to predict and can deliver acute doses over short periods. Currently NASA utilizes analytical tools for monitoring the space radiation environment in order to make decisions of immediate action to shelter astronauts. However this reactive approach could be significantly enhanced by predictive models that can forecast radiation exposure in advance, ideally hours ahead of major events, while providing estimates of prediction uncertainty to improve decision-making. In this work we present a machine learning approach for forecasting radiation exposure in BLEO using multimodal time-series data including direct solar imagery from Solar Dynamics Observatory, X-ray flux measurements from GOES missions, and radiation dose measurements from the BioSentinel satellite that was launched as part of Artemis~1 mission. To our knowledge, this is the first time full-disk solar imagery has been used to forecast radiation exposure. We demonstrate that our model can predict the onset of increased radiation due to an SPE event, as well as the radiation decay profile after an event has occurred.


---
# Quantification of Uncertainty and Its Propagation in Seismic Velocity Structure and Earthquake Source Inversion

## 地震速度结构和震源反演中不确定性的量化及其传播

Link: https://arxiv.org/abs/2411.17997

arXiv:2411.17997v1 Announce Type: new 
Abstract: In earthquake source inversions aimed at understanding diverse fault activities on earthquake faults using seismic observation data, uncertainties in velocity structure models are typically not considered. As a result, biases and underestimations of uncertainty can occur in source inversion. This article provides an overview of the author's efforts to address this issue by quantitatively evaluating the uncertainty in velocity structure models and appropriately accounting for its propagation into source inversion. First, the Bayesian multi-model source inversion method that can incorporate such uncertainties as probability distributions in the form of ensembles is explained. Next, a Bayesian traveltime tomography technique utilizing physics-informed neural networks (PINN) to quantify uncertainties in velocity structure models is introduced. Furthermore, the author's recent efforts to integrate these methods and apply them to hypocenter determination in the Nankai Trough region are briefly discussed. The article also outlines future prospects of source inversions considering uncertainties in velocity structure models and the anticipated role of the emerging scientific machine learning (SciML) methods such as PINN.


---
# MeltpoolINR: Predicting temperature field, melt pool geometry, and their rate of change in laser powder bed fusion

## MeltpoolINR: 预测温度场，熔池几何形状及其在激光粉末床熔融中的变化率

Link: https://arxiv.org/abs/2411.18048

arXiv:2411.18048v1 Announce Type: new 
Abstract: We present a data-driven, differentiable neural network model designed to learn the temperature field, its gradient, and the cooling rate, while implicitly representing the melt pool boundary as a level set in laser powder bed fusion. The physics-guided model combines fully connected feed-forward neural networks with Fourier feature encoding of the spatial coordinates and laser position. Notably, our differentiable model allows for the computation of temperature derivatives with respect to position, time, and process parameters using autodifferentiation. Moreover, the implicit neural representation of the melt pool boundary as a level set enables the inference of the solidification rate and the rate of change in melt pool geometry relative to process parameters. The model is trained to learn the top view of the temperature field and its spatiotemporal derivatives during a single-track laser powder bed fusion process, as a function of three process parameters, using data from high-fidelity thermo-fluid simulations. The model accuracy is evaluated and compared to a state-of-the-art convolutional neural network model, demonstrating strong generalization ability and close agreement with high-fidelity data.


---
# The Bigger the Better? Accurate Molecular Potential Energy Surfaces from Minimalist Neural Networks

## 越大越好？极简神经网络的精确分子势能面

Link: https://arxiv.org/abs/2411.18121

arXiv:2411.18121v1 Announce Type: new 
Abstract: Atomistic simulations are a powerful tool for studying the dynamics of molecules, proteins, and materials on wide time and length scales. Their reliability and predictiveness, however, depend directly on the accuracy of the underlying potential energy surface (PES). Guided by the principle of parsimony this work introduces KerNN, a combined kernel/neural network-based approach to represent molecular PESs. Compared to state-of-the-art neural network PESs the number of learnable parameters of KerNN is significantly reduced. This speeds up training and evaluation times by several orders of magnitude while retaining high prediction accuracy. Importantly, using kernels as the features also improves the extrapolation capabilities of KerNN far beyond the coverage provided by the training data which solves a general problem of NN-based PESs. KerNN applied to spectroscopy and reaction dynamics shows excellent performance on test set statistics and observables including vibrational bands computed from classical and quantum simulations.


---
# Physics Informed Neural Networks (PINNs) as intelligent computing technique for solving partial differential equations: Limitation and Future prospects

## 物理通知神经网络 (PINNs) 作为解决偏微分方程的智能计算技术: 局限性和未来前景

Link: https://arxiv.org/abs/2411.18240

arXiv:2411.18240v1 Announce Type: new 
Abstract: In recent years, Physics-Informed Neural Networks (PINNs) have become a representative method for solving partial differential equations (PDEs) with neural networks. PINNs provide a novel approach to solving PDEs through optimization algorithms, offering a unified framework for solving both forward and inverse problems. However, some limitations in terms of solution accuracy and generality have also been revealed. This paper systematically summarizes the limitations of PINNs and identifies three root causes for their failure in solving PDEs: (1) Poor multiscale approximation ability and ill-conditioning caused by PDE losses; (2) Insufficient exploration of convergence and error analysis, resulting in weak mathematical rigor; (3) Inadequate integration of physical information, causing mismatch between residuals and iteration errors. By focusing on addressing these limitations in PINNs, we outline the future directions and prospects for the intelligent computing of PDEs: (1) Analysis of ill-conditioning in PINNs and mitigation strategies; (2) Improvements to PINNs by enforcing temporal causality; (3) Empowering PINNs with classical numerical methods.


---
# TorchOptics: An open-source Python library for differentiable Fourier optics simulations

## TorchOptics: 用于微分傅立叶光学模拟的开源Python库

Link: https://arxiv.org/abs/2411.18591

arXiv:2411.18591v1 Announce Type: new 
Abstract: TorchOptics is an open-source Python library for differentiable Fourier optics simulations, developed using PyTorch to enable GPU-accelerated tensor computations and automatic differentiation. It provides a comprehensive framework for modeling, analyzing, and designing optical systems using Fourier optics, with applications in imaging, diffraction, holography, and signal processing. The library leverages PyTorch's automatic differentiation engine for gradient-based optimization, enabling the inverse design of complex optical systems. TorchOptics supports end-to-end optimization of hybrid models that integrate optical systems with machine learning architectures for digital post-processing. The library includes a wide range of optical elements and spatial profiles, and supports simulations with polarized light and fields with arbitrary spatial coherence.


---
# Analytic Continuation by Feature Learning

## 通过特征学习进行分析延续

Link: https://arxiv.org/abs/2411.17728

arXiv:2411.17728v1 Announce Type: cross 
Abstract: Analytic continuation aims to reconstruct real-time spectral functions from imaginary-time Green's functions; however, this process is notoriously ill-posed and challenging to solve. We propose a novel neural network architecture, named the Feature Learning Network (FL-net), to enhance the prediction accuracy of spectral functions, achieving an improvement of at least $20\%$ over traditional methods, such as the Maximum Entropy Method (MEM), and previous neural network approaches. Furthermore, we develop an analytical method to evaluate the robustness of the proposed network. Using this method, we demonstrate that increasing the hidden dimensionality of FL-net, while leading to lower loss, results in decreased robustness. Overall, our model provides valuable insights into effectively addressing the complex challenges associated with analytic continuation.


---
# Learning Mean First Passage Time: Chemical Short-Range Order and Kinetics of Diffusive Relaxation

## 学习平均首次通过时间: 化学短程有序和扩散弛豫动力学

Link: https://arxiv.org/abs/2411.17839

arXiv:2411.17839v1 Announce Type: cross 
Abstract: Long-timescale processes pose significant challenges in atomistic simulations, particularly for phenomena such as diffusion and phase transitions. We present a deep reinforcement learning (DRL)-based computational framework, combined with a temporal difference (TD) learning method, to simulate long-timescale atomic processes of diffusive relaxation. We apply it to study the emergence of chemical short-range order (SRO) in medium- and high-entropy alloys (MEAs/HEAs), which plays a crucial role in unlocking unique material properties, and find that the proposed method effectively maps the relationship between time, temperature, and SRO change. By accelerating both the sampling of lower-energy states and the simulation of transition kinetics, we identify the thermodynamic limit and the role of kinetic trapping in the SRO. Furthermore, learning the mean first passage time to a given, target SRO relaxation allows capturing realistic timescales in diffusive atomistic rearrangements. This method offers valuable guidelines for optimizing material processing and extends atomistic simulations to previously inaccessible timescales, facilitating the study of slow, thermally activated processes essential for understanding and engineering material properties.


---
# Integrating Machine Learning and Quantum Circuits for Proton Affinity Predictions

## 集成机器学习和量子电路进行质子亲和力预测

Link: https://arxiv.org/abs/2411.17856

arXiv:2411.17856v1 Announce Type: cross 
Abstract: A key step in interpreting gas-phase ion mobility coupled with mass spectrometry (IM-MS) data for unknown structure prediction involves identifying the most favorable protonated structure. In the gas phase, the site of protonation is determined using proton affinity (PA) measurements. Currently, mass spectrometry and ab initio computation methods are widely used to evaluate PA; however, both methods are resource-intensive and time-consuming. Therefore, there is a critical need for efficient methods to estimate PA, enabling the rapid identification of the most favorable protonation site in complex organic molecules with multiple proton binding sites. In this work, we developed a fast and accurate method for PA prediction by using multiple descriptors in combination with machine learning (ML) models. Using a comprehensive set of 186 descriptors, our model demonstrated strong predictive performance, with an R2 of 0.96 and a MAE of 2.47kcal/mol, comparable to experimental uncertainty. Furthermore, we designed quantum circuits as feature encoders for a classical neural network. To evaluate the effectiveness of this hybrid quantum-classical model, we compared its performance with traditional ML models using a reduced feature set derived from the full set. The result showed that this hybrid model achieved consistent performance comparable to traditional ML models with the same reduced feature set on both a noiseless simulator and real quantum hardware, highlighting the potential of quantum machine learning for accurate and efficient PA predictions.


---
# PyMatterSim: a Python Data Analysis Library for Computer Simulations of Materials Science, Physics, Chemistry, and Beyond

## PyMatterSim: 一个Python数据分析库，用于材料科学，物理，化学等的计算机模拟

Link: https://arxiv.org/abs/2411.17970

arXiv:2411.17970v1 Announce Type: cross 
Abstract: Computer simulation has become one of the most important tools in scientific research in many disciplines. Benefiting from the dynamical trajectories regulated by versatile interatomic interactions, various material properties can be quantitatively characterized at the atomic scale. This greatly deepens our understanding of Nature and provides incredible insights supplementing experimental observations. Hitherto, a plethora of literature discusses the computational discoveries in studying glasses in which positional disorder is inherent in their configurations. Motivated by active research and knowledge sharing, we developed a data analysis library in Python for computational materials science research. We hope to help promote scientific progress and narrow some technical gaps for the wide communities. The toolkit mainly focuses on physical analyses of glassy properties from the open-source simulator LAMMPS. Nevertheless, the code design renders high flexibility, with functionalities extendable to other computational tools. The library provides data-driven insights for different subjects and can be incorporated into advanced machine-learning workflows. The scope of the data analysis methodologies applies not only to materials science but also to physics, chemistry, and beyond.


---
# Disentangling morphology and conductance in amorphous graphene

## 非晶石墨烯的解缠结形貌和电导

Link: https://arxiv.org/abs/2411.18041

arXiv:2411.18041v1 Announce Type: cross 
Abstract: Amorphous graphene or amorphous monolayer carbon (AMC) is a family of carbon films that exhibit a surprising sensitivity of electronic conductance to morphology. We combine deep learning-enhanced simulation techniques with percolation theory to analyze three morphologically distinct mesoscale AMCs. Our approach avoids the pitfalls of applying periodic boundary conditions to these fundamentally aperiodic systems or equating crystalline inclusions with conducting sites. We reproduce the previously reported dependence of charge conductance on morphology and explore the limitations of partial morphology descriptors in witnessing conductance properties. Finally, we perform crystallinity analysis of conductance networks along the electronic energy spectrum and show that they metamorphose from being localized on crystallites at band edges to localized on defects around the Fermi energy opening the possibility of control through gate voltage.


---
# Deep End-to-end Adaptive k-Space Sampling, Reconstruction, and Registration for Dynamic MRI

## 用于动态MRI的深度端到端自适应k空间采样，重建和配准

Link: https://arxiv.org/abs/2411.18249

arXiv:2411.18249v1 Announce Type: cross 
Abstract: Dynamic MRI enables a range of clinical applications, including cardiac function assessment, organ motion tracking, and radiotherapy guidance. However, fully sampling the dynamic k-space data is often infeasible due to time constraints and physiological motion such as respiratory and cardiac motion. This necessitates undersampling, which degrades the quality of reconstructed images. Poor image quality not only hinders visualization but also impairs the estimation of deformation fields, crucial for registering dynamic (moving) images to a static reference image. This registration enables tasks such as motion correction, treatment planning, and quantitative analysis in applications like cardiac imaging and MR-guided radiotherapy. To overcome the challenges posed by undersampling and motion, we introduce an end-to-end deep learning (DL) framework that integrates adaptive dynamic k-space sampling, reconstruction, and registration. Our approach begins with a DL-based adaptive sampling strategy, optimizing dynamic k-space acquisition to capture the most relevant data for each specific case. This is followed by a DL-based reconstruction module that produces images optimized for accurate deformation field estimation from the undersampled moving data. Finally, a registration module estimates the deformation fields aligning the reconstructed dynamic images with a static reference. The proposed framework is independent of specific reconstruction and registration modules allowing for plug-and-play integration of these components. The entire framework is jointly trained using a combination of supervised and unsupervised loss functions, enabling end-to-end optimization for improved performance across all components. Through controlled experiments and ablation studies, we validate each component, demonstrating that each choice contributes to robust motion estimation from undersampled dynamic data.


---
# Transfer Learning for Deep Learning-based Prediction of Lattice Thermal Conductivity

## 基于深度学习的晶格热导率预测的迁移学习

Link: https://arxiv.org/abs/2411.18259

arXiv:2411.18259v1 Announce Type: cross 
Abstract: Machine learning promises to accelerate the material discovery by enabling high-throughput prediction of desirable macro-properties from atomic-level descriptors or structures. However, the limited data available about precise values of these properties have been a barrier, leading to predictive models with limited precision or the ability to generalize. This is particularly true of lattice thermal conductivity (LTC): existing datasets of precise (ab initio, DFT-based) computed values are limited to a few dozen materials with little variability. Based on such datasets, we study the impact of transfer learning on both the precision and generalizability of a deep learning model (ParAIsite). We start from an existing model (MEGNet~\cite{Chen2019}) and show that improvements are obtained by fine-tuning a pre-trained version on different tasks. Interestingly, we also show that a much greater improvement is obtained when first fine-tuning it on a large datasets of low-quality approximations of LTC (based on the AGL model) and then applying a second phase of fine-tuning with our high-quality, smaller-scale datasets. The promising results obtained pave the way not only towards a greater ability to explore large databases in search of low thermal conductivity materials but also to methods enabling increasingly precise predictions in areas where quality data are rare.


---
# Deep learning-based spatio-temporal fusion for high-fidelity ultra-high-speed x-ray radiography

## 基于深度学习的高保真超高速x射线成像时空融合

Link: https://arxiv.org/abs/2411.18441

arXiv:2411.18441v1 Announce Type: cross 
Abstract: Full-field ultra-high-speed (UHS) x-ray imaging experiments have been well established to characterize various processes and phenomena. However, the potential of UHS experiments through the joint acquisition of x-ray videos with distinct configurations has not been fully exploited. In this paper, we investigate the use of a deep learning-based spatio-temporal fusion (STF) framework to fuse two complementary sequences of x-ray images and reconstruct the target image sequence with high spatial resolution, high frame rate, and high fidelity. We applied a transfer learning strategy to train the model and compared the peak signal-to-noise ratio (PSNR), average absolute difference (AAD), and structural similarity (SSIM) of the proposed framework on two independent x-ray datasets with those obtained from a baseline deep learning model, a Bayesian fusion framework, and the bicubic interpolation method. The proposed framework outperformed the other methods with various configurations of the input frame separations and image noise levels. With 3 subsequent images from the low resolution (LR) sequence of a 4-time lower spatial resolution and another 2 images from the high resolution (HR) sequence of a 20-time lower frame rate, the proposed approach achieved an average PSNR of 37.57 dB and 35.15 dB, respectively. When coupled with the appropriate combination of high-speed cameras, the proposed approach will enhance the performance and therefore scientific value of the UHS x-ray imaging experiments.


---
# Advancing Natural Orbital Functional Calculations Through Deep Learning-Inspired Techniques for Large-Scale Strongly Correlated Electron Systems

## 通过深度学习技术推进大规模强相关电子系统的自然轨道功能计算

Link: https://arxiv.org/abs/2411.18493

arXiv:2411.18493v1 Announce Type: cross 
Abstract: Natural orbital functional (NOF) theory offers a promising approach for studying strongly correlated systems at an affordable computational cost, with an accuracy comparable to highly demanding wavefunction-based methods. However, its widespread adoption in cases involving a large number of correlated electrons has been limited by the extensive iterations required for convergence. In this work, we present a disruptive approach that embeds the techniques used for optimization in deep learning within the NOF calculation, representing a substantial advance in the scale of accessible systems. The revamped procedure is based on the adaptive momentum technique for orbital optimization, alternated with the optimization of the occupation numbers, significantly improving the computational feasibility of challenging calculations. We demonstrate this with three examples that involve a large number of electrons: (i) the symmetric dissociation of a large hydrogen cluster, (ii) an analysis of occupancies distribution in fullerenes, and (iii) a study of the singlet-triplet energy gap in linear acenes. Notably, the first example serves as an ideal model for a strongly correlated Mott insulator, featuring 1000 electrons and illustrating a metal-to-insulator transition, surpassing the largest calculations of strongly correlated electrons reported to date. We anticipate that this work will enable the practical application of NOFs to increasingly complex and intriguing systems, leveraging the method's inherent scalability and accuracy.


---
# Surveying the space of descriptions of a composite system with machine learning

## 用机器学习测量复合系统的描述空间

Link: https://arxiv.org/abs/2411.18579

arXiv:2411.18579v1 Announce Type: cross 
Abstract: Multivariate information theory provides a general and principled framework for understanding how the components of a complex system are connected. Existing analyses are coarse in nature -- built up from characterizations of discrete subsystems -- and can be computationally prohibitive. In this work, we propose to study the continuous space of possible descriptions of a composite system as a window into its organizational structure. A description consists of specific information conveyed about each of the components, and the space of possible descriptions is equivalent to the space of lossy compression schemes of the components. We introduce a machine learning framework to optimize descriptions that extremize key information theoretic quantities used to characterize organization, such as total correlation and O-information. Through case studies on spin systems, Sudoku boards, and letter sequences from natural language, we identify extremal descriptions that reveal how system-wide variation emerges from individual components. By integrating machine learning into a fine-grained information theoretic analysis of composite random variables, our framework opens a new avenues for probing the structure of real-world complex systems.


---
# Segmentation-Free Outcome Prediction from Head and Neck Cancer PET/CT Images: Deep Learning-Based Feature Extraction from Multi-Angle Maximum Intensity Projections (MA-MIPs)

## 基于头颈部肿瘤PET/CT图像的无分割结果预测: 基于深度学习的多角度最大强度投影特征提取 (ma-mips)

Link: https://arxiv.org/abs/2405.01756

arXiv:2405.01756v2 Announce Type: replace 
Abstract: We introduce an innovative, simple, effective segmentation-free approach for outcome prediction in head \& neck cancer (HNC) patients. By harnessing deep learning-based feature extraction techniques and multi-angle maximum intensity projections (MA-MIPs) applied to Fluorodeoxyglucose Positron Emission Tomography (FDG-PET) volumes, our proposed method eliminates the need for manual segmentations of regions-of-interest (ROIs) such as primary tumors and involved lymph nodes. Instead, a state-of-the-art object detection model is trained to perform automatic cropping of the head and neck region on the PET volumes. A pre-trained deep convolutional neural network backbone is then utilized to extract deep features from MA-MIPs obtained from 72 multi-angel axial rotations of the cropped PET volumes. These deep features extracted from multiple projection views of the PET volumes are then aggregated and fused, and employed to perform recurrence-free survival analysis on a cohort of 489 HNC patients. The proposed approach outperforms the best performing method on the target dataset for the task of recurrence-free survival analysis. By circumventing the manual delineation of the malignancies on the FDG PET-CT images, our approach eliminates the dependency on subjective interpretations and highly enhances the reproducibility of the proposed survival analysis method.


---
# Unveiling the optimization process of Physics Informed Neural Networks: How accurate and competitive can PINNs be?

## 揭开物理通知神经网络的优化过程: pinn的准确性和竞争力如何？

Link: https://arxiv.org/abs/2405.04230

arXiv:2405.04230v2 Announce Type: replace 
Abstract: This study investigates the potential accuracy boundaries of physics-informed neural networks, contrasting their approach with previous similar works and traditional numerical methods. We find that selecting improved optimization algorithms significantly enhances the accuracy of the results. Simple modifications to the loss function may also improve precision, offering an additional avenue for enhancement. Despite optimization algorithms having a greater impact on convergence than adjustments to the loss function, practical considerations often favor tweaking the latter due to ease of implementation. On a global scale, the integration of an enhanced optimizer and a marginally adjusted loss function enables a reduction in the loss function by several orders of magnitude across diverse physical problems. Consequently, our results obtained using compact networks (typically comprising 2 or 3 layers of 20-30 neurons) achieve accuracies comparable to finite difference schemes employing thousands of grid points. This study encourages the continued advancement of PINNs and associated optimization techniques for broader applications across various fields.


---
# Machine-Learning based photon counting for PMT waveforms and its application to the improvement of the energy resolution in large liquid scintillator detectors

## 基于机器学习的PMT波形光子计数及其在提高大型液体闪烁体探测器能量分辨率中的应用

Link: https://arxiv.org/abs/2405.18720

arXiv:2405.18720v2 Announce Type: replace 
Abstract: Photomultiplier tubes (PMTs) are widely used in particle experiments for photon detection. PMT waveform analysis is crucial for high-precision measurements of the position and energy of incident particles in liquid scintillator (LS) detectors. A key factor contributing to the energy resolution in large liquid scintillator detectors with PMTs is the charge smearing of PMTs. This paper presents a machine-learning-based photon counting method for PMT waveforms and its application to the energy reconstruction, using the JUNO experiment as an example.The results indicate that leveraging the photon counting information from the machine learning model can partially mitigate the impact of PMT charge smearing and lead to a relative 2.0% to 2.8% improvement on the energy resolution in the energy range of [1, 9] MeV.


---
# Prediction Beyond the Medium Range with an Atmosphere-Ocean Model that Combines Physics-based Modeling and Machine Learning

## 通过结合基于物理的建模和机器学习的大气-海洋模型进行中程以外的预测

Link: https://arxiv.org/abs/2405.19518

arXiv:2405.19518v2 Announce Type: replace 
Abstract: This paper explores the potential of a hybrid modeling approach that combines machine learning (ML) with conventional physics-based modeling for weather prediction beyond the medium range. It extends the work of Arcomano et al. (2022), which tested the approach for short- and medium-range weather prediction, and the work of Arcomano et al. (2023), which investigated its potential for climate modeling. The hybrid model used for the forecast experiments of the paper is based on the low-resolution, simplified parameterization atmospheric general circulation model SPEEDY. In addition to the hybridized prognostic variables of SPEEDY, the model has three purely ML-based prognostic variables: the 6h cumulative precipitation, the sea surface temperature, and the heat content of the top 300m deep layer of the ocean (a new addition compared to the model used in Arcomano et al., 2023). The model has skill in predicting the El Nino cycle and its global teleconnections with precipitation for 3-7 months depending on the season. The model captures equatorial variability of the precipitation associated with Kelvin and Rossby waves and MJO. Predictions of the precipitation in the equatorial region have skill for 15 days in the East Pacific and 11.5 days in the West Pacific. Though the model has low spatial resolution, for these tasks it has prediction skill comparable to what has been published for high-resolution, purely physics-based, conventional, operational forecast models.


---
# Investigating the hyperparameter space of deep neural network models for reaction coordinates: Revisiting the solvent coordinate in alanine dipeptide isomerization

## 研究反应坐标的深度神经网络模型的超参数空间: 重新审视丙氨酸二肽异构化中的溶剂坐标

Link: https://arxiv.org/abs/2408.02132

arXiv:2408.02132v2 Announce Type: replace 
Abstract: Identifying reaction coordinates (RCs) from many collective variable candidates have been of great challenge in understanding reaction mechanisms in complex systems. Machine learning approaches, especially the deep neural network (DNN), have become a powerful tool in this field, and have actively been applied. On the other hand, the structure of the DNN model is highly flexible, and the hyperparameters that determine the structure is often selected intuitively or in a highly non-trivial and tedious manner. Furthermore, how the choice of hyperparameter affects the quality of the DNN model remains obscure. In this work, we explore the hyperparameter space by developing the hyperparameter tuning approach for the DNN model in RC optimization, and investigate how the choice of parameter sets affect the quality of the RC. The DNN model is constructed from a large number of collective variables to predict the changes of committor along the RC by minimizing the cross-entropy function, and the hyperparameters are determined in an automatic manner using the Bayesian optimization method. The approach is applied to study the isomerization of alanine dipeptide in vacuum and in water, and the features that characterize the RC are extracted using the explainable AI (XAI) tools. The results show that the DNN models with notably different structures can describe the RC with similar accuracy. Furthermore, despite the difference in the hyperparameters, the features analyzed by XAI are highly similar, indicating that the hyperparameter space is multimodal. By studying the reaction in water, it is found that the electrostatic potential from the solvent to the hydrogen (H${}_{18}$), in addition to the dihedral angles $\phi$ and $\theta$, plays an important role in characterizing the RC. The DNN model thus effectively accounts for the torque character suggested previously.


---
# Inverse Physics-Informed Neural Networks for transport models in porous materials

## 用于多孔材料中传输模型的逆物理通知神经网络

Link: https://arxiv.org/abs/2407.10654

arXiv:2407.10654v3 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINN) are a machine learning tool that can be used to solve direct and inverse problems related to models described by Partial Differential Equations. This paper proposes an adaptive inverse PINN applied to different transport models, from diffusion to advection-diffusion-reaction problems. Once a suitable PINN is established to solve the forward problem, the transport parameters are added as trainable parameters. We find that, for the inverse problem to converge to the correct solution, the different components of the loss function (data misfit, initial conditions, boundary conditions and residual of the transport equation) need to be weighted adaptively as a function of the training iteration (epoch). Similarly, gradients of trainable parameters are scaled at each epoch accordingly. Several examples are presented for different test cases to support our PINN architecture and its scalability and robustness.


---
# Quantum noise modeling through Reinforcement Learning

## 基于强化学习的量子噪声建模

Link: https://arxiv.org/abs/2408.01506

arXiv:2408.01506v2 Announce Type: replace-cross 
Abstract: In the current era of quantum computing, robust and efficient tools are essential to bridge the gap between simulations and quantum hardware execution. In this work, we introduce a machine learning approach to characterize the noise impacting a quantum chip and emulate it during simulations. Our algorithm leverages reinforcement learning, offering increased flexibility in reproducing various noise models compared to conventional techniques such as randomized benchmarking or heuristic noise models. The effectiveness of the RL agent has been validated through simulations and testing on real superconducting qubits. Additionally, we provide practical use-case examples for the study of renowned quantum algorithms.


---
# Proximity Learning-Enabled Ligand Prediction for Ni-Catalyzed Atroposelective Suzuki-Miyaura Cross-Coupling: Leveraging Pd Catalysis Knowledge for Ni Discovery

## Ni催化的Atroposelective suzuki-miyaura交叉偶联的邻近学习支持的配体预测: 利用Pd催化知识进行Ni发现

Link: https://dx.doi.org/10.26434/chemrxiv-2024-03v52-v2?rft_dat=source%3Ddrss

The rational design of novel molecular catalysts often confronts challenges due to complex structure-performance relationships. Emerging data-driven approaches provide revolutionary solutions, yet the application of machine learning to new catalyst development inevitably faces a low-data regime, with limited effective structure-performance modeling available. In this study, we present a proximity learning strategy to facilitate knowledge transfer from well-documented Pd catalysis to novel, underexplored Ni systems. By synergistically modeling extensive palladium catalysis data with limited nickel/SadPhos data, our approach accurately predicted novel SadPhos ligands, enabling the first atroposelective nickel-catalyzed Suzuki-Miyaura cross-coupling reaction. The synthetic utility of the machine learning-predicted ligand was further demonstrated in the broad synthetic scope, gram-scale synthesis, and precise control of dual axial chiralities in ternaphthalene through the sequential coupling under Ni and Pd catalysis. Additionally, density functional theory calculations were employed to reveal the reaction mechanism and stereochemical model of this new catalytic system, validating the proposed mechanistic connection between Ni and Pd. This work demonstrates how machine learning models can effectively leverage mechanistic connectivity, applying extensive structure-performance relationship data from the literature to predict new catalysts, providing a novel strategy for the rational design of molecular catalysts from a few-shot learning perspective.


---
# CopDDB: a descriptor database for copolymers and its applications to machine learning

## CopDDB: 共聚物的描述符数据库及其在机器学习中的应用

Link: https://dx.doi.org/10.26434/chemrxiv-2024-fzrgp-v3?rft_dat=source%3Ddrss

Polymer informatics, which involves applying data-driven science to polymers, has attracted considerable research interest. However, developing adequate descriptors for polymers, particularly copolymers, to facilitate machine learning (ML) models with limited data sets remains a challenge. To address this issue, we computed sets of parameters, including reaction energies and activation barriers of elementary reactions in the early stage of radical polymerization, for 2500 radical–monomer pairs derived from 50 commercially available monomers and constructed an open database named “Copolymer Descriptor Database.” Furthermore, we built ML models using our descriptors as explanatory variables and physical properties such as the reactivity ratio, monomer conversion, monomer composition ratio, and molecular weight as objective variables. These models achieved high predictive accuracy, demonstrating the potential of our descriptors to advance the field of polymer informatics.


---
# HEPOM: Using Graph Neural Networks for the accelerated predictions of Hydrolysis Free Energies in different pH conditions.

## HEPOM: 使用图形神经网络加速预测不同pH条件下的水解自由能。

Link: https://dx.doi.org/10.26434/chemrxiv-2024-2v1nx?rft_dat=source%3Ddrss

Hydrolysis is a fundamental family of chemical reactions where water facilitates the cleavage of bonds. The process is ubiquitous in biological and chemical systems, owing to water's remarkable versatility as a solvent. However, accurately predicting the feasibility of hydrolysis through computational techniques is a difficult task, as subtle changes in reactant structure like heteroatom substitutions or neighboring functional groups can influence the reaction outcome. Furthermore, hydrolysis is sensitive to the pH of the aqueous medium, and the same reaction can have  different reaction properties at different pH conditions. In this work, we have combined reaction templates and high-throughput ab-initio calculations to construct a diverse dataset of hydrolysis free energies. The developed framework automatically identifies reaction centers, generates hydrolysis products, and utilizes a trained Graph Neural Network(GNN) model to predict  values for all potential hydrolysis reactions in a given molecule. The long-term goal of the work is to develop a data-driven, computational tool for high-throughput screening of pH-specific hydrolytic stability and the rapid prediction of reaction products, which can then be applied in a wide array of applications including chemical recycling of polymers and ion-conducting membranes for clean energy generation and storage.


---
# Engineering melanin-based meta-material for broad UV-visible absorption

## 基于工程黑色素的超材料，用于广泛的紫外可见吸收

Link: https://dx.doi.org/10.26434/chemrxiv-2024-n7bm6?rft_dat=source%3Ddrss

Designing materials with high intensity absorption of solar light across wide wavelength range is a primary goal in organic optoelectronics engineering. However, the potential application of most known biomolecules specifically in bio-optoelectronics is limited because they can only absorb light within specific wavelengths. Both experimental and computational approaches have investigated the potential of the skin pigment melanin, in this direction, but progress has been limited due to the complexity of its chemical space. In this work, we design a comprehensive virtual chemical space of melanin and develop machine learning-based approach to predict their complete optical and thermodynamical properties. These predictions help engineering melanin-based sustainable materials for tailored optoelectronic applications.


---
# Machine learning to identify suitable boundaries for band-pass spectral analysis of dynamic [11C]Ro15-4513 PET scan and voxel-wise parametric map generation

## 机器学习识别合适的边界，用于动态 [11C]Ro15-4513 PET扫描和逐体素参数图生成的带通光谱分析

Link: https://www.researchsquare.com/article/rs-5367311/latest

Background: Spectral analysis is a model-free quantification technique that treats the time-space signal as an impulse response to a bolus injection.Band-pass spectral analysis, considering specific frequency ranges, enables calculation of separate parametric maps of receptor subtype tracer binding for suitable radiopharmaceuticals. Frequency ranges are based on blocking studies. The process currently requires the manual selection of frequency ranges based on the data. To enhance the efficiency of band-pass spectral analysis and extend its application to a broader range of tracers, we propose employing machine learning to automate the selection of spectral boundaries. Based on these boundaries, voxel-wise parametric maps can be generated.Results:The best machine learning model agreed with the manual frequency boundary in 96.78% of the 3185 cases. The absolute mean error was 3.80% for slow component volume-of-distribution (V  \(_s\)  ) and 4.74% for fast component volume-of-distribution(V  \(_f\)  ), while the relative error was 2.83% &amp;plusmn; 43.47% for V$_s$ and -2.01% &amp;plusmn; 78.04% for V$_f$. The median intraclass correlation coefficient (ICC) arross six representative regions was 0.770 for V$_s$, 0.670 for V$_f$, and 0.502 for total component volume-of-distribution(V  \(_t\)  ).Parameter maps applying different boundaries for different ROIs were generated.Conclusion:  The machine learning model developed provided accurate boundary predictions in 96.78% of regions, with minimal average bias. However, when errors occur, they can be large, owing to the sparsity of peaks. The model enables setting boundaries automatically for the vast majority of regions, followed by manual checking of the outliers. It opens the possibility of accelerating analyses e.g. of GABA\textsubscript{A}\(\alpha\)1/2/3/5 subunit binding using [11C]flumazenil and of extending band-pass spectral analysis to other receptor systems.


---
# Disease diagnosis in Cassava leaves using CNN design and ResNet algorithm

## 基于CNN设计和ResNet算法的木薯叶片病害诊断

Link: https://www.researchsquare.com/article/rs-5334034/latest

Growth rate of crops is significantly lowered by illnesses that affect plants. It is impossible for anyone to eat the crops since they are tainted with various diseases. Farmers may suffer enormous losses as a consequence. Since cassava is an important food source in several countries, the financial system might be seriously damaged by the issue at hand. Traditional plant pathogen detection is labour-intensive and error-prone. It is not typically a dependable strategy to identify and stop the spread of plant viruses. Innovative technologies like deep learning as well as machine learning might aid in the early detection of plant diseases as an approach to get around these problems. The main goal of the work is to employ deep learning to image classification in order to accurately identify diseases that especially impact cassava plants. This recognition may make it possible to implement preventative measures like the specific application of chemical pesticides or confinement of contaminated crops. Each and every training and testing image comes from a rural area in the natural world. Using a specific collection of information, the simulation has been verified to ascertain its true results. The installation of a precise disease identification and mitigation model has the potential to significantly increase the durability of the cassava crop, improving food production and the quality of life for millions of people who are dependent upon this valuable crop.


---
# Seasonal Heatwave Forecasting with Explainable Machine Learning and Remote Sensing Data

## 使用可解释的机器学习和遥感数据进行季节性热浪预测

Link: https://www.researchsquare.com/article/rs-5267311/latest

Heatwaves can greatly impact societies, underscoring the need to extend current heatwave prediction lead times. This study investigated multiple machine-learning (ML) model approaches for heatwave occurrence prediction with long lead times of one to five months based on explanatory atmospheric and land surface features. Five ML classifiers were built using Google Earth Engine remote sensing datasets to predict heatwaves at national scale (Sweden) based on 16 features referring to the period of 1989&amp;ndash;2019. Extreme Gradient Boosting performed best for lead times of one month (F1-score&amp;thinsp;=&amp;thinsp;0.63, accuracy&amp;thinsp;=&amp;thinsp;0.81) and four months (F1-score&amp;thinsp;=&amp;thinsp;0.54, accuracy&amp;thinsp;=&amp;thinsp;0.79), while K-Nearest Neighbour was best for lead times of two, three and five months (respective F1-score&amp;thinsp;=&amp;thinsp;0.63, 0.65, 0.49, accuracy&amp;thinsp;=&amp;thinsp;0.77, 0.79, 0.78). When applying the SHapley Additive exPlanations technique for model interpretation, land surface features emerged as more impactful heatwave predictors than atmospheric features at longer lead times. More frequent heatwave occurrence was associated with places in Sweden characterized by lower values of geopotential height, latitude, topographical slope, evaporation, precipitation and cropland area, and higher values of average temperature, mean sea level pressure, and southerly and westerly winds. The study also concretely exemplifies how use of this multi-model ML method can enhance predictions and further step-wise improve them, thereby facilitating earlier warning in support of better planning of measures to mitigate adverse heatwave impacts, up to several months ahead of their possible occurrence.


---
# Enhancing COVID-19 Forecasts Through Multivariate Deep Learning Models

## 通过多变量深度学习模型增强COVID-19预测

Link: https://www.researchsquare.com/article/rs-5400759/latest

Background It is well known that deep learning (DL) models often struggle with low prediction performance due to data scarcity. This scarcity hampers the effectiveness of DL methods that typically require large datasets to generate reliable forecasts. Recently, several DL models have been proposed for predicting the spread of COVID-19. These models are country specific models and thus use the COVID-19 data only from the target country. To improve COVID-19 forecasting using DL models, we propose multivariate DL models using the additional data available from other countries.Methods Based on the rankings determined by Dynamic Time Warping (DTW) distance, which calculates the similarity of infection trends across countries, univariate DL models using only the target country data were extended to multivariate models which integrated data from the top-ranked countries to optimize performance. We considered seven DL models including the Transformer model, TCN, CNN-LSTM, BiLSTM, GRU, RNN, and LSTM.Results Our results showed that the multivariate transformer model achieved the most significant improvements in forecasting accuracy, with an average reduction of 60.15% in mean root mean square error (RMSE) across the five target countries and five time periods when integrating data from additional countries, compared to univariate models using only the target country data. Additionally, multivariate transformer models consistently demonstrated significant improvements over univariate models in terms of mean RMSE, as evidenced by the Diebold-Mariano test. Other multivariate DL models also showed performance gains, with the TCN model achieving an average reduction in RMSE of 36.28%, followed by CNN-LSTM at 29.47%, BiLSTM at 21.07%, GRU at 21.43%, RNN at 17.46%, and LSTM at 16.38%.Conclusions These findings indicate that leveraging similar infection patterns from data of other countries can provide valuable information for predicting the COVID-19 spread in the target country, especially when data is scarce, thereby enhancing forecasting performance.


---
# Assessment of neonicotinoids toxicity and their risk to honeybee under caged and open field ecosystem

## 笼式和野外生态系统下新烟碱类化合物的毒性及其对蜜蜂的风险评估

Link: https://www.researchsquare.com/article/rs-5323746/latest

Neonicotinoids are known to affect the behavior of honeybees significantly leading to the loss of colony fitness. Most chemicals are not directly lethal to bees, but the sublethal doses of certain chemicals can adversely affect bees on olfactory learning and memory, as well as visual learning which has been reported globally. Keeping the objective of elucidating the effect two most used neonicotinoids in diverse ecosystems over a period of time, the present study was conducted to record the toxicity of imidacloprid, 17.8% SL at field application rate followed by the decreasing concentration (44, 4, 3, 2, and 1&amp;micro;L/mL) and clothianidin 50% WDG (125, 12, 10, 8, 6, 4, and 2 &amp;micro;g/mL) on honeybee. A series of experiments such as ingestion test, ingestion after starvation test, indirect contact test, topical assay test, and semi-field test followed by field test was conducted and recorded an increase in the percent mortality for the increasing concentrations of the neonicotinoids with the exposure period. It was also recorded that the lethal concentration for neonicotinoid was found significantly lower. The LC50, LD50, LC99, and LD99 estimated through probit analysis recorded in similar trend along the exposure period. The Hazard Quotient (HQ) is significantly increased with the exposure period (11574 at 3 HAT and 18825 at 48 HAT) for both insecticides. This study highlighted the extremely low concentration of neonicotinoids could pose a potential toxic effect on bees and that could lead to the overall behavior of honeybee.


---
# Environmental Impact Prediction

## 环境影响预测

Link: https://www.researchsquare.com/article/rs-5419185/latest

Predicting environmental impacts is crucial for evaluating and reducing how human activity affects ecosystems, particularly when it comes to pollution, resource depletion, and climate change. In order to predict changes in the environment, this study looks at a variety of predictive models, including both sophisticated machine learning techniques and conventional statistical methods. We provide an integrated framework that increases prediction accuracy by utilizing data from several sources, including satellite images, climate records, air and water quality indexes, and socioeconomic characteristics. Using machine learning models, the study shows improved performance in short-term predictions of water pollution, soil deterioration, and air quality. However, due to data limitations and the complexity of ecological systems, long-term, complicated predictions&amp;mdash;like those regarding habitat degradation and biodiversity loss&amp;mdash;remain difficult. According to our research, enhancing future environmental effect projections and facilitating more sustainable decision-making processes would need incorporating real-time data, growing datasets, and creating adaptive models.


---
# Assessing the accuracy and reasoning of using ChatGPT to evaluate the quality of health news

## 使用ChatGPT评估健康新闻质量的准确性和推理

Link: https://www.researchsquare.com/article/rs-5390898/latest

Background
With the growing prevalence of health misinformation online, there is an urgent need for tools that can reliably assist the public in evaluating the quality of health information. This study investigates the performance of ChatGPT, a representative large language model (LLM), in rating the quality of health news and providing explanatory reasoning.
Methods
We evaluated ChatGPT's performance using an expert-annotated dataset from HealthNewsReview.org, which assesses the quality of health news across nine criteria. ChatGPT was prompted with standardized queries tailored to each criterion. We measured its rating performance using precision, recall, and F1 scores for binary classification (satisfactory/not satisfactory). Additionally, linguistic complexity, readability, and the quality of ChatGPT&rsquo;s explanatory reasoning were assessed through both quantitative linguistic analysis and manual evaluation of consistency and contextual relevance.
Results
ChatGPT&rsquo;s rating performance varied across criteria, with the highest accuracy for the Cost criterion (F1= 0.824) and lower accuracy for Benefit, Conflict, and Quality criteria (F1 &amp;lt; 0.5), underperforming compared to machine learning-based models. Its explanations were clear, with readability suited to late high school or early college levels, and scored highly for consistency (average score: 2.90/3) and contextual relevance (average score: 2.73/3), indicating strong explanatory potential despite rating limitations.
Conclusion
While ChatGPT&rsquo;s rating accuracy requires improvement, its strength in offering comprehensible explanations presents a valuable opportunity to enhance public understanding of health news quality. Future research should aim to refine LLMs' rating accuracy while leveraging their explanatory strengths to better serve the needs of non-expert audiences.


---
# Leveraging Generative AI Synthetic and Social Media Data for Content Generalizability to Overcome Data Constraints in Vision Deep Learning

## 利用生成式AI合成数据和社交媒体数据实现内容概括性，以克服视觉深度学习中的数据约束

Link: https://www.researchsquare.com/article/rs-5423676/latest

Generalizing deep learning models across diverse content types is a persistent challenge in domains like Facial Emotion Recognition (FER), where datasets often fail to reflect the wide range of emotional responses triggered by different stimuli. This study addresses the issue of content generalizability by comparing FER model performance between models trained on video data collected in a controlled laboratory environment, data extracted from a social media platform (YouTube), and synthetic data generated using Generative Adversarial Networks. The videos focus on facial reactions to advertisements, and the integration of these different data sources seeks to address underrepresented advertisement genres, emotional reactions, and individual diversity. Our FER models leverage Convolutional Neural Networks Xception architecture, which is fine-tuned using category based sampling. This ensures training and validation data represent diverse advertisement categories, while testing data includes novel content to evaluate generalizability rigorously. Precision-recall curves and ROC-AUC metrics are used to assess performance. Results indicate a 7% improvement in accuracy and a 12% increase in precision-recall AUC when combining real-world social media and synthetic data, demonstrating reduced overfitting and enhanced content generalizability. These findings highlight the effectiveness of integrating synthetic and real-world data to build FER systems that perform reliably across more diverse and representative content.


---
# An Energy-Aware Combinatorial Contextual Neural Bandit Approachfor Joint Performance Optimization in Client Selection for Federated Learning

## 用于联合学习的客户选择中的联合性能优化的能量感知组合上下文神经强盗方法

Link: https://www.researchsquare.com/article/rs-5175921/latest

In the evolving landscape of machine learning (ML), federated learning (FL) stands out as an innovative strategy for training models across dispersed devices without centralizing raw data. Such an approach, however, grapples with data heterogeneity challenges, violating the independent and identically distributed (IID) assumption and undermining the global model accuracy. To address this, we present federated adversary-resilient neural selector (FANS), a sophisticated context-aware client selection algorithm, leveraging a combinatorial contextual neural bandit framework. This algorithm accentuates the enhanced extraction of contextual information by evaluating each local client with a universally standardized dataset, subsequently yielding a more insightful contextual representation tailored for federated settings. Additionally, we further address another crucial aspect of client selection &mdash; energy consumption. Considering this key factor along with the global accuracy jointly, greatly increase the adaptability of FL in real-world applications. We then introduce the Selection Robustness Score (SRS), a novel metric designed to quantify the efficacy of client selection under both adversarial and energy-constrained conditions. Using this metric, we demonstrate FANS&rsquo;s effectiveness in enhancing the FL process. Empirical evaluations across diverse settings reveal our method&rsquo;s superiority over current state-of-the-art solutions, with significant improvement in the SRS and energy conservation.


---
# Generating Cervical Anatomy Labels using a Deep Ensemble Multi-Class Segmentation Model Applied to Transvaginal Ultrasound Images

## 使用应用于经阴道超声图像的深度集成多类分割模型生成宫颈解剖标签

Link: https://www.researchsquare.com/article/rs-5390889/latest

Preterm birth (PTB) is the leading cause of perinatal death, affecting 10% of pregnancies. Currently, transvaginal ultrasound (TVUS) measurement of cervical length (CL) is the sole quantitative imaging metric for PTB risk, but offers limited predictive value. While 3D computational models of cervical biomechanics show promise as PTB risk predictors, they require precise clinician-provided measurements. AI-enabled ultrasound segmentation offers a solution by automatically extracting anatomical features, thus addressing the labeling bottleneck. This study utilizes an ensemble of deep learning-based multi-class segmentation models trained on diverse TVUS data (N=246) and evaluated on an out-of-distribution dataset (N=29). High agreement (dice score ~0.8) between expert and model labels demonstrates the utility of AI tools in &nbsp;accurately measuring cervical geometry. Ultimately, this can enhance 3D biomechanical models and more sophisticated AI-based models to better predict birth timing, specifically targeting PTB risk.


---
# Dual Approach to Type 2 diabetes Mellitus Risk Assessment in Women: Machine Learning Predictions and Fractional-Order Modeling of Physiological Dynamics

## 女性2型糖尿病风险评估的双重方法: 机器学习预测和生理动力学的分数阶模型

Link: https://www.researchsquare.com/article/rs-5523185/latest

This study examines diabetes risk in women through predictive machine learning models and fractional- order physiological modeling. Machine learning models, including Bagged Trees, k-Nearest Neighbors (k-NN), Decision Trees, SVM (Support Vector Machine), and Logistic Regression, were applied to assess accuracy in diabetes prediction. Bagged Trees achieved the highest performance, with over 99% accuracy across metrics, and a user-friendly GUI-enabled real-time risk assessment. The GUI interface designed for these models provided users with accessible, dynamic feedback, enhancing usability for real-time assessment. Analysis revealed notable correlations, including age with pregnancies (0.54) and BMI with skin thickness (0.39), suggesting key factors in diabetes risk. Findings show that Glucose, BMI, Blood Pressure, and Diabetes Pedigree Function emerge as the top influential features, across all models. Using fractional-order modeling, we simulated glucose, insulin, BMI, and blood pressure changes over time, showing that higher fractional orders aligned with increased response dynamics. Together, these methods offer a comprehensive view of diabetes risk factors in women. By combining machine learning&rsquo;s predictive power with the detailed, time-sensitive insights of fractional-order modeling, this study highlights key risk indicators and deepens our understanding of diabetes dynamics, ultimately supporting more effective risk assessment and management strategies. This dual approach provides an enriched perspective on diabetes risk factors and offers improved strategies for prediction and management.


---
# Research on Mechanical Fault Diagnosis under Complex Working Conditions Based on Improved YOLOv8

## 基于改进YOLOv8的复杂工况机械故障诊断研究

Link: https://www.researchsquare.com/article/rs-5230594/latest

With the rapid development of artificial intelligence and big data technology, deep learning-based bearing fault diagnosis methods have demonstrated excellent diagnostic performance. However, most neural networks require a significant amount of prior knowledge during construction and training, and a lot of time is needed to build the optimal model to achieve high classification accuracy. In addition, when it comes to fault data across operating conditions and equipment, the network's generalization ability is often limited. In addition, the scarcity of labelled fault data and the large differences in data sample distribution further increase the difficulty of achieving high-precision fault diagnosis. To address this challenge, this article focuses on rolling bearings as the main research object proposes for the first time the application of YOLOv8 in bearing fault diagnosis and proposes an improved cross condition and cross equipment fault diagnosis method RSD-YOLOv8 based on YOLOv8. Firstly, the DSConv module is introduced in the YOLOv8 network to replace the original convolutional layers, enhancing the network's ability to capture vibration signal features. Secondly, replacing the C2f module with the C2f_Rep_SimAm module reduces the number of parameters while maintaining computational efficiency. This article simulates the fault states of rolling bearings under cross-operating conditions and cross-equipment conditions using two datasets, CWRU and XJTU-SY. It verifies the effectiveness of the model improvement. In addition, transfer learning experiments were conducted on the gearbox fault dataset of Jiangsu Qianpeng Diagnostic Engineering Co., Ltd. to verify the universality of the improved model. The successful application of the YOLOv8 network in bearing fault diagnosis has provided an effective solution for diagnosing bearings under different operating conditions and equipment.

