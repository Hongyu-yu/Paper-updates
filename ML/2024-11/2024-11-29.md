# Reply to: Machine learning-driven virtual biopsy system may increase organ discards at aggressive kidney transplant centers

## 回复: 机器学习驱动的虚拟活检系统可能会增加积极的肾脏移植中心的器官丢弃

Link: https://www.nature.com/articles/s41467-024-53703-6

<p>Nature Communications, Published online: 29 November 2024; <a href="https://www.nature.com/articles/s41467-024-53703-6">doi:10.1038/s41467-024-53703-6</a></p>Reply to: Machine learning-driven virtual biopsy system may increase organ discards at aggressive kidney transplant centers


---
# Machine learning-driven virtual biopsy system may increase organ discards at aggressive kidney transplant centers

## 机器学习驱动的虚拟活检系统可能会增加侵略性肾脏移植中心的器官丢弃率

Link: https://www.nature.com/articles/s41467-024-53702-7

<p>Nature Communications, Published online: 29 November 2024; <a href="https://www.nature.com/articles/s41467-024-53702-7">doi:10.1038/s41467-024-53702-7</a></p>Machine learning-driven virtual biopsy system may increase organ discards at aggressive kidney transplant centers


---
# From STEM-EDXS data to phase separation and quantification using physics-guided NMF

## 从stem-edxs数据到使用物理指导的NMF进行相分离和量化

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad9192

We present the development of a new algorithm which combines state-of-the-art energy-dispersive x-ray (EDX) spectroscopy theory and a suitable machine learning formulation for the hyperspectral unmixing of scanning transmission electron microscope EDX spectrum images. The algorithm is based on non-negative matrix factorization (NMF) incorporating a physics-guided factorization model. It optimizes a Poisson likelihood, under additional simplex constraint together with user-chosen sparsity-inducing and smoothing regularizations, and is based on iterative multiplicative updates. The fluorescence of x-rays is fully modeled thanks to state-of-the-art theoretical work. It is shown that the output of the algorithm can be used for a direct chemical quantification. With this approach, it is straightforward to include a priori knowledge on the specimen such as the presence or absence of certain chemical elements in some of its phases. This work is implemented within two open-source Python packages, espm and emtables, which are used here for data simulation, data analysis and quantification. Using simulated data, we demonstrate that incorporating physical modeling in the decomposition helps retrieve meaningful components from spatially and spectrally mixed phases, even when the data are very noisy. For synthetic data with a higher signal, the regularizations yield a tenfold increase in the quality of the reconstructed abundance maps compared to standard NMF. Our approach is further validated on experimental data with a known ground truth, where state-of-the art results are achieved by using prior knowledge about the sample. Our model can be generalized to any other scanning spectroscopy techniques where underlying physical modeling can be linearized.


---
# DyeDactic: towards biosynthetic alternatives to artificial textile dyes

## DyeDactic: 迈向人造纺织染料的生物合成替代品

Link: https://dx.doi.org/10.26434/chemrxiv-2024-hdpn5?rft_dat=source%3Ddrss

Production and application of textile dyes using microorganisms represents an important step towards sustainable manufacturing. Although living organisms can produce numerous coloured substances, they frequently demonstrate poor dyeing performance, insufficient photostability, or toxicity. To guide the development of new biosynthetically accessible colourants, we developed a workflow (DyeDactic) to predict colour at different pH values. Starting with a rapid estimation of the lowest electronic transition energy for potential colourants using Graph Neural Networks, the procedure can filter large libraries of generated chemical structures producing a targeted subset of compounds for further examination. The final step employs time-dependent density functional theory (TD-DFT) to estimate the intensity of absorption peaks in the visible spectral region, model spectral band shape and estimate colour. To tackle halochromism, which is frequently observed for natural colourants, populations of protonated and deprotonated species are estimated at different pH values using predicted acidity constants of ionisable atoms followed by addition and weighting of modelled absorption spectra. The complete workflow is applied to four natural colourants belonging to different classes (emodin, quinalizarin, biliverdin, and orcein) and the predicted colour dependence on pH is compared with the experimental data. Both the machine learning tool and the quantum chemical calculations are validated and fine-tuned using an assembled dataset of spectral properties of 647 natural colourants. Potential chemoenzymatic modifications are discussed based on comparison of structural and physico-chemical properties between natural colourants and artificial dyes and pigments from the Colour Index.


---
# Revealing the Impact of Aggregations in the Graph-based Molecular Machine Learning: Electrostatic Interaction versus Pooling Methods

## 在基于图形的分子机器学习中揭示聚集的影响: 静电相互作用与池化方法

Link: https://dx.doi.org/10.26434/chemrxiv-2024-sbwxm?rft_dat=source%3Ddrss

Molecular structures that can be readily represented by graphs comprising constituent atoms (nodes) and their chemical bonds (edges) can also be used as input data for well-known machine learning (ML) models that process this data, such as graph neural networks (GNNs). GNNs showed a reasonable performance in the predicting properties of chemical systems. In typical applications of GNNs to chemistry-related fields, the main objective is to create an optimal molecular representation by aggregating atomic features and pooling features in the graph. In this study, we investigated two different approaches that can possibly generate better molecular representations. First, we created intermolecular edges to predict the photochemical properties of chromophore molecules in the solution. These intermolecular edges were constructed using atomic partial charges, inspired from the fact that electrostatic interaction is the main component of solute-solvent interaction. In the second approach, we investigated the effect of the aggregation and pooling functions. The results showed that intermolecular electrostatic interactions based on ground state charges prevent the GNN model from generating more effective molecular representations. On the contrary, the model demonstrated better performance when the averaging and adding operations were employed in a hybrid manner for aggregation and pooling functions.


---
# Improving Drug-Induced Liver Injury Prediction Using Graph Neural Networks with Augmented Graph Features from Molecular Optimisation

## 使用具有分子优化增强图形特征的图形神经网络改善药物诱导的肝损伤预测

Link: https://dx.doi.org/10.26434/chemrxiv-2024-d12gk?rft_dat=source%3Ddrss

BACKGROUND. Drug-induced liver injury (DILI) is a significant concern in drug development, often leading to the discontinuation of clinical trials and the withdrawal of drugs from the market due to severe hepatotoxicity. This study explores the application of graph neural networks (GNNs) for DILI prediction, using molecular graph representations as the primary input.

METHODS. We evaluated several GNN architectures, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Sample and Aggregation (GraphSAGE), and Graph Isomorphism Networks (GINs), using the latest FDA DILI dataset and other molecular property prediction datasets. We introduce a novel approach that creates a custom graph dataset, driven by molecular optimisation, that incorporates detailed and realistic chemical features such as bond lengths and partial charges as input into the GNN models. We have named our model approach DILIGeNN.

RESULTS. DILIGeNN achieved an AUC of 0.897 on the DILI dataset, surpassing current state-of-the-art model in the DILI prediction task. Furthermore, DILIGeNN outperformed the state-of-the-art in other graph-based molecular prediction tasks, achieving an AUC of 0.918 on the Clintox dataset and 0.993 on the BBBP dataset and 0.953 on the BACE dataset, indicating strong generalisation and performance across different datasets.

CONCLUSION. DILIGeNN, without relying on biological data, outperforms the state-of-the-art methods in DILI prediction that incorporate both chemical and biological data. These findings highlight the effectiveness of our molecular graph generation and the GNN training approach as a powerful tool for early-stage drug development and drug repurposing pipeline.


---
# RNNEI: an attack detection model on Internet of Things Networks that utilizes Random Neural Networks and Evolutionary Intelligence

## RNNEI: 利用随机神经网络和进化智能的物联网网络攻击检测模型

Link: https://www.researchsquare.com/article/rs-5422283/latest

Over the past few years, there has been significant research on the Internet of Things (IOT), with a major challenge being network security and penetration. Security solutions require careful planning and vigilance to safeguard system security and privacy. Adjusting the weights of neural networks has been shown to improve detection accuracy to some extent. In attack detection, the primary goal is to enhance the precision of attack detection using machine learning techniques. The paper details a fresh approach for adjusting weights in the random neural network to recognize attacks. Reviews of the method under consideration indicate better performance than random neural network methods, Nearest Neighbor, and Support Vector Machine (SVM). Up to 99.49% accuracy has been achieved in attack detection, while the random neural network method has improved to 99.01%. The amalgamation of the most effective approaches in these experiments through a multi-learning model led to an accuracy improvement to 99.56%. The proposed model required less training time compared to the random neural network method.


---
# Deep Learning-Assisted Screening and Diagnosis of Scoliosis: Segmentation of Bare Back-Images via an Attention-Enhanced Convolutional Neural Network

## 深度学习辅助的脊柱侧凸筛查和诊断: 通过注意力增强的卷积神经网络分割裸露的背部图像

Link: https://www.researchsquare.com/article/rs-5422461/latest

Background: Traditional scoliosis screening necessitates a substantial number of specialized personnel and equipment, leading to inconvenience that can result in missed opportunities for early diagnosis and optimal treatment. We have developed a deep learning-based image segmentation model to enhance the efficiency of scoliosis screening.
Methods: A total of 350 patients with scoliosis and 108 healthy subjects were included in this study. The dataset comprised bare back images and full-length anteroposterior and lateral X-ray images from 458 participants. An attention mechanism was incorporated into the original U-Net architecture to build an attention U-Net model for image segmentation. The entire dataset was divided into training (321 cases), validation (46 cases), and test (91 cases) sets at a 7:1:2 ratio. The training set was used to train the attention U-Net model, whereas the validation set was used to fine-tune hyperparameters and prevent overfitting during training. The performance of the model was evaluated via the test set. After automatic segmentation of the back contour, a back asymmetry index was calculated viacomputer vision algorithms. The severity of scoliosis was classified on the basis of this index, and the classification results were statistically compared to those of three clinical experts.
Results: Following the segmentation of bare-back images and the application of computer vision algorithms, the U-Net model achieved an accuracy, precision, and recall rate of over 90% in predicting severe scoliosis. Notably, the AUC values for diagnosing scoliosis were 0.93 for the U-Net model and 0.92 for the associate chief physician, while for identifying severe scoliosis, the AUC values were 0.95 and 0.96, respectively.
Conclusion: The attentionU-Net model developed in this study achieved accuracy and precision in determining scoliosis severity comparable to that of clinical physicians by analyzing bare-back images. The model's ability to diagnose scoliosis was also similar to that ofclinical professionals. The use of this model for scoliosis screening and diagnosis offers advantages such as being radiation-free and improving efficiency. This provides a novel, noninvasive, and effective approach, as well as a theoretical foundation, for large-scale scoliosis screening.


---
# The use of laser-assisted cart positioning significantly reduces the docking time of multimodular robotic systems

## 激光辅助推车定位的使用大大减少了多模块机器人系统的对接时间

Link: https://www.researchsquare.com/article/rs-5352314/latest

Background The Hugo RAS system is characterized by its multimodular design, which leads to an increased docking effort. Exact data for docking time and the learning curve is missing. We describe for the first time the use of a laser-guided cart positioning to reduce the docking time.Methods In this prospective monocentric study, the docking time was evalutated for a consecutive series of pelvic surgeries with the Hugo RAS system. In a subgroup, a cross-line laser was adapted at the cart for positioning using fix points at the ceiling. The medical personnel were classified as &amp;ldquo;inexperienced&amp;rdquo; with &amp;le;&amp;thinsp;5 consecutive dockings and as &amp;ldquo;experienced&amp;rdquo; with &amp;gt;&amp;thinsp;5 consecutive dockings.Results From 10/2023 to 08/2024, 82 procedures were performed with the Hugo RAS. For the evaluation 75 procedures could be considered. The mean docking time was 7.6&amp;thinsp;&amp;plusmn;&amp;thinsp;3.5 min. There was a reduction in docking time from 13.5&amp;thinsp;&amp;plusmn;&amp;thinsp;3.7 min in the first 5 procedures to 4.4&amp;thinsp;&amp;plusmn;&amp;thinsp;0.9 min in the last 5 procedures (p&amp;thinsp;&amp;lt;&amp;thinsp;0.001). Docking with laser (n&amp;thinsp;=&amp;thinsp;45) was faster than without laser (n&amp;thinsp;=&amp;thinsp;30) (6.2&amp;thinsp;&amp;plusmn;&amp;thinsp;2.5 vs. 9.8&amp;thinsp;&amp;plusmn;&amp;thinsp;3.7 min, p&amp;thinsp;&amp;lt;&amp;thinsp;0.001). Faster docking time was observed with inexperienced surgical nursing staff with laser than without laser (10.4&amp;thinsp;&amp;plusmn;&amp;thinsp;3.7 vs. 5.4&amp;thinsp;&amp;plusmn;&amp;thinsp;1.4 min; p&amp;thinsp;&amp;lt;&amp;thinsp;0.001). With experienced nursing staff, the laser had no influence (6.6&amp;thinsp;&amp;plusmn;&amp;thinsp;1.3 vs. 6.7&amp;thinsp;&amp;plusmn;&amp;thinsp;2.9 min; p&amp;thinsp;=&amp;thinsp;0.9). As a reference docking time for daVinci Xi procedures was 2.4&amp;thinsp;&amp;plusmn;&amp;thinsp;1.7 min (n&amp;thinsp;=&amp;thinsp;5).Conclusion Laser-guided cart positioning has a significant impact on docking time, especially for unexperienced medical personnel. Especially in the times of experienced staff shortage, laser-guided cart positioning can save operating time.


---
# Advancing Depression Risk Assessment in Connective Tissue Diseases: A Multi- Classification Machine Learning Approach

## 推进结缔组织病抑郁风险评估: 一种多分类机器学习方法

Link: https://www.researchsquare.com/article/rs-5184196/latest

This study retrospectively collected clinical data from 480 patients with connective tissue diseases (CTDs) at Nanjing First Hospital between August 2019 and December 2023 to develop and validate a multi-classification machine learning (ML) model for assessing depression risk. Addressing the limitations of traditional assessment tools, six ML models were constructed using univariate analysis and the LASSO algorithm, with the artificial neural network (ANN) model emerging as the best performer, demonstrating strong predictive ability across different depression severity levels (none_F1=0.849, mild_F1=0.621, moderate and severe_F1=0.571). Additionally, the study provided an interpretation of the best-performing model using SHAP and developed a user-friendly R Shiny application (https://macnomogram.shinyapps.io/ANN-CTD/) to facilitate clinical use. The findings suggest that the ANN model represents a significant advancement in assessing depression risk among CTD patients, highlighting the potential of ML in enhancing mental health management for this patient population.


---
# Predicting the Impact of Extreme Weather on Agricultural Losses in the Delmarva Peninsula using Multi-Step Machine Learning and Financial Crop Loss Data

## 使用多步机器学习和金融作物损失数据预测极端天气对德尔马瓦半岛农业损失的影响

Link: https://www.researchsquare.com/article/rs-5398230/latest

The increasing occurrence of extreme weather events due to climate change presents significant challenges for agricultural production. Existing research on climatic impacts to agriculture has predominantly focused on changes in yield for major crops, providing limited insights into overall losses and impacts on diverse regional agricultural systems. This study addresses this gap by using financial crop loss data and crop insurance payouts to gain a more comprehensive understanding of agricultural impacts in diverse agricultural regions. To address the irregular data structure of financial loss data, we developed multi-step machine learning models to quantify the relationship between weather-related financial crop loss and contributing climatic factors. The Delmarva Peninsula in the Eastern United States is used as a case study location to demonstrate this methodology over the period from 1980 to 2018. Multi-step configurations of linear regression, random forest, and support vector machine approaches are compared in terms of their classification and estimation accuracy using a repeated hold-out cross-validation analysis. Results indicate that machine learning methods, particularly random forest, outperform both statistical approaches and our null baseline model, demonstrating superior generalizability in agricultural damage estimation. Multistep configurations that address irregular data distributions are shown to have a significant influence on models' capacity to detect and estimate damage occurrence. The study reveals a preference for simpler modeling approaches that minimize variance in handling unseen data, as well as the importance of accounting for seasonal patterns, spatial groupings, and persistent weather phenomena in accurately estimating agricultural losses.


---
# Assessing Seasonal Fluctuations in Forecast Precision through Comparative Regression Modelling in Meteorology

## 通过气象学中的比较回归模型评估预报精度的季节性波动

Link: https://www.researchsquare.com/article/rs-5397718/latest

This study provides an in-depth review of various regression models used to forecast meteorological parameters across seasons. Regression models that use traditional regression can be evaluated against advanced machine learning techniques like Random Forest and Gradient Boosting to evaluate their predictive power using metrics such as root mean square Error (RMSE), Mean Absolute Error (MAE) as well as Mean Absolute Percentage Error (MAPE) to calculate R2 and ratio between RSR/RMSE to observer Standard Deviation ratio, Kling-Gupta Efficiency (KGE). The research highlights notable performance differences over time, highlighting both the variability of weather data as well as the challenges associated with accurate forecasting. The Ridge Regression model stands out from other models with one of the most accurate error metrics (RMSE: 294.87, MAE: 232.58, MAPE 7.74 RSR&amp;thinsp;=&amp;thinsp;0.81); as well as consistently producing R2 values of 0.34 and KGE values of 0.53 within its model parameters. The methods adopted in this research would help the stakeholders, civic bodies and others for attaining sustainable water resources approach to tackle the repercussions of climate change.


---
# Virtual Learning During Medical School May Inadequately Prepare Students for General Surgical Residency

## 医学院期间的虚拟学习可能不足以使学生为普通外科住院医师做好准备

Link: https://www.researchsquare.com/article/rs-5073329/latest

Purpose: Due to pandemic-related restrictions, medical schools transitioned to virtual clinical rotations in 2020. Virtual learning is now an integral part of medical education, but there remain questions as to whether it adequately prepares students for the rigors of surgical residency. We hypothesized that students exposed to virtual learning during medical school demonstrate inferior performance during residency as compared to their predecessors.
Methods: Data were collected from 12 General Surgery Residency programs. Residents who began training in academic years (AY) 2018-2022 were included and followed for two years. Residents who started in AY2018-2020 (conventional group) prior to the introduction of virtual rotations were compared to residents who started in AY2021-2022 (virtual group) after virtual clinical rotations were implemented during medical school. The primary outcome was the sum of annual milestone scores, adjusted for post-graduate year and analyzed with a linear mixed-effects model. Secondary outcomes included milestone scores by ACGME competency category, USMLE scores, ABSITE percent correct, remediation, and attrition.
Results: 334 residents were included: 199 in the conventional group and 135 in the virtual group. There was no difference in mean USMLE score between conventional vs virtual groups: USMLE Step1: 239 vs 240, p=0.52, USMLE Step2: 251 vs 251, p=0.77. When adjusted for post-graduate year (PGY), virtual learning was associated with an average decrease of 2.3 points over the sum of all milestones over the course of a year of residency when compared to the conventional group (95% CI -0.4 to -4.2, p=0.02). &amp;nbsp;In the analysis of categorized ACGME competency milestone scores, virtual learning was associated with a decrease in scores for patient care (virtual vs conventional: -0.1, 95% CI -0.032 to -0.16, p&amp;lt;0.01), systems-based practice (virtual vs conventional: -0.11, 95% CI -0.047 to -0.17, p&amp;lt;0.01), and interpersonal and communication skills (virtual vs conventional: -0.075 95% CI -0.001 to -0.14, p=0.05). A non-statistically significant 2% decrease in ABSITE percent correct in the virtual group (95% CI 1-5%, p=0.07) was noted. 40 residents underwent remediation: 19 (11%) in the conventional group and 21 (16%) in the virtual group (odds ratio (OR), virtual vs conventional, 1.74, 95%CI 0.85-3.59, p=0.14p=0.14). Twelve residents underwent attrition: 7 (4%) in the conventional group and 5 (4%) in the virtual group (OR, virtual vs conventional, 1.05 95% CI 0.26 - 3.96, p=1). There was no difference in average annual case numbers between the groups after accounting for PGY (p=0.18).
Conclusion: Virtual learning during medical school is associated with poorer performance as a junior surgical resident, compared with in-person instruction, as indicated by a small decrease in milestone scores, and a trend towards inferior ABSITE performance and increased remediation. In-person and hands-on learning experiences during medical school should be prioritized to better prepare medical students for surgical residency.


---
# Short-Term Load Forecasting using Hybrid Approach Combining African Vulture Optimization Algorithm and Self-Adaptive Neural Networks

## 非洲秃鹫优化算法与自适应神经网络相结合的短期负荷预测

Link: https://www.researchsquare.com/article/rs-5418959/latest

In this paper, we present a hybrid approach that combines the African Vulture Optimization Algorithm (AVOA) with Self-Adaptive Neural Networks (SANNs) for short-term load forecasting. The AVOA, a metaheuristic inspired by the foraging behaviour of vultures, is utilised to optimise the parameters of a Self-Adaptive Neural Network, which adjusts its structure and learning parameters based on the problem at hand. Our experimental results, conducted on several benchmark datasets, demonstrate that the hybrid model significantly improves forecasting accuracy compared to conventional methods, offering a promising solution for more reliable and efficient load forecasting in power systems.


---
# QEFMLA-FIDO: Quantum Evolutionary Frameworks for Machine Learning Acceleration: Fisher Information-Driven Optimization in Hybrid Classical-Quantum Architectures

## Qefmla-fido: 用于机器学习加速的量子进化框架: 混合经典-量子架构中的Fisher信息驱动优化

Link: https://www.researchsquare.com/article/rs-5424606/latest

Quantum machine learning involves improving quantum algorithms using machine learning and/or improving machine learning using quantum mechanics. In this article, we propose a novel quantum evolutionary algorithm (QEA) that integrates quantum mechanics into machine learning. This algorithm is similar to how an artificial neural network mimics the human brain. Our proposed quantum-inspired algorithm can be run on classical hardware to provide with speedup for computationally hard problems. The algorithm is also readily suited to be extended for running on quantum hardware to provide with much improved speedup than possible on classical hardware. Inspired by the natural evolution of quantum states, the QEA operates on both classical and quantum hardware, enhancing computational efficiency. The algorithm iteratively evolves a system&amp;rsquo;s Hamiltonian to fit training data, solving complex problems faster than traditional methods. By maximizing the quantum Fisher information matrix (QFIM), it optimizes parameters efficiently. The QEA leverages quantum parallelism for reduced computational complexity and is robust to noise, making it applicable in real-world scenarios. Additionally, it features a predictive capability for identifying incorrect outputs before they occur.


---
# Stress &ndash; mission possible! The STRESSmission game as a psychoeducational tool in coping with stress

## 压力-任务可能!压力任务游戏作为应对压力的心理教育工具

Link: https://www.researchsquare.com/article/rs-5269742/latest

Stress is an inherent and inextricable aspect of the live. When stress is excessive, it become chronic and has a negative impact on health. There is a need to disseminate knowledge about stress management techniques in order to reduce stress levels. In response to this demand, STRESmission, a psycho-educational tool was designed. It comprises task cards (grouped according to Aristel's triad of soma, psyche and polis), stress event cards (scored based on the Holmes and Rahe stress event scale), power and place cards, and a game board. We have tested if STRESmission (1) reduces perceived stress levels immediately and on a one-off basis, and whether it is an educational tool that helps in the acquisition of coping strategies, (2) can reduce stress levels in the long term, (3) is useful and attractive enough to encourage its use and therefore practical use of its benefits. A series of studies was conducted on groups of University students. We have found that STRESSmission decreased both subjective stress levels (psychological tests) and objective stress levels (lowering cortisol - CORT levels in the saliva). We concluded that the board game could be a stress-releasing and a learning tool to help cope with stressors.


---
# Chiseling the Graph: An Edge-Sculpting Method for Explaining Graph Neural Networks

## 凿图: 解释图神经网络的边缘雕刻方法

Link: https://www.researchsquare.com/article/rs-5414037/latest

Graph Neural Networks (GNNs) leverage the structural properties of the graph to inform the architecture of the neural network, thus achieving improved accuracy in graph learning tasks. However, like many neural network models, GNNs face a significant challenge with interpretability. To mitigate this issue, recent works have developed post-hoc instance-level explanation methods that focus on identifying minimal and sufficient subgraphs which strongly influence GNN predictions. Approaches that build on the graph information bottleneck principle (GIB) to quantify minimality and sufficiency have received particular attention, and have been used in several state-of-the-art explanation mechanisms. This work identifies several fundamental issues in such quantifications, particularly a signaling issue in the sufficiency, and a redundancy issue in the minimality quantifications. These may lead to explanations that do not accurately reflect the rationale behind GNN decisions. To overcome these challenges, we propose a new objective function and explainer architecture, dubbed the SculptEdgeX. The SculptEdgeX framework assesses the sufficiency of an input subgraph by generating an in-distribution supergraph and evaluating its prediction accuracy when processed by the GNN. This involves an initial densification process that adds edges to the input graph, followed by a selective edge removal step &mdash; called edge sculpting &mdash; to produce an in-distribution supergraph. To ensure the in-distribution property, we pre-train a calibrator network that parametrizes the underlying distribution of a given graph, hence enabling us to compare the distribution parameters with those of the original input distribution. We validate our method through extensive experiments on both synthetic and real-world datasets, demonstrating the effectiveness of SculptEdgeX in producing informative explanations.


---
# Semi-supervised attribute selection for partially labeled multiset-valued data&nbsp;

## 部分标记多集值数据的半监督属性选择

Link: https://www.researchsquare.com/article/rs-5298390/latest

In machine learning, when part of the data with labels needs to be pro- cessed, it is termed as a semi-supervised learning algorithm. Dataset with missing attribute values or labels is referred to as incomplete information sys- tem. Addressing incomplete information within a system poses a significant challenge, which can be effectively tackled through the application of rough set theory (R-theory). However, R-theory has its limits, it fails to consider the frequency of an attribute value and then can not well fit the distribu- tion of attribute values. If we consider partially labeled data and replace a missing attribute value with the multiset of all possible attribute values under the same attribute, then it leads to the emergence of partially labeled multiset-valued data. In semi-supervised learning algorithm, in order to save time and cost, a large number of redundant features need to be deleted. This paper studies semi-supervised attribute selection (ss-attribute selec- tion) for partially labeled multiset-valued data. Initially, a partially labeled multiset-valued decision information system (p-MSVDIS) is partitioned into two distinct systems: a labeled multiset-valued decision information system (l-MSVDIS) and an unlabeled multiset-valued decision information system (u-MSVDIS). Subsequently, using the indistinguishable relation, distinguish- able relation, and dependence function, two types of attribute subset impor- tance in a p-MSVDIS are defined. They are the weighted sum of l-MSVDIS and u-MSVDIS determined by the missing rate of labels and can be regarded as a uncertainty measurement (UM) of a p-MSVDIS. Next, an adaptive ss- attribute selection algorithm for a p-MSVDIS is introduced, leveraging the degrees of importance, allowing for automatic adaptation to diverse missing rates. Finally, 10 datasets are used for experiment and statistical analysis, the outcomes show the proposed algorithm has their advantage than some algorithms.


---
# A graph representation learning-based method for fault diagnosis of rotating machinery under time-varying speed conditions

## 基于图表示学习的旋转机械时变转速故障诊断方法

Link: https://www.researchsquare.com/article/rs-5428325/latest

The health of rotating machinery is critical to the quality and efficiency of the manufacturing process. However, the existing intelligent fault diagnosis methods are mostly carried out under constant speed conditions, which makes it difficult to adapt to the variability and complexity of equipment speed with time in actual industrial scenarios. Based on graph learning and self-attention mechanism, this study proposes a novel fault diagnosis method for rotating machinery under time-varying speed conditions. Node feature information is extracted from raw vibration signals in multiple directions to construct spatial graph data. Then the spatial graph is transformed into embedded data, and the spatiotemporal nested graph containing time-varying fault information is built. After that, the graph convolutional attention interactive parallel network model is established. Combining the advantages of the graph convolutional network and the self-attention mechanism, the fault information contained in the graph is deeply mined to promote the model to identify the fault types correctly. The superiority of the proposed method is verified by two time-varying speeds fault diagnosis test data. Compared with other deep learning methods, this method can still achieve optimal diagnostic results even in the case of insufficient training samples.


---
# Android Malware Detection using TripleGuard Neural Network and Hybrid Bird Mating with Battle Royal Optimization

## 使用TripleGuard神经网络和混合鸟交配与战斗皇家优化的Android恶意软件检测

Link: https://www.researchsquare.com/article/rs-5434673/latest

Android malware detection is a process that identifies and mitigates malicious software targeting Android operating systems, enhancing device security and reducing unauthorized access. However, it has potential disadvantages like false positives, advanced malware evasion, and the need for regular updates. To overcome this problem, this paper proposes a DL model with meticulous data preprocessing, eliminating missing records and standardizing numerical features through Z-score normalization. Feature extraction is then carried out to capture essential patterns within the pre-processed data. A unique hybrid optimization model called Hybrid Bird Mating with Battle Royal Optimization (HBMBRO), blending the Bird Mating Optimizer (BMO) and Battle Royale Algorithm (BRO), selects the most relevant features for optimal model performance. This study introduces a robust methodology for Android Malware detection, the "TripleGuard Neural Network" (TripleGuard NN), which amalgamates three specialized neural network components: The Optimized Autoencoder, Gated Recurrent Unit (GRU), and Artificial Neural Network (ANN). The synergy between the three neural network components offers versatile and robust Android Malware detection, with the Optimized Autoencoder identifying anomalies, the GRU analyzing sequential data for temporal Android Malware patterns, and the ANN delivering general Android Malware detection capabilities. The models within the TripleGuard NN are rigorously trained using MATLAB, and achieved an accuracy of 99.1%. This methodology promises a comprehensive and adaptable approach to Android Malware detection.


---
# Enhancing COVID-19 Classification in Chest X-ray Images through CNN-based Model Optimization Techniques

## 通过基于CNN的模型优化技术增强胸部x射线图像中的COVID-19分类

Link: https://www.researchsquare.com/article/rs-5404776/latest

This paper explores the enhancement of COVID-19 classification in chest X-ray images through the integration of advanced model optimization techniques. Utilizing a dataset compiled by researchers from Qatar University, Doha, Qatar, and the University of Dhaka, Bangladesh, the study employs a Convolutional Neural Network (CNN) architecture, specifically leveraging transfer learning with the VGG network. The dataset, named COVID-QU-Ex, contains 33,920 chest X-ray images, including 11,956 COVID-19 positive cases, 11,263 Non-COVID infections (Viral or Bacterial Pneumonia), and 10,701 Normal cases.&amp;nbsp;
The model incorporates Global Average Pooling (GAP) to reduce overfitting and improve generalization by replacing fully connected layers. Additionally, Spatial Transformer Networks (STN) are utilized to enhance the network's spatial invariance, allowing it to better handle variations in the input images. The outcomes demonstrate a significant improvement in classification accuracy, with the optimized model achieving superior performance compared to baseline approaches. This research highlights the potential of these techniques in improving the reliability and effectiveness of COVID-19 detection in medical imaging.


---
# Optimization of Matching Networks with Transfer Learning in Few-Shot Pneumonia Detection

## 基于迁移学习的匹配网络在少发肺炎检测中的优化

Link: https://www.researchsquare.com/article/rs-5372229/latest

Pneumonia remains the leading cause of death among children under five years of age, with approximately 1.6&amp;nbsp;million deaths annually. Early detection is the key to reducing child mortality. However, most of the traditional diagnostic methods depend on the availability of trained personnel and medical resources, which are particularly limited in low-resource settings. While machine learning has provided a promising technology for early detection of pneumonia, its uses often suffer from the problem of a scarcity of labeled data needed to train robust models. In this study, we propose an optimized model for one-shot pneumonia detection that incorporates transfer learning with the matching networks. The proposed model utilizes a pre-trained MobileNetV3 model for feature extraction to produce high-quality embeddings that Matching Networks can use to classify pneumonia instances using a minimal number of labeled examples. The experimental results revealed that the proposed model outperformed state-of-the-art traditional machine learning algorithms such as random forest and support vector machines with a high accuracy of 93.21%, precision of 93.34%, recall of 93.20%, and F1 score of 93.19%. The proposed model showed relatively competitive performance compared to CNNs by attaining AUCs of 1 for COVID cases, 0.98 for normal cases, and 0.98 for pneumonia. These results indicate that the proposed model effectively balances classification performance with data efficiency and, as such, can be effectively deployed in resource-constrained environments.


---
# Research on the Development of an Intelligent Prediction Model for Blood Pressure Variability During Hemodialysis

## 血液透析过程中血压变异性智能预测模型的建立研究

Link: https://www.researchsquare.com/article/rs-4997780/latest

Objective: Blood pressure fluctuations during dialysis, including intradialytic hypotension (IDH) and intradialytic hypertension (IDHTN), are coon complications among patients undergoing maintenance hemodialysis. Early prediction of IDH and IDHTN can help reduce the occurrence of these fluctuations. With the development of artificial intelligence, machine learning and deep learning models have become increasingly sophisticated in the field of hemodialysis. Utilizing machine learning to predict blood pressure fluctuations during dialysis has become a viable predictive method.
Methods: Our study included data from 67,524 hemodialysis sessions conducted at Ningbo No.2 Hospital and Xiangshan First People's Hospital from August 1, 2019, to Septeer 30, 2023. 47,053 sessions were used for model training and testing, while 20,471 sessions were used for external validation. We collected 45 features, including general information, vital signs, blood routine, blood biochemistry, and other relevant data. Data not meeting the inclusion criteria were excluded, and feature engineering was performed. The definitions of IDH and IDHTN were clarified, and 10 machine learning algorithms were used to build the models. For model development, the dialysis data were randomly split into a training set (80%) and a testing set (20%). To evaluate model performance, six metrics were used: accuracy, precision, recall, F1 score, ROC-AUC, and PR-AUC. Shapley Additive Explanation (SHAP) method was employed to identify eight key features, which were used to develop a clinical application utilizing the Streamlit framework.
Results: Statistical analysis showed that IDH occurred in 56.63% of hemodialysis sessions, while the incidence of IDHTN was 23.53%. Multiple machine learning models (e.g., CatBoost, RF) were developed to predict IDH and IDHTN events. XGBoost performed the best, achieving ROC-AUC scores of 0.89 for both IDH and IDHTN in internal validation, with PR-AUC scores of 0.95 and 0.78, and high accuracy, precision, recall, and F1 scores. The SHAP method identified pre-dialysis systolic blood pressure, BMI, and pre-dialysis mean arterial pressure as the top three important features. It has been translated into a convenient application for use in clinical settings.
Conclusion: Using machine learning models to predict IDH and IDHTN during hemodialysis is feasible and provides clinically reliable predictive performance. This can help timely implement interventions during hemodialysis to prevent problems, reduce blood pressure fluctuations during dialysis, and improve patient outcomes.


---
# Study on Learning Adaptability of STEM Students in the New College Entrance Examination Context

## 新高考背景下STEM学生学习适应性研究

Link: https://www.researchsquare.com/article/rs-5344859/latest

Over ten years of the New College Entrance Examination Reform, the flexible subject selection model has posed challenges to STEM (Science, Technology, Engineering, and Math) majors education in Chinese universities. The relaxation of subject requirements has led to diverse knowledge backgrounds among students, resulting in some lacking a solid foundation in these fields, which contributes to high failure rates and frequent major changes. This study reconstructs the dimensions of learning adaptability for STEM students, analyzing different adaptability types using data from 39 "985 Project" universities in China. Findings indicate two main types: low adaptability, characterized by low motivation and difficulty using intelligent tools, and high adaptability, which correlates with better adjustment but moderate interest in the major. Finally, this study offers targeted recommendations for improving the learning adaptability of STEM students.


---
# Dynamic Incremental Learning in Medical Imaging

## 动态增量学习在医学影像中的应用

Link: https://www.researchsquare.com/article/rs-5347560/latest

The foundational models such as YOLO, Faster R-CNN, and SSD have demonstrated substantial potential in computer vision, particularly in object detection. However, their application in medical imaging faces significant challenges due to the need for fine-grained recognition of small lesions and the continuous emergence of new disease types. Directly extending these models to medical image object detection is difficult, as they often struggle with generalizing to unseen radiological findings. Additionally, incremental learning in this domain is hampered by issues such as catastrophic forgetting and background shift. Our study proposes an incremental learning-based approach to enhance the performance and stability of medical image object detection models. This method addresses the unique challenges of medical imaging, including small lesion detection and low visual contrast, by combining dynamic weighted loss, augmented pseudo labels, and confidence score distillation. Incremental learning allows the model to adapt to new data without forgetting previously learned knowledge, which is essential given the limited size and evolving nature of medical imaging datasets. The main contributions of this study include the development of a dynamic weighted loss and network tailored for medical images, which improves detection accuracy. We also generate reliable pseudo-labels and apply data augmentation to address background shift and sample imbalance. Furthermore, we introduce an object confidence knowledge distillation method to enhance detection stability. Our approach demonstrates significant improvements in detection performance, showcasing its potential for practical clinical application and its implications for future medical image analysis and diagnosis.


---
# Research on coal and gas outburst prediction based on physical information neural network

## 基于物理信息神经网络的煤与瓦斯突出预测研究

Link: https://www.researchsquare.com/article/rs-5344764/latest

The advancement of AI technologies provides a base for predicting coal and gas outbursts from the mathematical perspective. To enhance prediction precision of coal and gas outbursts, this research proposes a method leveraging a physical information neural network to forecast outburst intensity. The primary factors influencing coal and gas outbursts, such as ground stress, coal firmness coefficient, mining depth, gas pressure, gas content, initial velocity of gas emission, and monotonic outburst characteristics, are integrated into the physical neural network model. This integration achieves a coupling of mechanistic and data-driven models for outburst prediction. Utilizing a typical dataset obtained from a mine, research findings demonstrate that a prediction model based on the physical information neural network surpasses RF, SVM, and BPNN models in terms of generalization capability and accuracy, significantly enhancing prediction accuracy even with limited sample data.


---
# Prediction of the endoleak risk after EVAR based on multimodal geometric characteristics before AAA surgery

## 基于AAA术前多模态几何特征的EVAR术后内漏风险预测

Link: https://www.researchsquare.com/article/rs-5269243/latest

Endovascular Aortic Aneurysm Repair (EVAR) can effectively prevent the continuous growth and rupture of Abdominal Aortic Aneurysms (AAA), but endoleak is a serious complication after the EVAR operation. Innovative techniques are presented in this work to solve this problem: (i) Local multi-dimensional anatomical features and global morphological features are conceptualized and extracted based on a statistical shape model (SSM), and (ii) Combined with morphological features and different machine learning (ML) methods, the occurrence of endoleak type I and II can be effectively predicted. The results show that the model using XGBoost achieves the best prediction performance for the occurrence of endoleak, with an AUC of 0.93 and accuracy of 0.85; further in type I and II endoleak predictions, the AUC achieves 0.90 and 0.80, and the accuracy of 0.81 and 0.74, respectively. Compared with the SOTA technologies, our ML-enabled multi-modal morphological feature extraction outperforms in predicting endoleak occurrence before surgery, avoiding excessive follow-up, and improving long-term management of patients in clinical practices.


---
# From Isolation to Integration: The Mental Health Journey of International Students in Turkey

## 从孤立到融合: 土耳其国际学生的心理健康之旅

Link: https://www.researchsquare.com/article/rs-5349000/latest

Objective This study aimed to examine the mental health status, coping strategies, perceived social support and barriers in mental health help seeking behaviour among first-year international students enrolled in Turkish language learning programs in Turkey.Participants: The study included undergraduate, graduate, and Ph.D. international students studying at Turkish language institutions.Methods A mixed-methods approach was utilized. Quantitative data were collected through surveys administered during the winter and spring terms of 2024, comprising the Warwick-Edinburgh Mental Wellbeing Scale, the Multidimensional Scale of Perceived Social Support, the Brief COPE Inventory, and a demographic questionnaire. Qualitative data were gathered through one-on-one and group interviews with 60 participants.Results Among the 381 participants from 48 countries, 45.93% reported optimal mental health, 45.14% exhibited moderate mental health, and 8.92% experienced low mental health. High levels of perceived social support from family and friends were significant predictors of mental well-being. Thematic analysis of the qualitative data identified three main themes: barriers to mental health help-seeking, perceived social support from sources beyond family and friends, and coping strategies used by students. Institutional and cultural barriers, including limited access to counseling and cultural stigma, were highlighted as critical challenges impacting mental health.Conclusions The findings reveal that while perceived social support significantly enhances mental well-being, institutional and cultural barriers severely hinder help-seeking behaviors among international students. These results underscore the urgent need for culturally competent counseling services and more accessible mental health resources in universities to support the unique needs of this student population.


---
# optRF: Optimising random forest stability by determining the optimal number of trees

## optRF: 通过确定树的最佳数量来优化随机森林的稳定性

Link: https://www.researchsquare.com/article/rs-5432153/latest

Machine learning is frequently used to make decisions based on big data. Among these techniques, random forest is particularly prominent in genomic research, where it is used for selecting the best individuals within a test population or for identifying the most important genomic markers. Although random forest is known to have many advantages, one aspect that is often overseen is that it is a non-deterministic method that can produce different models using the same input data. This can have severe consequences on decision-making processes. In this study, we introduce a method to quantify the impact of non-determinism on predictions, variable importance estimates, and the selection process. Our findings demonstrate that increasing the number of trees in random forests enhances the stability in a non-linear way while computation time increases linearly. Consequently, we conclude that there exists an optimal number of trees for any given data set that maximises the stability without unnecessarily extending the computation time. Based on these results, we have developed the R package optRF which models the relationship between the number of trees and the stability of random forest, providing recommendations for the optimal number of trees for any given data set.


---
# Exploring the English Language Needs of Undergraduate Students in Mozambique

## 莫桑比克本科生英语语言需求探究

Link: https://www.researchsquare.com/article/rs-5285304/latest

Needs Analysis is the backbone of curriculum design, a crucial aspect to consider when developing any language programme. This research aimed to identify the English language needs of undergraduate students in Mozambican universities. The study, which focused on a learning-centred approach, investigated the students&amp;rsquo; English language needs from their perspectives and those of lecturers and employers. It employed a comprehensive mixed-methods approach involving the participation of students, English language lecturers, and employers. Questionnaires were used to collect data from 27 students, and semi-structured interviews were conducted to gather data from five lecturers and one employer, allowing for a deeper understanding of their perspectives and experiences. The findings revealed that most students have low English language proficiency despite English being the language of instruction, and these have practical implications for curriculum design. The results underscore the pressing need for English language programmes to prioritise content and activities that are strictly related to the students&amp;rsquo; field of study and aimed at developing professional communication skills, focusing on speaking, reading, and writing. Given the students&amp;rsquo; limited English use outside class, the study suggests an integrated approach of General English (GE) and English for Specific Purposes (ESP) instead of English for Academic Purposes (EAP).


---
# Portability of Short Term Wind Power Forecasting

## 短期风电功率预测的可移植性

Link: https://www.researchsquare.com/article/rs-5311042/latest

Wind power forecasting (WPF) plays an increasingly important role in integrating wind power into electricity systems. The porta-bility of state-of-the-art WPF methods is assessed in this paper; the goal is to explore the influence of model hyperparameter configuration on forecasting performance. The overall aim is to expand understanding of WPF methods in order to improve the reliability and competitiveness of wind energy generation technologies.&amp;nbsp;
The performance of two hybrid decomposition-based WPF methods are evaluated and compared, Variational Mode Decomposition &amp;amp; Feed Forward Neural Network (VMD-FFNN) and Ensemble Empirical Mode Decomposition &amp;amp; Feed Forward Neural Network (EEMD-FFNN). Supervisory Control and Data Acquisition (SCADA) data from wind farms in Ireland and the UK is utilised. The robustness and portability of the WPF methods when applied to different datasets is examined.&amp;nbsp;
Both WPF methods produce robust and accurate forecasts across different datasets however, forecasts produced using low-resolution data are superior to high-resolution data forecasts. In the portability assessment, the forecasting performance is sensitive to two of the four model hyperparameters examined.


---
# Artificial neural network modeling of dye adsorption kinetics and thermodynamics with magnetic nanoparticle-activated carbon from Allium cepa peels

## 洋葱皮磁性纳米活性炭吸附染料动力学和热力学的人工神经网络模型

Link: https://www.researchsquare.com/article/rs-5412619/latest

The study utilizes novel onion peel (Allium cepa) activated carbon biomass impregnated with magnetic nanoparticles (OMNPs) for the removal of toxic Methylene Blue (MB) and Congo Red (CR) dyes. The SEM analysis reveals the morphological structures, while XRD indicates an amorphous nature. FTIR confirms the functional groups present, TGA demonstrates thermal stability, and the pore size is measured at 2.193 nm. OMNPs reveal a higher sorption rate for both MB and CR dye, with a clearance rate of 96.25% and 93.11%. The thermodynamic reaction is believed to be an exothermic reaction and the process is spontaneous. The simulation investigations indicate that Freundlich is the best-proven isotherm (R2 for MB&amp;thinsp;=&amp;thinsp;0.9945 and CR dyes&amp;thinsp;=&amp;thinsp;0.9878), pseudo-second-order kinetics yields chemisorption and ANN is assessed for its fitness (R for MB&amp;thinsp;=&amp;thinsp;0.993 and CR dyes&amp;thinsp;=&amp;thinsp;0.984). This new composite material demonstrated remarkable dye removal efficiency, and ANN models accurately predicted adsorption performance.


---
# Defect Passivation of Hafnium Oxide Ferroelectric Tunnel Junction Using Forming Gas Annealing for Neuromorphic Applications

## 使用形成气体退火对氧化铪铁电隧道结进行缺陷钝化，用于神经形态应用

Link: https://www.researchsquare.com/article/rs-5216270/latest

Forming gas annealing (FGA) is applied to HfOx ferroelectric tunnel junction (FTJ) synaptic devices to passivate defects and reduce trap-assisted-tunneling (TAT). Without FGA, TAT caused by defects in metal&amp;ndash;ferroelectric&amp;ndash;insulator&amp;ndash;semiconductor (MFIS) FTJ stack dominates the conduction mechanism in FTJs and results in no memory window (MW). The reduction of defects or TAT after FGA reveals the effect of polarization switching on the FTJ performance. Consequently, linear/symmetric potentiation and depression (P/D) characteristics of FTJ after FGA with stable repeatability are obtained. Owing to the FGA-induced linearity and symmetricity of P/D, a learning accuracy of approximately 90% is achieved via pattern recognition simulations utilizing HfOx FTJ crossbar.


---
# Multi-user Watermarking Based on Paralleled Invertible Neural Networks

## 基于并行可逆神经网络的多用户水印

Link: https://www.researchsquare.com/article/rs-5429669/latest

With the rapid development of artificial intelligence technology, more and more deep-faked audios have emerged in cyberspace, leading to an urgent need for detecting and tracing deep fake audios. Watermarking provides an active method for detecting deep-faked audios, and especially through multi-bit watermarking technology. Multiple watermarks can provide stronger protection and tracking capabilities in various scenarios. Especially users can upload audios that incorporate with both personal watermarks of lyricist and composer and platform watermarks, ensuring a better monitor the dissemination and usage of audio. The current methods for embedding multi-user watermarks require training multiple networks, and these networks may interfere with each other during the training process. To address this issue, we propose an audio watermarking technique based on Paralleled Invertible Neural Networks (PINN), which allows splitting a single network into multiple networks for multi-user watermark embedding while training only one network. Specifically, we design a parallel-structured invertible neural network. This reversible structure is flexible, allowing the network to be split into multiple sub-networks for watermark rewriting or multi-user watermark embedding, with these embedded watermarks being independent of each other. By embedding multiple watermarks in the carrier, deep-faked audio can be identified and its source traced. Each watermark can be rewritten through a small-scale sub-network without affecting the others, making this approach more convenient in practical applications. Experimental results shows that the proposed method can effectively authenticate audios and has strong resistance to common distortions. Furthermore, partial rewriting experiments demonstrate the flexibility of the proposed method.


---
# Hysteretic Curve Characteristics in Rectangular Shear Walls Predicted by Machine Learning

## 基于机器学习的矩形剪力墙滞回曲线特征预测

Link: https://www.researchsquare.com/article/rs-5308377/latest

Rectangular reinforced concrete (RC) shear walls are crucial for seismic resistance in high-rise buildings. Characteristic points on the skeleton curve from pseudo-static tests are key for evaluating seismic performance.    Traditional models struggle with the high-dimensional, nonlinear relationships between these points and component dimensions. An interpretable machine learning model (IEG-ML) was proposed for predicting these feature points. IEG-ML aligns with empirical trends from extensive experiments and is explainable via explicit formulas. Trained on a self-built dataset of 184 samples, IEG-ML accuracy and efficiency are enhanced using a population optimization algorithm. The model identifies the importance of feature points and component factors, providing a dominant explicable formula. Results show IEG-ML high accuracy and efficiency, particularly with a backpropagation network optimized by the dung beetle algorithm (DBO), making it a robust tool for seismic evaluation.


---
# Tensor Subspace Learning andFolded-concave Function Regularizationfor Hyperspectral Anomaly Detection

## 用于高光谱异常检测的张量子空间学习和折叠凹函数正则化

Link: https://www.researchsquare.com/article/rs-5236790/latest

Hyperspectral anomaly detection focuses on identifying and localizing the anomalous targets in remote sensing. The complex scenarios in hyperspectral imagesmake it more difficult to effectively distinguish anomalous objects from background data, especially in noisy environments. Furthermore, matrix factorizationoften unfolds hyperspectral cubic data into two-dimension form, but this causesthe structural knowledge to be lost. To surmount the above disadvantages, weproposes a tensor subspace-based learning strategy with folded-concave regularization for hyperspectral anomaly detection. First, hyperspectral data undergoesinitial preprocessing through band selection and robust tensor principal component analysis to generate a dictionary representing the background. Then,a tensor subspace learning approach aims to factorize hyperspectral data intothe background and anomaly tensors, in which the folded-concave function isleveraged to minimize minor components for denoising. Next, lF,1 norm on tensor is used to extract abnormal information from hyperspectral data. Finally,comprehensive experiments on several real datasets show that the proposed algorithm performs better than the comparative benchmark methods in detection performance.


---
# A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction

## 数学误解的基准: 通过AI支持的教学弥合中学代数的差距

Link: https://www.researchsquare.com/article/rs-5306778/latest

This study introduces an evaluation benchmark for middle school algebra tobe used in artificial intelligence(AI) based educational platforms. The goal is tosupport the design of AI systems that can enhance learners&rsquo; conceptual under-standing of algebra by taking into account learners&rsquo; current level of algebracomprehension. The dataset comprises of 55 algebra misconceptions, commonerrors and 220 diagnostic examples identified in prior peer-reviewed studies. Weprovide an example application using GPT-4, observing a range of precisionand recall scores depending on the topic and experimental setup reaching 83.9%when including educators&rsquo; feedback and restricting it by topic. We found thattopics such as ratios and proportions prove as difficult for GTP-4 as they arefor students. We included a human assessment of GPT-4 results and feedbackfrom five middle school math educators on the clarity and occurrence of the mis-conceptions in the dataset and the potential use of AI in conjunction with thedataset. Most educators (80% or more) indicated that they encounter these mis-conceptions among their students, suggesting the dataset&rsquo;s relevance to teachingmiddle school algebra. Despite varied familiarity with AI tools, four out of fiveeducators expressed interest in using the dataset with AI to diagnose students&rsquo;misconceptions or train teachers. The results emphasize the importance of topic-constrained testing, the need for multimodal approaches, and the relevance ofhuman expertise in gaining practical insights when using AI for human learning.

