# Rethinking machine unlearning for large language models

## 重新思考大型语言模型的机器学习

Link: https://www.nature.com/articles/s42256-025-00985-0

**Authors:** Yang Liu

<p>Nature Machine Intelligence, Published online: 17 February 2025; <a href="https://www.nature.com/articles/s42256-025-00985-0">doi:10.1038/s42256-025-00985-0</a></p>Machine unlearning techniques remove undesirable data and associated model capabilities while preserving essential knowledge, so that machine learning models can be updated without costly retraining. Liu et al. review recent advances and opportunities in machine unlearning in LLMs, revisiting methodologies and overlooked principles for future improvements and exploring emerging applications in copyright and privacy safeguards and in reducing sociotechnical harms.


---
# Improved Solubility Predictions in scCO2 Using Thermodynamics-Informed Machine Learning Models

## 使用热力学机器学习模型改进scCO2中的溶解度预测

Link: https://dx.doi.org/10.26434/chemrxiv-2025-17w5j?rft_dat=source%3Ddrss

**Authors:** Michael, Kiselev

Accurate solubility prediction in supercritical carbon dioxide (scCO2) is crucial for optimizing experimental design by eliminating unnecessary and costly trials at an early stage, thereby streamlining the workflow. A comprehensive solubility database containing 31975 records has been compiled, providing a foundation for developing predictive models applicable to a diverse class of chemical compounds, with a particular focus on drug-like substances. In this study, we propose a Domain-Aware Machine Learning approach that incorporates thermodynamic properties governing phase transitions to solubility predictions in scCO2. Predictive models were developed using the CatBoost algorithm and a graph-based architecture employing directed message passing to identify the most effective approach. Furthermore, auxiliary properties of the solute, including melting point, critical parameters, enthalpy of vaporization, and Gibbs free energy of solvation, were predicted as part of this work. The findings underscore the efficacy of incorporating domain-specific thermodynamic features to enhance the predictive accuracy of scCO2 solubility modeling. The interpretation and the applicability domain assessment have confirmed the qualitative selection of the employed descriptors, demonstrating their ability to generalize to unique compounds that fall outside the defined domain.


---
# A Deep Learning-Augmented Density Functional
Framework for Reaction Modeling with Chemical
Accuracy

## 一种深度学习增强的密度泛函
化学反应建模框架
准确度

Link: https://dx.doi.org/10.26434/chemrxiv-2024-vx4tb-v3?rft_dat=source%3Ddrss

**Authors:** Han, Wang

Accurate prediction of reaction energetics remains a fundamental challenge in computational chemistry, as conventional density functional theory (DFT) often fails to reconcile high accuracy with computational effi ciency. Here, we introduce Deep post-Hartree-Fock (DeePHF), a machine learning framework that synergistically integrates neural networks with quantum mechanical descriptors to achieve CCSD(T)-level precision while retaining the efficiency of DFT. By establishing a direct mapping between the eigenvalues of local density matrices and high-level correlation energies, DeePHF circumvents the traditional accuracy-scalability trade-off . Trained on a limited dataset of small-molecule reactions, our method demonstrates unprecedented performance across multiple benchmark
datasets, exhibiting exceptional transferability. In fact, its accuracy even surpasses that of advanced double-hybrid functionals, all while maintaining O(N^3) scaling. DeePHF offers a promising pathway to bridge the gap between high-level quantum chemistry methods and the practical demands for scalable, accurate models in computational chemistry, and with further refi nement, it is poised to make signifi cant contributions to the advancement of chemical reaction modeling.


---
# From Data to Chemistry: Revealing Causality and Reaction Coordinates through Interpretable Machine Learning in Supramolecular Transition Metal Catalysis

## 从数据到化学: 通过超分子过渡金属催化中的可解释机器学习揭示因果关系和反应坐标

Link: https://dx.doi.org/10.26434/chemrxiv-2024-nd20j-v2?rft_dat=source%3Ddrss

**Authors:** Thomas S., Hofer

Supramolecular transition-metal catalysts with tailored reaction environments allow for the usage of abundant 3d metals as catalytic centres, leading to more sustainable chemical processes. However, such catalysts are large and flexible systems with intricate interactions, resulting in complex reaction coordinates. To capture their dynamic nature, we developed a broadly applicable, high-throughput workflow, leveraging quantum mechanics/molecular mechanics molecular dynamics (QM/MM MD) in explicit solvent, to investigate a Cu(I)-calix[8]arene catalysed C-N coupling reaction. The system complexity and high amount of data generated from sampling the reaction require automated analyses. To identify and quantify the reaction coordinate from noisy simulation trajectories, we applied interpretable machine learning techniques (Lasso, Random Forest, Logistic Regression) in a consensus model, alongside dimensionality reduction methods (PCA, LDA, tICA). Leveraging a Granger Causality model, we go beyond the traditional view of a reaction coordinate, by defining it as a sequence of molecular motions that led up to the reaction.


---
# Evaluation of pyroptosis-associated genes in endometrial cancer based on the 101- combination machine learning framework and multi-omics data

## 基于101组合机器学习框架和多组学数据的子宫内膜癌焦亡相关基因评估

Link: https://www.researchsquare.com/article/rs-6016108/latest

Background Endometrial cancer (EC) represents a common malignancy within gynecological cancers, characterized by a notably high mortality rate. The absence of reliable prognostic biomarkers significantly impairs the effectiveness of predictive, preventive, and personalized medicine (PPPM/3PM) strategies. Pyroptosis, a distinct form of programmed cell death, has been closely linked to anti-cancer immune responses. Nonetheless, the precise role of pyroptosis in the context of EC remains elusive.Methods Pyroptosis-associated genes (PAGs) were screened in Msigdb. We used consensus clustering to classify PAGs from TCGA-UCEC into two clusters, and examined their characteristics. The Seurat package was employed to analyze significant PAGs in EC single-cell data. The mime package was utilized to screen suitable machine learning approaches and build models. A nomogram was constructed to validate the model's performance. Additionally, CIBERSORT was used to evaluate immune infiltration results, and TIDE scores from the TCIA database were applied to assess EC patients' responses to immune checkpoint therapy. Subsequently, we performed PAG-related pathway analysis in EC patients with or without response to PD-1 therapy using the CellChat module in Seurat. Finally, the OncoPredict package was used to predict drug sensitivity in EC patients.Results A consensus PAGs ("CASP3", "CHMP3", "CYCS", "GSDMD", "IRF1", and "NOD1") was constructed based on a 101-combination machine learning computational framework, demonstrating outstanding performance in predicting prognosis and clinical translation. We observed distinct biological functions and immune cell infiltration in the tumor microenvironment between the high- and low-risk groups. Notably, the immunophenoscore (IPS) score showed a significant difference between risk subgroups, suggesting a negative response to PD-1 in the high-risk group. Potential drugs targeting specific risk subgroups were also identified.Conclusion Our study constructed an PAGs that can serve as a promising tool for prognosis prediction, targeted prevention, and personalized medicine in EC.


---
# PM 2.5 Concentration 7-days Prediction in the Beijing-Tianjin-Hebei Region Using a Novel Stacking Framework

## 基于新型堆叠框架的京津冀地区PM 2.5浓度7天预测

Link: https://www.researchsquare.com/article/rs-6007740/latest

High-precision prediction of near-surface PM2.5 concentration is an significant theoretical prerequisite for effective monitoring and prevention of air pollution, and also provides guiding suggestions for PM2.5 health risk prevention and control. In view of the fact that the control variables of existing PM2.5 prediction models are mostly dependent on the influencing factors at the near-surface, and it is often difficult to fully explore the continuous spatio-temporal characteristics in PM2.5. In this study, MODIS remote sensing-derived Aerosol Optical Depth (AOD) daily data, atmospheric environment ground monitoring station data and meteorological factors are introduced to identify strong correlation factors. A highly robust seven-day prediction model for PM2.5 concentration is constructed based on the Stacking algorithm combined with various machine learning methods to improve the generalisation ability of the model; the estimation ability of the integrated model is compared and analyzed with LSTM, RF and KNN models. The results demonstrated that the PM2.5 prediction results on the basis of this integrated RF-LSTM-Stacking model exhibited a better fit, with R&amp;sup2;, RMSE, and MAE values of 0.95, 7.74 &amp;micro;g/m&amp;sup3;, and 6.08 &amp;micro;g/m&amp;sup3;, respectively. This approach improved the prediction accuracy by approximately 17% compared to a single machine learning model. Based on this study, it was evident that the LSTM-RF model, integrated with the fusion-based Stacking algorithm, significantly enhanced the PM2.5 prediction accuracy and provided an effective reference for PM2.5 predicting and early warning monitoring.


---
# Enhancing English Proficiency Through an Intelligent Personal Assistant

## 通过智能个人助理提高英语水平

Link: https://www.researchsquare.com/article/rs-6005908/latest

This relative review investigates the coordination of artificial intelligence controlled advances in improving English language abilities, explicitly focusing on elocution and scholastic capability. It centers around the utilization of computer based intelligence driven devices like the Google Read So anyone might hear application, in mix with the Concentrated on Without holding back technique, to further develop jargon maintenance and elocution precision. The examination likewise explores the utilization of voice partners in refining scholastic English, featuring their true capacity for supporting language learning. The review exhibits the adequacy of Stowed away Markov Models (Gee) in man-made intelligence based discourse acknowledgment frameworks, which offer better outcomes in jargon maintenance thought about than conventional phonetic methodologies. This proposes that computer based intelligence driven advances have huge commitment for long haul language procurement. Besides, the use of Profound Brain Organizations (DNNs) is exhibited to upgrade both scholarly jargon and syntactic accuracy, helping students in conventional scholastic settings. Generally, the review highlights the worth of computer based intelligence in propelling elocution and scholastic language abilities, giving important experiences to language teachers and students the same.


---
# The Role of Astrocytes in the Temporoammonic Pathway: Masticatory Behavior as a Neuroprotective Strategy Against Age-Related Cognitive Decline

## 星形胶质细胞在颞氨途径中的作用: 咀嚼行为作为对抗年龄相关认知衰退的神经保护策略

Link: https://www.researchsquare.com/article/rs-6025628/latest

Astrocytes undergo phenotypic changes with aging, contributing to neurodegenerative diseases and cognitive impairments in later life. The temporoammonic (TA) pathway terminates at the stratum lacunosum-moleculare (SLM) of the CA1 region, where astrocytic support is crucial for synaptic plasticity and information processing related to spatial learning and memory. This study tested the hypothesis that age-related morphological changes in astrocytes of the SLM affect cognitive performance and we explored whether masticatory activity modulates these changes. Young (6 months) and aged (18 months) female Swiss albino mice were subjected to three distinct masticatory regimens: a hard diet (HD), HD followed by a soft diet (HD/SD), or HD followed by SD and a return to HD (HD/SD/HD). Cognitive performance was assessed using the Morris Water Maze (MWM), with learning rates calculated from escape latencies throughout five days of trials. After behavioral testing, the mice were culled and immunohistochemical analysis of glial fibrillary acidic protein (GFAP) expression was performed. 3D reconstructions of astrocytes within the SLM were generated and analyzed. Hierarchical clustering identified distinct astrocyte morphotypes, revealing a significant age-related shift from high-complexity astrocytes (AST1) toward lower-complexity subtypes (AST2 and AST3. The results demonstrate that aging reduces astrocytic complexity, especially in the dorsal CA1 region, which correlated with impaired spatial learning and memory. Notably, mice on the HD/SD/HD regimen exhibited partial recovery of cognitive function and astrocytic morphology, suggesting a potential rehabilitation effect from masticatory activity. Statistical analysis confirmed significant differences in cognitive performance and astrocytic complexity across age groups and dietary regimens (p&amp;thinsp;&amp;lt;&amp;thinsp;0.01). These findings highlight that the morphological changes in astrocytes within the SLM may contribute to age-related cognitive decline. Overall, maintaining proper mastication may be an effective approach to maintain astrocytic integrity during aging and preserve hippocampus-dependent cognitive function, particularly in older individuals.


---
# InfEHR: Resolving Clinical Uncertainty through Deep Geometric Learning on Electronic Health Records

## InfEHR: 通过电子健康记录的深度几何学习解决临床不确定性

Link: https://www.researchsquare.com/article/rs-5953885/latest

Electronic health records (EHRs) contain multimodal data that can inform diagnostic and prognostic clinical decisions but are often unsuited for advanced machine learning (ML)&amp;ndash;based patient-specific analyses. ML models and clinical heuristics learn generalizable relationships from predefined factors, yet many patients may not benefit if those factors are missing in the EHR or differ&amp;mdash;however subtly&amp;mdash;from typical training populations. Clinical heuristics are limited to low complexity, often linear, relationships and patterns between clinical variables. ML approaches in EHRs significantly expand pattern sophistication but require large, labeled datasets, which are often unattainable especially in low prevalence diseases and are limited by sources of random and non-random variation in EHRs. Deep learning (DL), in contrast with ML and clinical heuristics, learns features without predefinition but requires even greater label access for predictions. While DL can construct unsupervised EHR representations, the patterns and characteristics of less prevalent examples are poorly resolved, and downstream clinical applications still require labels. We present Inf-EHR, a framework to automatically compute clinical likelihoods from whole EHRs of patients from diverse clinical settings without need of large volumes of labeled training data. We apply deep geometric learning to EHRs through a novel procedure that converts whole EHRs to temporal graphs. These graphs naturally capture phenotypic temporal dynamics leading to unbiased representations. Using only a few labeled examples, InfEHR computes and automatically revises likelihoods leading to highly performant inferences especially in low prevalence diseases which are often the most clinically ambiguous. To demonstrate utility, we use EHRs from the Mount Sinai Health System and The University of California, Irvine Medical Center and test its performance compared to physician-provided clinical heuristics across two diseases with no clinical or epidemiological overlap: a rare disease (neonatal culture-negative sepsis) with prevalence of 2% in neonates, and a more common disease (adult post-operative acute kidney injury) with prevalence of 22%. We show that Inf-EHR is superior to existing clinical heuristics both for culture-negative sepsis (sensitivity: 0.65 vs .041, specificity: 0.99 vs.0.98) and post-operative acute kidney injury (sensitivity: 0.72 vs 0.20, specificity: 0.91 vs 0.97). We present the first application of geometric deep learning in EHRs that can be used in real world clinical settings at scale, for improving phenotype identification and resolving clinical uncertainty.


---
# What do we actually want to experience? A computational metric for assessing reward values

## 我们实际上想要体验什么？用于评估奖励值的计算度量

Link: https://www.researchsquare.com/article/rs-5875678/latest

People&amp;rsquo;s motivation to have different experiences is predicated on how much they find those experiences rewarding or not, and these reward values are not always fully accessible to our consciousness. In two studies, we demonstrate that using a combination of reinforcement learning (RL) paradigms and computational modeling, we can measure computationally inferred reward values (cRV) of experiences, which do not rely on conscious self-report. Consistent with motivational reward theory, convenience samples of participants exhibited higher cRV (greater reward value of that experience) to viewing positive vs. negative images (subject pool; Study 1) and to viewing more vs. less attractive faces (online sample; Study 2). Further, these cRVs were sensitive to context (familiarity vs. novelty of images, Study 1) and to individual differences (attraction preference, Study 2). Lastly, although cRVs were mildly correlated with explicit self-report values, which demonstrates their validity, they were better predictors of behavior than were the explicit values, which suggests that cRVs are capturing reward processes that are not represented by explicit value judgments. This method of measuring cRV holds great promise for understanding the motivation driving people&amp;rsquo;s choices of a variety of experiences across a wide array of fields of study.


---
# Single and Multi-Objective Optimal Power Flow Based on JAYA Algorithm with Teaching-Learning Based Optimization

## 基于教学优化的JAYA算法的单多目标最优潮流

Link: https://www.researchsquare.com/article/rs-6017780/latest

This paper deals with the Optimal Power Flow (OPF) in an IEEE standard bus (30-bus) power system and presents a multi-objective optimization approach to minimize generation costs, active power losses and voltage deviations. The OPF problem is of critical importance for the reliable, efficient and economical operation of power systems. However, the solution to this problem is complex due to its nonlinear nature and large number of constraints. Conventional methods are often insufficient to overcome the nonlinear challenges inherent in OPF. In addressing these challenges, this study employs metaheuristic algorithms, namely Teaching-Learning Based Optimisation (TLBO), JAYA and hybrid TLBO-JAYA, to enhance the efficiency and convergence speed of the solution process. To manage the multi-objective nature of the problem, Pareto optimisation is utilised to identify a solution set that balances conflicting objectives. The outcomes demonstrate that the hybrid TLBO-JAYA algorithm offers a balanced enhancement in terms of generation cost, active power loss and voltage stability, thereby providing a versatile and efficient solution framework for contemporary power systems. These findings underscore the potential of hybrid metaheuristic algorithms in addressing complex multi-objective optimisation problems in power systems.


---
# Machine Learning for Experimental Design of Ultrafast Electron Diffraction

## 用于超快电子衍射实验设计的机器学习

Link: https://www.researchsquare.com/article/rs-5966320/latest

Ultrafast Electron Diffraction (UED) experiments can generate several gigabytes of data that must be manually processed and analyzed to extract insights into materials behavior at ultrafast timescales. The lack of real-time data analysis precents in situ tuning of experimental parameters toward desirable outcomes or away from sample damage. Here, we demonstrate that machine learning methods based on Convolutional Neural Networks (CNN) trained on synthetic UED data can perform real-time analysis of diffraction data to resolve dynamical processes in the material and identify signs of material damage. Convolutional Variational Autoencoder (VAE) models showed the ability to track structural phase transformation in a model material system through the time trajectory of UED images in the low-dimensional latent space. By mapping experimental conditions to distinct regions of the latent space, such models enable real-time steering of experimental parameters towards conditions that realize phase transformations or other desirable outcomes. These examples show the ability of machine learning (ML) to design self-correcting diffraction experiments to optimize the use of large-scale user facilities. These methods can readily be extended to other experimental characterization methods, including microscopy and spectroscopy.


---
# Evaluating Placement Quality in Allied Health: Rasch-Based Validation of the Clinical Placement Quality Survey - Student

## 评估专职医疗的安置质量: 基于Rasch的临床安置质量调查的验证-学生

Link: https://www.researchsquare.com/article/rs-6019236/latest

The Clinical Placement Quality Survey &amp;ndash; Student (CPQS-S) was developed to capture allied health students' perceptions of placement quality, in alignment with the Best Practice Clinical Learning Environment framework. This study aimed to validate the CPQS-S using Rasch Analysis across multiple allied health disciplines, encompassing students from Clinical Exercise Physiology, Exercise Science, Nutrition and Dietetics, Occupational Therapy, Physiotherapy, Rehabilitation Counselling, Social Work, and Speech Pathology programs. Data collected from 933 students were divided into development and validation samples. The CPQS-S was confirmed to be measuring a unidimensional construct and Rasch Analysis showed that items demonstrated strong fit statistics and separation reliability, affirming the tool&amp;rsquo;s psychometric robustness in measuring student perceptions. These findings support the CPQS-S as a reliable, data-driven instrument that consistently assesses placement experiences across diverse settings. The validated structure underscores the CPQS-S as a reliable instrument for assessing and benchmarking placement quality, providing educators with actionable data to enhance clinical learning environments. More broadly, these findings contribute to the advancement of work-integrated learning research by offering a validated tool to inform educational interventions and quality improvement initiatives in health professions education.


---
# Differential Item Functioning in Preterm Infant Oral Feeding Readiness Assessment Scale in Neonates with critical conditions in NICU based on A Machine Learning Approach

## 基于机器学习方法的NICU危重新生儿早产儿经口喂养准备评估量表中的差异项目功能

Link: https://www.researchsquare.com/article/rs-5899017/latest

Aim This study utilized the Rasch Model to test the psychometric properties of the Preterm Infant Oral Feeding Readiness Assessment Scale (PIOFRA) in neonates with critical conditions in neonate intensive care unit (NICU).Methods A total of 1419 infants were involved. Rasch Model (RM) was used to test the reliability and validity of the PIOFRA. The GPCMlasso Model was used to examine the differential item functioning (DIF).Results  The involved samples responded to PIOFRA according to Rasch Model pattern. Disordered category function was found in PIOFRA. Besides, we identified one extra component in PIOFRA concerning the awake status. The DIF analysis revealed that gestational age and born weight only produced limit impact on neonates&amp;rsquo; performance.Conclusions our result supports that FIOFRA is applicable for depicting the neurobehavior in high-risk infants with critical conditions in NICU. One drawback is found that the rating scale may jeopardize the measurement precision, further rating calibration is needed. Items in PIOFRA are displaying different DIF in corresponding subsamples (e.g. gestational age, born weight, oral feeding status). Future studies should focus on validating these findings in a more balanced sample which this study fails to achieve.


---
# Real-Time Financial Fraud Detection Using Adaptive Graph Neural Networks and Federated Learning

## 基于自适应图神经网络和联邦学习的实时金融欺诈检测

Link: https://www.researchsquare.com/article/rs-6026136/latest

Detecting financial fraud in real time is an ongoing challenge due to the ever-evolving nature of fraudulent activities. Conventional fraud detection systems rely heavily on static machine learning models, which often struggle to adapt to emerging fraud patterns. Additionally, data privacy regulations and institutional constraints limit collaborative fraud detection efforts, as financial organizations are often unable to share sensitive transactional data. In this research, we introduce a real-time fraud detection framework that combines Adaptive Graph Neural Networks (GNNs) and Federated Learning (FL) to overcome these limitations. The GNN component dynamically models relationships within financial transactions, allowing the system to detect suspicious patterns as they emerge rather than relying on historical fraud markers. Meanwhile, federated learning enables multiple financial institutions to collaboratively train fraud detection models without directly sharing customer data, thus addressing privacy concerns. To enhance explainability and regulatory compliance, the proposed system integrates Explainable AI (XAI) methods, making fraud detection decisions more transparent. Experimental evaluations on benchmark financial datasets and real-world transactional data reveal that our approach improves fraud detection accuracy by 15&amp;ndash;30% while reducing false positives compared to existing machine learning-based solutions. The findings highlight the potential of GNNs and FL in advancing fraud prevention strategies while maintaining data security and interpretability, making it a promising alternative to traditional fraud detection mechanisms.


---
# Sensitivity of Brain Injury Models to Head Pose, Sample Rate and Interpolation

## 脑损伤模型对头部姿势，采样率和插值的敏感性

Link: https://www.researchsquare.com/article/rs-6029253/latest

Purpose: This study investigates how the lower sampling rates and interpolation methods typical of photogrammetric processes for head impact kinematics measurement can affect the accuracy of brain strain predictions, a critical metric in understanding traumatic brain injury (TBI) and mild traumatic brain injury (mTBI).&amp;nbsp;
Methods: A dataset of head impact kinematics was generated using emulated instrumented mouthguard (iMG) data sampled at 1000 Hz. These data were converted to head pose measurements and downsampled to rates reflective of video-based systems (500, 100 and 50 Hz). Interpolation schemes (linear, cubic spline and PCHIP) were applied to upsample the downsampled data back to 1000 Hz before recovering angular velocity. Brain strain, measured as the 95th percentile of Maximum Principal Strain (MPS95), was predicted using both a traditional finite element head model (the EdiFEHM) and a convolutional neural network (CNN).&amp;nbsp;
Results: Interpolation marginally improved the accuracy of strain predictions at lower sample rates, with PCHIP performing best among the methods tested. However, even with interpolation, over 25% of predictions at 50 Hz deviated by more than 10% from the 1000 Hz reference. The CNN displayed heightened sensitivity to linear interpolation compared to the EdiFEHM, due to its inability to account for the spikes present in the piecewise continuous angular velocity profiles.&amp;nbsp;
Conclusion: Higher sample rates (&ge; 500 Hz) yield accurate brain strain predictions, but lower rates (e.g., 50 Hz) introduce significant inaccuracies, despite marginal improvements with simple polynomial interpolation.


---
# Skin Cancer Detection Using Deep Learning Techniques: A Review

## 使用深度学习技术检测皮肤癌: 综述

Link: https://www.researchsquare.com/article/rs-6027842/latest

Melanoma and other skin cancers offer serious health hazards, especially given the high fatality rates linked with late detection. Early identification is critical for improving patient outcomes; yet, present clinical approaches are often subjective and difficult, resulting in varied accuracy. This research investigates the application of deep learning (DL) for skin cancer diagnosis, with a focus on four convolutional neural network (CNN) architectures: AlexNet, VGG16, ResNet, and DenseNet. These models are tested for their ability to categorise skin lesions and differentiate between melanoma and non-melanoma instances using extensive image analysis. These designs provide a strong alternative to standard diagnostic approaches by harnessing CNNs' skills in feature extraction and pattern recognition.&amp;nbsp;
The research emphasises a few major findings: ResNet and DenseNet surpass AlexNet and VGG16 in terms of classification accuracy and generalisability on a variety of datasets. However, substantial impediments continue to exist, including data imbalance, poor interpretability of model conclusions, and the difficulty of generalising across distinct patient populations. Addressing these constraints is critical to increasing the clinical value of CNN-based systems.&amp;nbsp;
Future study should concentrate on incorporating multimodal data, such as clinical information and imaging data, to improve model robustness. Furthermore, establishing explainable AI (XAI) frameworks will be critical to improving confidence in AI-powered diagnostic tools. Despite these obstacles, deep learning provides a scalable and cost-effective method for early skin cancer diagnosis, which has the potential to drastically cut death rates and enhance treatment results.


---
# Surface Defect Detection of Magnetic Tiles Based on an Improved Lightweight GhostNet Network

## 基于改进轻量级GhostNet网络的磁瓦表面缺陷检测

Link: https://www.researchsquare.com/article/rs-6020940/latest

In modern industry, the performance of permanent magnet motors is crucial to enhancing efficiency and system reliability. As a key component of these motors, the quality of magnetic tiles directly impacts motor performance. Therefore, ensuring that magnetic tile surfaces are free of defects is essential for maintaining product quality. While traditional visual inspection methods have been widely used, they suffer from limitations in precision and stability. Although deep learning has improved detection accuracy, it increases the demand on computational resources. To address these issues, this paper proposes an optimized lightweight deep learning model called S-GhostNet, which aims to enhance the efficiency and accuracy of magnetic tile surface defect detection while reducing computational complexity. S-GhostNet employs advanced optimization techniques, such as generating Ghost features using different dilation rates in convolutional layers to capture multi-scale defect information, thereby enhancing feature diversity. Channel shuffling and depthwise separable convolutions promote feature fusion and reduce redundant computations. Additionally, the integration of Feature Pyramid Networks (FPN) improves the detection of defects of various sizes. Experimental results show that S-GhostNet achieves an accuracy of 95.46\% in magnetic tile surface defect detection, achieving a 14.36\% improvement over the original GhostNet, while reducing computational cost (FLOPs) by approximately 29.76\%, from 4.20 G to 2.95 G. This demonstrates that S-GhostNet not only enhances detection accuracy but also significantly reduces the required computational resources, highlighting its advantages in this field.


---
# Adaptive, ML-Enhanced Resource Management for High-Performance Cloud-Based Web Platforms

## 适用于基于云的高性能Web平台的自适应、ML增强资源管理

Link: https://www.researchsquare.com/article/rs-6025433/latest

Efficient resource management in cloud-based web platforms is critical to maintaining performance and cost efficiency under dynamic and unpredictable workloads. This paper proposes a novel resource management framework that integrates predictive workload modeling, multi-tier autoscaling, and cost-aware optimization. The framework utilizes machine learning models to forecast workload patterns and coordinates resource allocation across application, caching, and storage tiers, ensuring minimal latency and optimal resource utilization.&amp;nbsp; Experimental results demonstrate a 45% reduction in mean latency and a 30% decrease in total resource costs compared to traditional threshold-based autoscaling. The framework also improves resource utilization to 85% on average while halving the frequency of scaling actions, reducing operational instability. These outcomes highlight the effectiveness of the proposed approach in balancing performance and cost objectives in complex cloud environments. The proposed framework advances the state of the art in cloud resource management by addressing inter-tier dependencies and leveraging predictive analytics for proactive scaling. Its adaptability to diverse workload patterns and potential applicability to multi-cloud and edge computing scenarios make it a scalable and robust solution for modern web platforms.


---
# DAM-Seg: Anatomically accurate cardiac segmentation using Dense Associative Networks

## Dam-seg: 使用密集关联网络的解剖学精确心脏分割

Link: https://www.researchsquare.com/article/rs-6028457/latest

Deep learning-based cardiac segmentation has seen significant advancements over the years. Many studies have tackled the challenge of anatomically incorrect segmentation predictions by introducing auxiliary modules. These modules either post-process segmentation outputs or enforce consistency between specific points to ensure anatomical correctness. However, such approaches often increase network complexity, require separate training for these modules, and may lack robustness in scenarios with poor visibility. To address these limitations, we propose a novel transformer-based architecture that leverages dense associative networks to learn and retain specific patterns inherent to cardiac inputs. Unlike traditional methods, our approach restricts the network to memorize a limited set of patterns. During forward propagation, a weighted sum of these patterns is used to enforce anatomical correctness in the output. Since these patterns are input-independent, the model demonstrates enhanced robustness, even in cases with poor visibility. The proposed pipeline was evaluated on two publicly available datasets, CAMUS and CardiacNet. Experimental results indicate that our model consistently outperforms baseline approaches across all metrics, highlighting its effectiveness and reliability for cardiac segmentation tasks.&nbsp;

