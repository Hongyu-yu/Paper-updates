# Enhancing Cosmological Model Selection with Interpretable Machine Learning

## 通过可解释的机器学习增强宇宙学模型选择

Link: http://link.aps.org/doi/10.1103/PhysRevLett.134.041002

**Authors:** Indira Ocampo, George Alestas, Savvas Nesseris, and Domenico Sapone

Author(s): Indira Ocampo, George Alestas, Savvas Nesseris, and Domenico Sapone<br /><p>We propose a novel approach using neural networks (NNs) to differentiate between cosmological models, and implemented <span class="sc">lime</span> as an interpretability approach to identify the key features influencing our model’s decisions. We show the potential of NNs to enhance the extraction of meaningful information …</p><br />[Phys. Rev. Lett. 134, 041002] Published Fri Jan 31, 2025


---
# Femtojoule optical nonlinearity for deep learning with incoherent illumination

## 非相干照明深度学习的飞焦耳光学非线性

Link: https://www.science.org/doi/abs/10.1126/sciadv.ads4224?af=R

**Authors:** Qixin Feng, Can B. Uzundal, Ruihan Guo, Collin Sanborn, Ruishi Qi, Jingxu Xie, Jianing Zhang, Junqiao Wu, Feng Wang

Science Advances, Volume 11, Issue 5, January 2025. <br />


---
# Adapting hybrid density functionals with machine learning

## 用机器学习调整混合密度泛函

Link: https://www.science.org/doi/abs/10.1126/sciadv.adt7769?af=R

**Authors:** Danish Khan, Alastair J. A. Price, Bing Huang, Maximilian L. Ach, O. Anatole von Lilienfeld

Science Advances, Volume 11, Issue 5, January 2025. <br />


---
# Transformer-generated atomic embeddings to enhance prediction accuracy of crystal properties with machine learning

## Transformer生成的原子嵌入，可通过机器学习提高晶体特性的预测精度

Link: https://www.nature.com/articles/s41467-025-56481-x

**Authors:** Hao Zhang

<p>Nature Communications, Published online: 31 January 2025; <a href="https://www.nature.com/articles/s41467-025-56481-x">doi:10.1038/s41467-025-56481-x</a></p>Atomic representations are crucial for building reliable and transferable machine learning models. Here, the authors propose transformer-based universal atomic embeddings to enhance the prediction accuracy of crystal properties.


---
# [ASAP] Accelerated Design of Dual-Metal-Site Catalysts via Machine-Learning Prediction

## [ASAP] 通过机器学习预测加速双金属位点催化剂的设计

Link: http://dx.doi.org/10.1021/acs.jpclett.5c00126

**Authors:** Yang Wang, Qian Wang, Xijun Wang, Jing Yang, Jun Jiang, and Chuanyi Jia

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acs.jpclett.5c00126/asset/images/medium/jz5c00126_0006.gif" /></p><div><cite>The Journal of Physical Chemistry Letters</cite></div><div>DOI: 10.1021/acs.jpclett.5c00126</div>


---
# Physics-guided actor-critic reinforcement learning for swimming in turbulence

## 物理指导的演员-评论家强化学习，用于在湍流中游泳

Link: http://link.aps.org/doi/10.1103/PhysRevResearch.7.013121

**Authors:** Christopher Koh, Laurent Pagnier, and Michael Chertkov

Author(s): Christopher Koh, Laurent Pagnier, and Michael Chertkov<br /><p>Turbulent diffusion causes particles placed in proximity to separate. We investigate the required swimming efforts to maintain an active particle close to its passively advected counterpart. We explore optimally balancing these efforts by developing a novel physics-informed reinforcement learning st…</p><br />[Phys. Rev. Research 7, 013121] Published Fri Jan 31, 2025


---
# Advancing privacy-aware machine learning on sensitive data via edge-based continual µ-training for personalized large models

## 通过基于边缘的持续 µ-针对个性化大型模型的训练，在敏感数据上推进隐私感知机器学习

Link: http://iopscience.iop.org/article/10.1088/2632-2153/adaca3

**Authors:** Zhaojing Huang, Leping Yu, Luis Fernando Herbozo Contreras, Kamran Eshraghian, Nhan Duy Truong, Armin Nikpour and Omid Kavehei

This paper introduces an innovative method for fine-tuning a large multi-label model for abnormality detection, utilizing a smaller trainer and advanced knowledge distillation techniques. It studies the effects of fine-tuning on various abnormalities, noting different improvements based on the Original Model’s performance in specific tasks. The experimental setup, optimized for on-device inference and fine-tuning with limited computational resources, demonstrates moderate yet promising enhancements in model performance post-fine-tuning. Key insights from the study include the significance of aligning the µ-Trainer’s behavior with the Original Model and the influence of hyper-parameters like batch size on fine-tuning outcomes. The research acknowledges limitations such as the limited exploration of loss functions in multi-label models and constraints in architectural design, suggesting potential avenues for future investigation. While the proposed Naive Continual Fine-tuning Process is in its early stages, we highlight this paper’s potential model personalization on long-term data. Moreover, weight transfer in our system is exclusively for fine-tuning; hence, it improves user privacy protection by failing data reconstruction attempts from weights, like an issue with Federated learning models. Our on-device fine-tuning prevents the transferring of data or gradients from the edge of the network to their server. Despite modest performance improvements after fine-tuning, these working layers represent a small fraction (0.7%) of the total weights in the Original Model and 1.6% in the µ-Trainer. This study establishes a foundational framework for advancing personalized model adaptation, on-device inference and fine-tuning while emphasizing the importance of safeguarding data privacy in model development.


---
# Integrating Machine Learning and Characterization in Battery Research: Toward Cognitive Digital Twins with Physics and Knowledge

## 在电池研究中整合机器学习和表征: 走向具有物理和知识的认知数字孪生

Link: https://advanced.onlinelibrary.wiley.com/doi/10.1002/adfm.202422601?af=R

**Authors:** Erhai Hu, 
Hong Han Choo, 
Wei Zhang, 
Afriyanti Sumboja, 
Ivandini T. Anggraningrum, 
Anne Zulfia Syahrial, 
Qiang Zhu, 
Jianwei Xu, 
Xian Jun Loh, 
Hongge Pan, 
Jian Chen, 
Qingyu Yan

Advanced Functional Materials, EarlyView.


---
# Bridging statistical mechanics and thermodynamics away from equilibrium: a data-driven approach for learning internal variables and their dynamics

## 桥接统计力学和热力学远离平衡: 学习内部变量及其动力学的数据驱动方法

Link: https://arxiv.org/abs/2501.17993

**Authors:** Weilun Qiu, Shenglin Huang, Celia Reina

arXiv:2501.17993v1 Announce Type: new 
Abstract: Thermodynamics with internal variables is a common approach in continuum mechanics to model inelastic (i.e., non-equilibrium) material behavior. While this approach is computationally and theoretically attractive, it currently lacks a well-established statistical mechanics foundation. As a result, internal variables are typically chosen phenomenologically and lack a direct link to the underlying physics which hinders the predictability of the theory. To address these challenges, we propose a machine learning approach that is consistent with the principles of statistical mechanics and thermodynamics. The proposed approach leverages the following techniques (i) the information bottleneck (IB) method to ensure that the learned internal variables are functions of the microstates and are capable of capturing the salient feature of the microscopic distribution; (ii) conditional normalizing flows to represent arbitrary probability distributions of the microscopic states as functions of the state variables; and (iii) Variational Onsager Neural Networks (VONNs) to guarantee thermodynamic consistency and Markovianity of the learned evolution equations. The resulting framework, called IB-VONNs, is tested on two problems of colloidal systems, governed at the microscale by overdamped Langevin dynamics. The first one is a prototypical model for a colloidal particle in an optical trap, which can be solved analytically, and thus ideal to verify the framework. The second problem is a one-dimensional phase-transforming system, whose macroscopic description still lacks a statistical mechanics foundation under general conditions. The results in both cases indicate that the proposed machine learning strategy can indeed bridge statistical mechanics and thermodynamics with internal variables away from equilibrium.


---
# Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features

## 通过衍射潜在空间特征的空间映射学习金属微结构异质性

Link: https://arxiv.org/abs/2501.18064

**Authors:** Mathieu Calvat, Chris Bean, Dhruv Anjaria, Hyoungryul Park, Haoren Wang, Kenneth Vecchio, J. C. Stinville

arXiv:2501.18064v1 Announce Type: new 
Abstract: To leverage advancements in machine learning for metallic materials design and property prediction, it is crucial to develop a data-reduced representation of metal microstructures that surpasses the limitations of current physics-based discrete microstructure descriptors. This need is particularly relevant for metallic materials processed through additive manufacturing, which exhibit complex hierarchical microstructures that cannot be adequately described using the conventional metrics typically applied to wrought materials. Furthermore, capturing the spatial heterogeneity of microstructures at the different scales is necessary within such framework to accurately predict their properties. To address these challenges, we propose the physical spatial mapping of metal diffraction latent space features. This approach integrates (i) point diffraction data encoding via variational autoencoders or contrastive learning and (ii) the physical mapping of the encoded values. Together these steps offer a method offers a novel means to comprehensively describe metal microstructures. We demonstrate this approach on a wrought and additively manufactured alloy, showing that it effectively encodes microstructural information and enables direct identification of microstructural heterogeneity not directly possible by physics-based models. This data-reduced microstructure representation opens the application of machine learning models in accelerating metallic material design and accurately predicting their properties.


---
# A tomographic interpretation of structure-property relations for materials discovery

## 材料发现的结构-性质关系的层析解释

Link: https://arxiv.org/abs/2501.18163

**Authors:** Raul Ortega-Ochoa, Al\'an Aspuru-Guzik, Tejs Vegge, Tonio Buonassisi

arXiv:2501.18163v1 Announce Type: new 
Abstract: Recent advancements in machine learning (ML) for materials have demonstrated that "simple" materials representations (e.g., the chemical formula alone without structural information) can sometimes achieve competitive property prediction performance in common-tasks. Our physics-based intuition would suggest that such representations are "incomplete", which indicates a gap in our understanding. This work proposes a tomographic interpretation of structure-property relations of materials to bridge that gap by defining what is a material representation, material properties, the material and the relationships between these three concepts using ideas from information theory. We verify this framework performing an exhaustive comparison of property-augmented representations on a range of material's property prediction objectives, providing insight into how different properties can encode complementary information.


---
# Ultra-large mutually synchronized networks of 10 nm spin Hall nano-oscillators

## 10 nm自旋霍尔纳米振荡器的超大型相互同步网络

Link: https://arxiv.org/abs/2501.18321

**Authors:** Nilamani Behera, Avinash Kumar Chaurasiya, Akash Kumar, Roman Khymyn, Artem Litvinenko, Lakhan Bainsla, Ahmad A. Awad, Johan {\AA}kerman

arXiv:2501.18321v1 Announce Type: new 
Abstract: While mutually interacting spin Hall nano-oscillators (SHNOs) hold great promise for wireless communication, neural networks, neuromorphic computing, and Ising machines, the highest number of synchronized SHNOs remains limited to $N$ = 64. Using ultra-narrow 10 and 20-nm nano-constrictions in W-Ta/CoFeB/MgO trilayers, we demonstrate mutually synchronized SHNO networks of up to $N$ = 105,000. The microwave power and quality factor scale as $N$ with new record values of 9 nW and $1.04 \times 10^6$, respectively. An unexpectedly strong array size dependence of the frequency-current tunability is explained by magnon exchange between nano-constrictions and magnon losses at the array edges, further corroborated by micromagnetic simulations and Brillouin light scattering microscopy. Our results represent a significant step towards viable SHNO network applications in wireless communication and unconventional computing.


---
# Simulation of the crystallization kinetics of Ge$_2$Sb$_2$Te$_5$ nanoconfined in superlattice geometries for phase change memories

## 相变存储器超晶格几何中Ge $_2 $ Sb $_2 $ Te $_5 $ 纳米约束的结晶动力学模拟

Link: https://arxiv.org/abs/2501.18370

**Authors:** Debdipto Acharya, Omar Abou El Kheir, Simone Marcorini, Marco Bernasconi

arXiv:2501.18370v1 Announce Type: new 
Abstract: Phase change materials are the most promising candidates for the realization of artificial synapsis for neuromorphic computing. Different resistance levels corresponding to analogic values of the synapsis conductance can be achieved by modulating the size of an amorphous region embedded in its crystalline matrix. Recently, it has been proposed that a superlattice made of alternating layers of the phase change compound Sb$_2$Te$_3$ and of the TiTe$_2$ confining material allows for a better control of multiple intermediate resistance states and for a lower drift with time of the electrical resistance of the amorphous phase. In this work, we consider to substitute Sb$_2$Te$_3$ with the Ge$_2$Sb$_2$Te$_5$ prototypical phase change compound that should feature better data retention. By exploiting molecular dynamics simulations with a machine learning interatomic potential, we have investigated the crystallization kinetics of Ge$_2$Sb$_2$Te$_5$ nanoconfined in geometries mimicking Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices. It turns out that nanoconfinement induces a slight reduction in the crystal growth velocities with respect to the bulk, but also an enhancement of the nucleation rate due to heterogeneous nucleation. The results support the idea of investigating Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices for applications in neuromorphic devices with improved data retention. The effect on the crystallization kinetics of the addition of van der Waals interaction to the interatomic potential is also discussed.


---
# Deep learning with reflection high-energy electron diffraction images to predict cation ratio in Sr$_x$Ti$_{1-x}$O3 thin films

## 基于反射高能电子衍射图像的深度学习预测S r $ _x $ Ti $_{1-x}$ O3薄膜中的阳离子比率

Link: https://arxiv.org/abs/2501.18523

**Authors:** Sumner B. Harris, Patrick T. Gemperline, Christopher M. Rouleau, Rama K. Vasudevan, Ryan B. Comes

arXiv:2501.18523v1 Announce Type: new 
Abstract: Machine learning (ML) with in situ diagnostics offers a transformative approach to accelerate, understand, and control thin film synthesis by uncovering relationships between synthesis conditions and material properties. In this study, we demonstrate the application of deep learning to predict the stoichiometry of Sr$_x$Ti$_{1-x}$O3 thin films using reflection high-energy electron diffraction images acquired during pulsed laser deposition. A gated convolutional neural network trained for regression of the Sr atomic fraction achieved accurate predictions with a small dataset of 31 samples. Explainable AI techniques revealed a previously unknown correlation between diffraction streak features and cation stoichiometry in Sr$_x$Ti$_{1-x}$O3 thin films. Our results demonstrate how ML can be used to transform a ubiquitous in situ diagnostic tool, that is usually limited to qualitative assessments, into a quantitative surrogate measurement of continuously valued thin film properties. Such methods are critically needed to enable real-time control, autonomous workflows, and accelerate traditional synthesis approaches.


---
# When less is more: evolving large neural networks from small ones

## 当少就是多: 从小型神经网络进化大型神经网络

Link: https://arxiv.org/abs/2501.18012

**Authors:** Anil Radhakrishnan, John F. Lindner, Scott T. Miller, Sudeshna Sinha, William L. Ditto

arXiv:2501.18012v1 Announce Type: cross 
Abstract: In contrast to conventional artificial neural networks, which are large and structurally static, we study feed-forward neural networks that are small and dynamic, whose nodes can be added (or subtracted) during training. A single neuronal weight in the network controls the network's size, while the weight itself is optimized by the same gradient-descent algorithm that optimizes the network's other weights and biases, but with a size-dependent objective or loss function. We train and evaluate such Nimble Neural Networks on nonlinear regression and classification tasks where they outperform the corresponding static networks. Growing networks to minimal, appropriate, or optimal sizes while training elucidates network dynamics and contrasts with pruning large networks after training but before deployment.


---
# Tensor Completion for Surrogate Modeling of Material Property Prediction

## 用于材料性能预测代理建模的张量补全

Link: https://arxiv.org/abs/2501.18137

**Authors:** Shaan Pakala, Dawon Ahn, Evangelos Papalexakis

arXiv:2501.18137v1 Announce Type: cross 
Abstract: When designing materials to optimize certain properties, there are often many possible configurations of designs that need to be explored. For example, the materials' composition of elements will affect properties such as strength or conductivity, which are necessary to know when developing new materials. Exploring all combinations of elements to find optimal materials becomes very time consuming, especially when there are more design variables. For this reason, there is growing interest in using machine learning (ML) to predict a material's properties. In this work, we model the optimization of certain material properties as a tensor completion problem, to leverage the structure of our datasets and navigate the vast number of combinations of material configurations. Across a variety of material property prediction tasks, our experiments show tensor completion methods achieving 10-20% decreased error compared with baseline ML models such as GradientBoosting and Multilayer Perceptron (MLP), while maintaining similar training speed.


---
# Neural Network Modeling of Microstructure Complexity Using Digital Libraries

## 基于数字图书馆的微结构复杂性神经网络建模

Link: https://arxiv.org/abs/2501.18189

**Authors:** Yingjie Zhao, Zhiping Xu

arXiv:2501.18189v1 Announce Type: cross 
Abstract: Microstructure evolution in matter is often modeled numerically using field or level-set solvers, mirroring the dual representation of spatiotemporal complexity in terms of pixel or voxel data, and geometrical forms in vector graphics. Motivated by this analog, as well as the structural and event-driven nature of artificial and spiking neural networks, respectively, we evaluate their performance in learning and predicting fatigue crack growth and Turing pattern development. Predictions are made based on digital libraries constructed from computer simulations, which can be replaced by experimental data to lift the mathematical overconstraints of physics. Our assessment suggests that the leaky integrate-and-fire neuron model offers superior predictive accuracy with fewer parameters and less memory usage, alleviating the accuracy-cost tradeoff in contrast to the common practices in computer vision tasks. Examination of network architectures shows that these benefits arise from its reduced weight range and sparser connections. The study highlights the capability of event-driven models in tackling problems with evolutionary bulk-phase and interface behaviors using the digital library approach.


---
# Comprehensive Enumeration of Three-Dimensional Photonic Crystals Enabled through Deep Learning Assisted Fourier Synthesis

## 通过深度学习辅助傅里叶合成实现的三维光子晶体的综合枚举

Link: https://arxiv.org/abs/2501.18495

**Authors:** Congcong Cui, Guangfeng Wei, Matthias Saba, Lu Han

arXiv:2501.18495v1 Announce Type: cross 
Abstract: Three-dimensional (3D) photonic structures enable numerous applications through their unique ability to guide, trap, and manipulate light. Constructing new functional photonic crystals remains a significant challenge since traditional design principles based on band structure calculations require numerous time-consuming computations. Additionally, traditional design is based on enumerated structures making it difficult to find novel functional geometries. Here, we propose an ultra-fast photonic crystal performance prediction method to enable efficient structure optimization of arbitrary 3D photonic crystals even with multiple variable modulation. Our methodology combines Fourier synthesis-enabling the creation of any smooth geometry within a crystallographic space group-with deep learning, which facilitates efficient photonic characterization within the vast parameter space. Over 2 million structures can be explored within 2 hours using a mainstream desktop workstation. The ideal structures with desired band properties, such as large photonic bandgap, specific frequency ranges, etc., could be rapidly discovered. We systematically confirmed the well-documented assumption that the most significant photonic bandgaps are found in minimal surface morphologies, in which the single diamond (dia net) with Fd3m (227) symmetry reigns supreme among known photonic structures, followed by the chiral single gyroid (srs net) with I4132 (214) symmetry. Additionally, a less well-known 3D photonic crystal with lcs topology within Ia3d (230) was rediscovered to exhibit a wide complete photonic bandgap, comparable to the diamond and the gyroid net. Our method not only validates the assumed hierarchy of photonic structures but also lays the foundation for the tailored design of functional materials and offers fresh insights into the advancement of next-generation optical devices and information technology.


---
# Optimal generalisation and learning transition in extensive-width shallow neural networks near interpolation

## 插值附近的宽幅浅层神经网络中的最佳泛化和学习过渡

Link: https://arxiv.org/abs/2501.18530

**Authors:** Jean Barbier, Francesco Camilli, Minh-Toan Nguyen, Mauro Pastore, Rudy Skerk

arXiv:2501.18530v1 Announce Type: cross 
Abstract: We consider a teacher-student model of supervised learning with a fully-trained 2-layer neural network whose width $k$ and input dimension $d$ are large and proportional. We compute the Bayes-optimal generalisation error of the network for any activation function in the regime where the number of training data $n$ scales quadratically with the input dimension, i.e., around the interpolation threshold where the number of trainable parameters $kd+k$ and of data points $n$ are comparable. Our analysis tackles generic weight distributions. Focusing on binary weights, we uncover a discontinuous phase transition separating a "universal" phase from a "specialisation" phase. In the first, the generalisation error is independent of the weight distribution and decays slowly with the sampling rate $n/d^2$, with the student learning only some non-linear combinations of the teacher weights. In the latter, the error is weight distribution-dependent and decays faster due to the alignment of the student towards the teacher network. We thus unveil the existence of a highly predictive solution near interpolation, which is however potentially hard to find.


---
# Constructing multicomponent cluster expansions with machine-learning and chemical embedding

## 通过机器学习和化学嵌入构建多组分簇扩展

Link: https://arxiv.org/abs/2409.06071

**Authors:** Yann L. M\"uller, Anirudh Raju Natarajan

arXiv:2409.06071v2 Announce Type: replace 
Abstract: Cluster expansions are commonly employed as surrogate models to link the electronic structure of an alloy to its finite-temperature properties. Using cluster expansions to model materials with several alloying elements is challenging due to a rapid increase in the number of fitting parameters and training set size. We introduce the embedded cluster expansion (eCE) formalism that enables the parameterization of accurate on-lattice surrogate models for alloys containing several chemical species. The eCE model simultaneously learns a low dimensional embedding of site basis functions along with the weights of an energy model. A prototypical senary alloy comprised of elements in groups 5 and 6 of the periodic table is used to demonstrate that eCE models can accurately reproduce ordering energetics of complex alloys without a significant increase in model complexity. Further, eCE models can leverage similarities between chemical elements to efficiently extrapolate into compositional spaces that are not explicitly included in the training dataset. The eCE formalism presented in this study unlocks the possibility of employing cluster expansion models to study multicomponent alloys containing several alloying elements.


---
# Advancing Natural Orbital Functional Calculations Through Deep Learning-Inspired Techniques for Large-Scale Strongly Correlated Electron Systems

## 通过深度学习技术推进大规模强相关电子系统的自然轨道功能计算

Link: https://arxiv.org/abs/2411.18493

**Authors:** Juan Felipe Huan Lew-Yee, Jorge M. del Campo, Mario Piris

arXiv:2411.18493v2 Announce Type: replace 
Abstract: Natural orbital functional (NOF) theory offers a promising approach for studying strongly correlated systems at an affordable computational cost, with an accuracy comparable to highly demanding wavefunction-based methods. However, its widespread adoption in cases involving a large number of correlated electrons has been limited by the extensive iterations required for convergence. In this work, we present a disruptive approach that embeds the techniques used for optimization in deep learning within the NOF calculation, constituting a substantial advance in the scale of accessible systems. The revamped procedure is based on the adaptive momentum technique for orbital optimization, alternated with the optimization of the occupation numbers, significantly improving the computational feasibility of challenging calculations. This work represents a complete change in the size scale of the systems that can be reached using NOF theory. We demonstrate this with three examples that involve a large number of electrons: (i) the symmetric dissociation of a large hydrogen cluster, (ii) an analysis of occupancies distribution in fullerenes, and (iii) a study of the singlet-triplet energy gap in linear acenes. Notably, the hydrogen cluster calculation, featuring 1000 electrons, represents the largest NOF calculation performed to date and one of the largest strongly correlated electron calculations ever reported. This system, which serves as an ideal model for a strongly correlated Mott insulator, illustrates a metal-to-insulator transition where all electrons participate in the correlation phenomenon, offering insight in a unique challenge. We anticipate that this work will enable the practical application of NOFs to increasingly complex and intriguing systems, leveraging the method's inherent scalability and accuracy.


---
# Applications of machine learning in ion beam analysis of materials

## 机器学习在材料离子束分析中的应用

Link: https://arxiv.org/abs/2412.12312

**Authors:** Tiago Fiorini da Silva

arXiv:2412.12312v2 Announce Type: replace 
Abstract: Ion Beam Analysis (IBA) is an established tool for material characterization, providing precise information on elemental composition, depth profiles, and structural information in the region near the surface of materials. However, traditional data processing methods can be slow and computationally intensive, limiting the efficiency and speed of the analysis. This article explores the current landscape of applying Machine Learning Algorithms (MLA) in the field of IBA, demonstrating the immense potential to optimize and accelerate processes. We present how ML has been employed to extract valuable insights from large datasets, automate repetitive tasks, and enhance the interpretability of results, with practical examples of applications in various IBA techniques, such as RBS, PIXE, and others. Finally, perspectives on using MLA to approach open problems in IBA are also discussed.


---
# Transfer Learning in $\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis

## $ \ ell_1 $ 正则化回归中的迁移学习: 基于Sharp渐近分析的超参数选择策略

Link: https://arxiv.org/abs/2409.17704

**Authors:** Koki Okajima, Tomoyuki Obuchi

arXiv:2409.17704v2 Announce Type: replace-cross 
Abstract: Transfer learning techniques aim to leverage information from multiple related datasets to enhance prediction quality against a target dataset. Such methods have been adopted in the context of high-dimensional sparse regression, and some Lasso-based algorithms have been invented: Trans-Lasso and Pretraining Lasso are such examples. These algorithms require the statistician to select hyperparameters that control the extent and type of information transfer from related datasets. However, selection strategies for these hyperparameters, as well as the impact of these choices on the algorithm's performance, have been largely unexplored. To address this, we conduct a thorough, precise study of the algorithm in a high-dimensional setting via an asymptotic analysis using the replica method. Our approach reveals a surprisingly simple behavior of the algorithm: Ignoring one of the two types of information transferred to the fine-tuning stage has little effect on generalization performance, implying that efforts for hyperparameter selection can be significantly reduced. Our theoretical findings are also empirically supported by applications on real-world and semi-artificial datasets using the IMDb and MNIST datasets, respectively.


---
# An information-matching approach to optimal experimental design and active learning

## 优化实验设计和主动学习的信息匹配方法

Link: https://arxiv.org/abs/2411.02740

**Authors:** Yonatan Kurniawan (Brigham Young University, Provo, UT, USA), Tracianne B. Neilsen (Brigham Young University, Provo, UT, USA), Benjamin L. Francis (Achilles Heel Technologies, Orem, UT, USA), Alex M. Stankovic (SLAC National Accelerator Laboratory, Menlo Park, CA, USA), Mingjian Wen (University of Houston, Houston, TX, USA), Ilia Nikiforov (University of Minnesota, Minneapolis, MN, USA), Ellad B. Tadmor (University of Minnesota, Minneapolis, MN, USA), Vasily V. Bulatov (Lawrence Livermore National Laboratory), Vincenzo Lordi (Lawrence Livermore National Laboratory), Mark K. Transtrum (Brigham Young University, Provo, UT, USA, SLAC National Accelerator Laboratory, Menlo Park, CA, USA)

arXiv:2411.02740v2 Announce Type: replace-cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.


---
# Object Detection with Deep Learning for Rare Event Search in the GADGET II TPC

## 在GADGET II TPC中使用深度学习进行罕见事件搜索的对象检测

Link: https://arxiv.org/abs/2501.17892

**Authors:** Tyler Wheeler, S. Ravishankar, C. Wrede, A. Andalib, A. Anthony, Y. Ayyad, B. Jain, A. Jaros, R. Mahajan, L. Schaedig, A. Adams, S. Ahn, J. M. Allmond, D. Bardayan, D. Bazin, K. Bosmpotinis, T. Budner, S. R. Carmichael, S. M. Cha, A. Chen, K. A. Chipps, J. M. Christie, I. Cox, J. Dopfer, M. Friedman, J. Garcia-Duarte, E. Good, T. J. Gray, A. Green, R. Grzywacz, K. Hahn, R. Jain, E. Jensen, T. King, S. Liddick, B. Longfellow, R. Lubna, C. Marshall, Y. Mishnayot, A. J. Mitchell, F. Montes, T. H. Ogunbeku, J. Owens-Fryar, S. D. Pain, J. Pereira, E. Pollacco, A. M. Rogers, M. Z. Serikow, K. Setoodehnia, L. J. Sun, J. Surbrook, A. Tsantiri, L. E. Weghorn

arXiv:2501.17892v1 Announce Type: new 
Abstract: In the pursuit of identifying rare two-particle events within the GADGET II Time Projection Chamber (TPC), this paper presents a comprehensive approach for leveraging Convolutional Neural Networks (CNNs) and various data processing methods. To address the inherent complexities of 3D TPC track reconstructions, the data is expressed in 2D projections and 1D quantities. This approach capitalizes on the diverse data modalities of the TPC, allowing for the efficient representation of the distinct features of the 3D events, with no loss in topology uniqueness. Additionally, it leverages the computational efficiency of 2D CNNs and benefits from the extensive availability of pre-trained models. Given the scarcity of real training data for the rare events of interest, simulated events are used to train the models to detect real events. To account for potential distribution shifts when predominantly depending on simulations, significant perturbations are embedded within the simulations. This produces a broad parameter space that works to account for potential physics parameter and detector response variations and uncertainties. These parameter-varied simulations are used to train sensitive 2D CNN object detectors. When combined with 1D histogram peak detection algorithms, this multi-modal detection framework is highly adept at identifying rare, two-particle events in data taken during experiment 21072 at the Facility for Rare Isotope Beams (FRIB), demonstrating a 100% recall for events of interest. We present the methods and outcomes of our investigation and discuss the potential future applications of these techniques.


---
# An iterative spectral algorithm for digraph clustering

## 有向图聚类的迭代谱算法

Link: https://arxiv.org/abs/2501.17951

**Authors:** James Martin, Tim Rogers, Luca Zanetti

arXiv:2501.17951v1 Announce Type: new 
Abstract: Graph clustering is a fundamental technique in data analysis with applications in many different fields. While there is a large body of work on clustering undirected graphs, the problem of clustering directed graphs is much less understood. The analysis is more complex in the directed graph case for two reasons: the clustering must preserve directional information in the relationships between clusters, and directed graphs have non-Hermitian adjacency matrices whose properties are less conducive to traditional spectral methods. Here we consider the problem of partitioning the vertex set of a directed graph into $k\ge 2$ clusters so that edges between different clusters tend to follow the same direction. We present an iterative algorithm based on spectral methods applied to new Hermitian representations of directed graphs. Our algorithm performs favourably against the state-of-the-art, both on synthetic and real-world data sets. Additionally, it is able to identify a "meta-graph" of $k$ vertices that represents the higher-order relations between clusters in a directed graph. We showcase this capability on data sets pertaining food webs, biological neural networks, and the online card game Hearthstone.


---
# A photonic integrated processor for multiple parallel computational tasks

## 用于多个并行计算任务的光子集成处理器

Link: https://arxiv.org/abs/2501.18186

**Authors:** Sheng Dong, Ruiqi Zheng, Huan Rao, Junyi Zhang, Jingxu Chen, Chencheng Zeng, Yu Huang, Jiejun Zhang, Jianping Yao

arXiv:2501.18186v1 Announce Type: new 
Abstract: Optical networks with parallel processing capabilities are significant in advancing high-speed data computing and large-scale data processing by providing ultra-width computational bandwidth. In this paper, we present a photonic integrated processor that can be segmented into multiple functional blocks, to enable compact and reconfigurable matrix operations for multiple parallel computational tasks. Fabricated on a silicon-on-insulator (SOI) platform, the photonic integrated processor supports fully reconfigurable optical matrix operations. By segmenting the chip into multiple functional blocks, it enables optical matrix operations of various sizes, offering great flexibility and scalability for parallel computational tasks. Specifically, we utilize this processor to perform optical convolution operations with various kernel sizes, including reconfigurable three-channel 1x1 convolution kernels and 2x2 real-valued convolution kernels, implemented within distinct segmented blocks of the chip. The multichannel optical 1x1 convolution operation is experimentally validated by using the deep residual U-Net, demonstrating precise segmentation of pneumonia lesion region in lung CT images. In addition, the capability of the 2x2 optical convolution operation is also experimentally validated by constructing an optical convolution layer and integrating an electrical fully connected layer, achieving ten-class classification of handwritten digit images. The photonic integrated processor features high scalability and robust parallel computational capability, positioning it a promising candidate for applications in optical neural networks.


---
# Scalable intensity-based photonic matrix-vector multiplication processor using single-wavelength time-division-multiplexed signals

## 使用单波长时分复用信号的基于强度的可扩展光子矩阵矢量乘法处理器

Link: https://arxiv.org/abs/2501.18194

**Authors:** Chengli Chai, Rui Tang, Makoto Okano, Kasidit Toprasertpong, Shinichi Takagi, Mitsuru Takenaka

arXiv:2501.18194v1 Announce Type: new 
Abstract: Photonic integrated circuits provide a compact platform for ultrafast and energy-efficient matrix-vector multiplications (MVMs) in the optical domain. Recently, schemes based on time-division multiplexing (TDM) have been proposed as scalable approaches for realizing large-scale photonic MVM processors. However, existing demonstrations rely on coherent detection or multiple wavelengths, both of which complicate their operations. In this work, we demonstrate a scalable TDM-based photonic MVM processor that uses only single-wavelength intensity-modulated optical signals, thereby avoiding coherent detection and enabling simplified operations. A 32-channel processor is fabricated on a Si-on-insulator (SOI) platform and used to experimentally perform convolution operations in a convolutional neural network (CNN) for handwritten digit recognition, achieving a classification accuracy of 93.47% for 1500 images.


---
# Enhanced State Estimation for turbulent flows combining Ensemble Data Assimilation and Machine Learning

## 结合集合数据同化和机器学习的湍流增强状态估计

Link: https://arxiv.org/abs/2501.18262

**Authors:** Miguel M. Valero, Marcello Meldi

arXiv:2501.18262v1 Announce Type: new 
Abstract: A novel strategy is proposed to improve the accuracy of state estimation and reconstruction from low-fidelity models and sparse data from sensors. This strategy combines ensemble Data Assimilation (DA) and Machine Learning (ML) tools, exploiting their complementary features. ML techniques rely on the data produced by DA methods during analysis phases to train physics-informed corrective algorithms, which are then coupled with the low-fidelity models when data from sensors is unavailable. The methodology is validated via the analysis of the turbulent plane channel flow test case for $Re_\tau \approx 550$. Here, the low-fidelity model consists of coarse-grained simulations coupled with the Immersed Boundary Method (IBM), while observation is sampled by a highly refined body-fitted calculation. The analysis demonstrates the capabilities of the algorithm based on DA and ML to accurately predict the flow features with significantly reduced computational costs. This approach exhibits potential for future synergistic applications of DA and ML, leveraging the robustness and efficiency of ML models alongside the physical interpretability ensured by DA algorithms.


---
# Waveform-Specific Performance of Deep Learning-Based Super-Resolution for Ultrasound Contrast Imaging

## 基于深度学习的超声造影超分辨率的波形特异性性能

Link: https://arxiv.org/abs/2501.18375

**Authors:** Rienk Zorgdrager, Nathan Blanken, Jelmer M. Wolterink, Michel Versluis, Guillaume Lajoinie

arXiv:2501.18375v1 Announce Type: new 
Abstract: Resolving arterial flows is essential for understanding cardiovascular pathologies, improving diagnosis, and monitoring patient condition. Ultrasound contrast imaging uses microbubbles to enhance the scattering of the blood pool, allowing for real-time visualization of blood flow. Recent developments in vector flow imaging further expand the imaging capabilities of ultrasound by temporally resolving fast arterial flow. The next obstacle to overcome is the lack of spatial resolution. Super-resolved ultrasound images can be obtained by deconvolving radiofrequency (RF) signals before beamforming, breaking the link between resolution and pulse duration. Convolutional neural networks (CNNs) can be trained to locally estimate the deconvolution kernel and consequently super-localize the microbubbles directly within the RF signal. However, microbubble contrast is highly nonlinear, and the potential of CNNs in microbubble localization has not yet been fully exploited. Assessing deep learning-based deconvolution performance for non-trivial imaging pulses is therefore essential for successful translation to a practical setting, where the signal-to-noise ratio is limited, and transmission schemes should comply with safety guidelines. In this study, we train CNNs to deconvolve RF signals and localize the microbubbles driven by harmonic pulses, chirps, or delay-encoded pulse trains. Furthermore, we discuss potential hurdles for in-vitro and in-vivo super-resolution by presenting preliminary experimental results. We find that, whereas the CNNs can accurately localize microbubbles for all pulses, a short imaging pulse offers the best performance in noise-free conditions. However, chirps offer a comparable performance without noise, but are more robust to noise and outperform all other pulses in low-signal-to-noise ratio conditions.


---
# Comprehensive Enumeration of Three-Dimensional Photonic Crystals Enabled through Deep Learning Assisted Fourier Synthesis

## 通过深度学习辅助傅里叶合成实现的三维光子晶体的综合枚举

Link: https://arxiv.org/abs/2501.18495

**Authors:** Congcong Cui, Guangfeng Wei, Matthias Saba, Lu Han

arXiv:2501.18495v1 Announce Type: new 
Abstract: Three-dimensional (3D) photonic structures enable numerous applications through their unique ability to guide, trap, and manipulate light. Constructing new functional photonic crystals remains a significant challenge since traditional design principles based on band structure calculations require numerous time-consuming computations. Additionally, traditional design is based on enumerated structures making it difficult to find novel functional geometries. Here, we propose an ultra-fast photonic crystal performance prediction method to enable efficient structure optimization of arbitrary 3D photonic crystals even with multiple variable modulation. Our methodology combines Fourier synthesis-enabling the creation of any smooth geometry within a crystallographic space group-with deep learning, which facilitates efficient photonic characterization within the vast parameter space. Over 2 million structures can be explored within 2 hours using a mainstream desktop workstation. The ideal structures with desired band properties, such as large photonic bandgap, specific frequency ranges, etc., could be rapidly discovered. We systematically confirmed the well-documented assumption that the most significant photonic bandgaps are found in minimal surface morphologies, in which the single diamond (dia net) with Fd3m (227) symmetry reigns supreme among known photonic structures, followed by the chiral single gyroid (srs net) with I4132 (214) symmetry. Additionally, a less well-known 3D photonic crystal with lcs topology within Ia3d (230) was rediscovered to exhibit a wide complete photonic bandgap, comparable to the diamond and the gyroid net. Our method not only validates the assumed hierarchy of photonic structures but also lays the foundation for the tailored design of functional materials and offers fresh insights into the advancement of next-generation optical devices and information technology.


---
# A machine-learning optimized vertical-axis wind turbine

## 一种机器学习优化的垂直轴风力机

Link: https://arxiv.org/abs/2501.17886

**Authors:** Huan Liu, Richard D. James

arXiv:2501.17886v1 Announce Type: cross 
Abstract: Vertical-axis wind turbines (VAWTs) have garnered increasing attention in the field of renewable energy due to their unique advantages over traditional horizontal-axis wind turbines (HAWTs). However, traditional VAWTs including Darrieus and Savonius types suffer from significant drawbacks -- negative torque regions exist during rotation. In this work, we propose a new design of VAWT, which combines design principles from both Darrieus and Savonius but addresses their inherent defects. The performance of the proposed VAWT is evaluated through numerical simulations and validated by experimental testing. The results demonstrate that its power output is approximately three times greater than that of traditional Savonius VAWTs of comparable size. The performance of the proposed VAWT is further optimized using machine learning techniques, including Gaussian process regression and neural networks, based on extensive supercomputer simulations. This optimization leads to a 30% increase in power output.


---
# Progress in Artificial Intelligence and its Determinants

## 人工智能及其决定因素研究进展

Link: https://arxiv.org/abs/2501.17894

**Authors:** Michael R. Douglas, Sergiy Verstyuk

arXiv:2501.17894v1 Announce Type: cross 
Abstract: We study long-run progress in artificial intelligence in a quantitative way. Many measures, including traditional ones such as patents and publications, machine learning benchmarks, and a new Aggregate State of the Art in ML (or ASOTA) Index we have constructed from these, show exponential growth at roughly constant rates over long periods. Production of patents and publications doubles every ten years, by contrast with the growth of computing resources driven by Moore's Law, roughly a doubling every two years. We argue that the input of AI researchers is also crucial and its contribution can be objectively estimated. Consequently, we give a simple argument that explains the 5:1 relation between these two rates. We then discuss the application of this argument to different output measures and compare our analyses with predictions based on machine learning scaling laws proposed in existing literature. Our quantitative framework facilitates understanding, predicting, and modulating the development of these important technologies.


---
# Visualization of Organ Movements Using Automatic Region Segmentation of Swallowing CT

## 使用吞咽CT的自动区域分割来可视化器官运动

Link: https://arxiv.org/abs/2501.17897

**Authors:** Yukihiro Michiwaki, Takahiro Kikuchi, Takashi Ijiri, Yoko Inamoto, Hiroshi Moriya, Takumi Ogawa, Ryota Nakatani, Yuto Masaki, Yoshito Otake, Yoshinobu Sato

arXiv:2501.17897v1 Announce Type: cross 
Abstract: This study presents the first report on the development of an artificial intelligence (AI) for automatic region segmentation of four-dimensional computer tomography (4D-CT) images during swallowing. The material consists of 4D-CT images taken during swallowing. Additionally, data for verifying the practicality of the AI were obtained from 4D-CT images during mastication and swallowing. The ground truth data for the region segmentation for the AI were created from five 4D-CT datasets of swallowing. A 3D convolutional model of nnU-Net was used for the AI. The learning and evaluation method for the AI was leave-one-out cross-validation. The number of epochs for training the nnU-Net was 100. The Dice coefficient was used as a metric to assess the AI's region segmentation accuracy. Regions with a median Dice coefficient of 0.7 or higher included the bolus, bones, tongue, and soft palate. Regions with a Dice coefficient below 0.7 included the thyroid cartilage and epiglottis. Factors that reduced the Dice coefficient included metal artifacts caused by dental crowns in the bolus and the speed of movement for the thyroid cartilage and epiglottis. In practical verification of the AI, no significant misrecognition was observed for facial bones, jaw bones, or the tongue. However, regions such as the hyoid bone, thyroid cartilage, and epiglottis were not fully delineated during fast movement. It is expected that future research will improve the accuracy of the AI's region segmentation, though the risk of misrecognition will always exist. Therefore, the development of tools for efficiently correcting the AI's segmentation results is necessary. AI-based visualization is expected to contribute not only to the deepening of motion analysis of organs during swallowing but also to improving the accuracy of swallowing CT by clearly showing the current state of its precision.


---
# Influence of High-Performance Image-to-Image Translation Networks on Clinical Visual Assessment and Outcome Prediction: Utilizing Ultrasound to MRI Translation in Prostate Cancer

## 高性能图像到图像翻译网络对临床视觉评估和结果预测的影响: 利用超声对前列腺癌的MRI翻译

Link: https://arxiv.org/abs/2501.18109

**Authors:** Mohammad R. Salmanpour, Amin Mousavi, Yixi Xu, William B Weeks, Ilker Hacihaliloglu

arXiv:2501.18109v1 Announce Type: cross 
Abstract: Purpose: This study examines the core traits of image-to-image translation (I2I) networks, focusing on their effectiveness and adaptability in everyday clinical settings. Methods: We have analyzed data from 794 patients diagnosed with prostate cancer (PCa), using ten prominent 2D/3D I2I networks to convert ultrasound (US) images into MRI scans. We also introduced a new analysis of Radiomic features (RF) via the Spearman correlation coefficient to explore whether networks with high performance (SSIM>85%) could detect subtle RFs. Our study further examined synthetic images by 7 invited physicians. As a final evaluation study, we have investigated the improvement that are achieved using the synthetic MRI data on two traditional machine learning and one deep learning method. Results: In quantitative assessment, 2D-Pix2Pix network substantially outperformed the other 7 networks, with an average SSIM~0.855. The RF analysis revealed that 76 out of 186 RFs were identified using the 2D-Pix2Pix algorithm alone, although half of the RFs were lost during the translation process. A detailed qualitative review by 7 medical doctors noted a deficiency in low-level feature recognition in I2I tasks. Furthermore, the study found that synthesized image-based classification outperformed US image-based classification with an average accuracy and AUC~0.93. Conclusion: This study showed that while 2D-Pix2Pix outperformed cutting-edge networks in low-level feature discovery and overall error and similarity metrics, it still requires improvement in low-level feature performance, as highlighted by Group 3. Further, the study found using synthetic image-based classification outperformed original US image-based methods.


---
# A tomographic interpretation of structure-property relations for materials discovery

## 材料发现的结构-性质关系的层析解释

Link: https://arxiv.org/abs/2501.18163

**Authors:** Raul Ortega-Ochoa, Al\'an Aspuru-Guzik, Tejs Vegge, Tonio Buonassisi

arXiv:2501.18163v1 Announce Type: cross 
Abstract: Recent advancements in machine learning (ML) for materials have demonstrated that "simple" materials representations (e.g., the chemical formula alone without structural information) can sometimes achieve competitive property prediction performance in common-tasks. Our physics-based intuition would suggest that such representations are "incomplete", which indicates a gap in our understanding. This work proposes a tomographic interpretation of structure-property relations of materials to bridge that gap by defining what is a material representation, material properties, the material and the relationships between these three concepts using ideas from information theory. We verify this framework performing an exhaustive comparison of property-augmented representations on a range of material's property prediction objectives, providing insight into how different properties can encode complementary information.


---
# Neural Network Modeling of Microstructure Complexity Using Digital Libraries

## 基于数字图书馆的微结构复杂性神经网络建模

Link: https://arxiv.org/abs/2501.18189

**Authors:** Yingjie Zhao, Zhiping Xu

arXiv:2501.18189v1 Announce Type: cross 
Abstract: Microstructure evolution in matter is often modeled numerically using field or level-set solvers, mirroring the dual representation of spatiotemporal complexity in terms of pixel or voxel data, and geometrical forms in vector graphics. Motivated by this analog, as well as the structural and event-driven nature of artificial and spiking neural networks, respectively, we evaluate their performance in learning and predicting fatigue crack growth and Turing pattern development. Predictions are made based on digital libraries constructed from computer simulations, which can be replaced by experimental data to lift the mathematical overconstraints of physics. Our assessment suggests that the leaky integrate-and-fire neuron model offers superior predictive accuracy with fewer parameters and less memory usage, alleviating the accuracy-cost tradeoff in contrast to the common practices in computer vision tasks. Examination of network architectures shows that these benefits arise from its reduced weight range and sparser connections. The study highlights the capability of event-driven models in tackling problems with evolutionary bulk-phase and interface behaviors using the digital library approach.


---
# Ultra-large mutually synchronized networks of 10 nm spin Hall nano-oscillators

## 10 nm自旋霍尔纳米振荡器的超大型相互同步网络

Link: https://arxiv.org/abs/2501.18321

**Authors:** Nilamani Behera, Avinash Kumar Chaurasiya, Akash Kumar, Roman Khymyn, Artem Litvinenko, Lakhan Bainsla, Ahmad A. Awad, Johan {\AA}kerman

arXiv:2501.18321v1 Announce Type: cross 
Abstract: While mutually interacting spin Hall nano-oscillators (SHNOs) hold great promise for wireless communication, neural networks, neuromorphic computing, and Ising machines, the highest number of synchronized SHNOs remains limited to $N$ = 64. Using ultra-narrow 10 and 20-nm nano-constrictions in W-Ta/CoFeB/MgO trilayers, we demonstrate mutually synchronized SHNO networks of up to $N$ = 105,000. The microwave power and quality factor scale as $N$ with new record values of 9 nW and $1.04 \times 10^6$, respectively. An unexpectedly strong array size dependence of the frequency-current tunability is explained by magnon exchange between nano-constrictions and magnon losses at the array edges, further corroborated by micromagnetic simulations and Brillouin light scattering microscopy. Our results represent a significant step towards viable SHNO network applications in wireless communication and unconventional computing.


---
# DeepExtractor: Time-domain reconstruction of signals and glitches in gravitational wave data with deep learning

## DeepExtractor: 通过深度学习对引力波数据中的信号和毛刺进行时域重建

Link: https://arxiv.org/abs/2501.18423

**Authors:** Tom Dooney, Harsh Narola, Stefano Bromuri, R. Lyana Curier, Chris Van Den Broeck, Sarah Caudill, Daniel Stanley Tan

arXiv:2501.18423v1 Announce Type: cross 
Abstract: Gravitational wave (GW) interferometers, detect faint signals from distant astrophysical events, such as binary black hole mergers. However, their high sensitivity also makes them susceptible to background noise, which can obscure these signals. This noise often includes transient artifacts called "glitches" that can mimic astrophysical signals or mask their characteristics. Fast and accurate reconstruction of both signals and glitches is crucial for reliable scientific inference. In this study, we present DeepExtractor, a deep learning framework designed to reconstruct signals and glitches with power exceeding interferometer noise, regardless of their source. We design DeepExtractor to model the inherent noise distribution of GW interferometers, following conventional assumptions that the noise is Gaussian and stationary over short time scales. It operates by predicting and subtracting the noise component of the data, retaining only the clean reconstruction. Our approach achieves superior generalization capabilities for arbitrary signals and glitches compared to methods that directly map inputs to the clean training waveforms. We validate DeepExtractor's effectiveness through three experiments: (1) reconstructing simulated glitches injected into simulated detector noise, (2) comparing performance with the state-of-the-art BayesWave algorithm, and (3) analyzing real data from the Gravity Spy dataset to demonstrate effective glitch subtraction from LIGO strain data. DeepExtractor achieves a median mismatch of only 0.9% for simulated glitches, outperforming several deep learning baselines. Additionally, DeepExtractor surpasses BayesWave in glitch recovery, offering a dramatic computational speedup by reconstructing one glitch sample in approx. 0.1 seconds on a CPU, compared to BayesWave's processing time of approx. one hour per glitch.


---
# adabmDCA 2.0 -- a flexible but easy-to-use package for Direct Coupling Analysis

## adabmDCA 2.0-一个灵活但易于使用的软件包，用于直接耦合分析

Link: https://arxiv.org/abs/2501.18456

**Authors:** Lorenzo Rosset, Roberto Netti, Anna Paola Muntoni, Martin Weigt, Francesco Zamponi

arXiv:2501.18456v1 Announce Type: cross 
Abstract: In this methods article, we provide a flexible but easy-to-use implementation of Direct Coupling Analysis (DCA) based on Boltzmann machine learning, together with a tutorial on how to use it. The package \texttt{adabmDCA 2.0} is available in different programming languages (C++, Julia, Python) usable on different architectures (single-core and multi-core CPU, GPU) using a common front-end interface. In addition to several learning protocols for dense and sparse generative DCA models, it allows to directly address common downstream tasks like residue-residue contact prediction, mutational-effect prediction, scoring of sequence libraries and generation of artificial sequences for sequence design. It is readily applicable to protein and RNA sequence data.


---
# Sample Classification using Machine Learning-Assisted Entangled Two-Photon Absorption

## 使用机器学习辅助的纠缠双光子吸收进行样本分类

Link: https://arxiv.org/abs/2501.18534

**Authors:** \'Aulide Mart\'inez-Tapia, Roberto de J. Le\'on-Montiel

arXiv:2501.18534v1 Announce Type: cross 
Abstract: Entangled two-photon absorption (eTPA) has been recognized as a potentially powerful tool for the implementation of ultra-sensitive spectroscopy. Unfortunately, there exists a general agreement in the quantum optics community that experimental eTPA signals, particularly those obtained from molecular solutions, are extremely weak. Consequently, obtaining spectroscopic information about an arbitrary sample via conventional methods rapidly becomes an unrealistic endeavor. To address this problem, we introduce an experimental scheme that reduces the amount of data needed to identify and classify unknown samples via their electronic structure. Our proposed method makes use of machine learning (ML) to extract information about the number of intermediate levels that participate in the two-photon excitation of the absorbing medium. This is achieved by training artificial neural networks (ANNs) with various eTPA signals where the delay between the absorbed photons is externally controlled. Inspired by multiple experimental studies of eTPA, we consider model systems comprising one to four intermediate levels, whose energies are randomly chosen from four different intermediate-level band gaps, namely: $\Delta\lambda = 10$, $20$, $30$, and $40$ nm. Within these band gaps, and with the goal of testing the efficiency of our artificial intelligence algorithms, we make use of three different wavelength spacing $1$, $0.5$ and $0.1$ nm. We find that for a proper entanglement time between the absorbed photons, classification average efficiencies exceed 99$\%$ for all configurations. Our results demonstrate the potential of artificial neural networks for facilitating the experimental implementation of eTPA spectroscopy.


---
# PyMoosh : a comprehensive numerical toolkit for computing the optical properties of multilayered structures

## PyMoosh: 用于计算多层结构光学特性的综合数值工具包

Link: https://arxiv.org/abs/2309.00654

**Authors:** Denis Langevin, Pauline Bennet, Abdourahman Khaireh-Walieh, Peter Wiecha, Olivier Teytaud, Antoine Moreau

arXiv:2309.00654v3 Announce Type: replace 
Abstract: We present PyMoosh, a Python-based simulation library designed to provide a comprehensive set of numerical tools allowing to compute essentially all optical characteristics of multilayered structures, ranging from reflectance and transmittance to guided modes and photovoltaic efficiency. PyMoosh is designed not just for research purposes, but also for use-cases in education. To this end, we have invested significant effort in ensuring user-friendliness and simplicity of the interface. PyMoosh has been developed in line with the principles of Open Science and taking into account the fact that multilayered structures are increasingly being used as a testing ground for optimization and deep learning approaches. We provide in this paper the theoretical basis at the core of PyMoosh, an overview of its capabilities, as well as a comparison between the different numerical methods implemented in terms of speed and stability. We are convinced such a versatile tool will be useful for the community in many ways.


---
# Braided interferometer mesh for robust photonic matrix-vector multiplications with non-ideal components

## 用于具有非理想分量的鲁棒光子矩阵矢量乘法的编织干涉仪网格

Link: https://arxiv.org/abs/2411.02243

**Authors:** Federico Marchesin, Mat\v{e}j Hejda, Tzamn Melendez Carmona, Stefano Di Carlo, Alessandro Savino, Fabio Pavanello, Thomas Van Vaerenbergh, Peter Bienstman

arXiv:2411.02243v2 Announce Type: replace 
Abstract: Matrix-vector multiplications (MVMs) are essential for a wide range of applications, particularly in modern machine learning and quantum computing. In photonics, there is growing interest in developing architectures capable of performing linear operations with high speed, low latency, and minimal loss. Traditional interferometric photonic architectures, such as the Clements design, have been extensively used for MVM operations. However, as these architectures scale, improving stability and robustness becomes critical. In this paper, we introduce a novel photonic braid interferometer architecture that outperforms both the Clements and Fldzhyan designs in these aspects. Using numerical simulations, we evaluate the performance of these architectures under ideal conditions and systematically introduce non-idealities such as insertion losses, beam splitter imbalances, and crosstalk. The results demonstrate that the braid architecture offers superior robustness due to its symmetrical design and reduced layer count. Further analysis shows that the braid architecture is particularly advantageous in large-scale implementations, delivering better performance as the size of the interferometer increases. We also assess the footprint and total insertion losses of each architecture. Although waveguide crossings in the braid architecture slightly increase the footprint and insertion loss, recent advances in crossing technology significantly minimize these effects. Our study suggests that the braid architecture is a robust solution for photonic neuromorphic computing, maintaining high fidelity in realistic conditions where imperfections are inevitable.


---
# Quantification of Uncertainty and Its Propagation in Seismic Velocity Structure and Earthquake Source Inversion

## 地震速度结构和震源反演中不确定性的量化及其传播

Link: https://arxiv.org/abs/2411.17997

**Authors:** Ryoichiro Agata

arXiv:2411.17997v2 Announce Type: replace 
Abstract: In earthquake source inversions aimed at understanding diverse fault activities on earthquake faults using seismic observation data, uncertainties in velocity structure models are typically not considered. As a result, biases and underestimations of uncertainty can occur in source inversion. This article provides an overview of the author's efforts to address this issue by quantitatively evaluating the uncertainty in velocity structure models and appropriately accounting for its propagation into source inversion. First, the Bayesian multi-model source inversion method that can incorporate such uncertainties as probability distributions in the form of ensembles is explained. Next, a Bayesian traveltime tomography technique utilizing physics-informed neural networks (PINN) to quantify uncertainties in velocity structure models is introduced. Furthermore, the author's recent efforts to integrate these methods and apply them to hypocenter determination in the Nankai Trough region are briefly discussed. The article also outlines future prospects of source inversions considering uncertainties in velocity structure models and the anticipated role of the emerging scientific machine learning (SciML) methods such as PINN.


---
# FLRONet: Deep Operator Learning for High-Fidelity Fluid Flow Field Reconstruction from Sparse Sensor Measurements

## FLRONet: 基于稀疏传感器测量的高保真流体流场重建的深度算子学习

Link: https://arxiv.org/abs/2412.08009

**Authors:** Hiep Vo Dang, Joseph B. Choi, Phong C. H. Nguyen

arXiv:2412.08009v3 Announce Type: replace 
Abstract: Reconstructing high-fidelity fluid flow fields from sparse sensor measurements is vital for many science and engineering applications but remains challenging because of dimensional disparities between state and observational spaces. Due to such dimensional differences, the measurement operator becomes ill-conditioned and non-invertible, making the reconstruction of flow fields from sensor measurements extremely difficult. Although sparse optimization and machine learning address the above problems to some extent, questions about their generalization and efficiency remain, particularly regarding the discretization dependence of these models. In this context, deep operator learning offers a better solution as this approach models mappings between infinite-dimensional functional spaces, enabling superior generalization and discretization-independent reconstruction. We introduce FLRONet, a deep operator learning framework that is trained to reconstruct fluid flow fields from sparse sensor measurements. FLRONet employs a branch-trunk network architecture to represent the inverse measurement operator that maps sensor observations to the original flow field, a continuous function of both space and time. Validation performed on the CFDBench dataset has demonstrated that FLRONet consistently achieves high levels of reconstruction accuracy and robustness, even in scenarios where sensor measurements are inaccurate or missing. Furthermore, the operator learning approach endows FLRONet with the capability to perform zero-shot super-resolution in both spatial and temporal domains, offering a solution for rapid reconstruction of high-fidelity flow fields.


---
# Data-driven assessment of optimal spatiotemporal resolutions for information extraction in noisy time series data

## 噪声时间序列数据中信息提取的最佳时空分辨率的数据驱动评估

Link: https://arxiv.org/abs/2412.13741

**Authors:** Domiziano Doria, Simone Martino, Matteo Becchi, Giovanni M. Pavan

arXiv:2412.13741v3 Announce Type: replace 
Abstract: In general, comprehension of any type of complex system depends on the resolution used to examine the phenomena occurring within it. However, identifying a priori, for example, the best time frequencies/scales to study a certain system over-time, or the spatial distances at which correlations, symmetries, and fluctuations are, most often non-trivial. Here we describe an unsupervised approach that, starting solely from the data of a system, allows learning the characteristic length scales of the dominant key events/processes and the optimal spatiotemporal resolutions to characterize them. We tested this approach on time series data obtained from simulation or experimental trajectories of various example many-body complex systems ranging from the atomic to the macroscopic scale and having diverse internal dynamic complexities. Our method automatically analyzes the system data by analyzing correlations at all relevant inter-particle distances and at all possible inter-frame intervals in which their time series can be subdivided, namely, at all space and time resolutions.The optimal spatiotemporal resolution for studying a certain system thus maximizes information extraction and classification from the system's data, which we prove to be related to the characteristic spatiotemporal length scales of the local/collective physical events dominating it. This approach is broadly applicable and can be used to optimize the study of different types of data (static distributions, time series, or signals). The concept of 'optimal resolution' has a general character and provides a robust basis for characterizing any type of system based on its data, as well as to guide data analysis in general.


---
# Perspectives: Comparison of Deep Learning Segmentation Models on Biophysical and Biomedical Data

## 观点: 生物物理和生物医学数据上深度学习分割模型的比较

Link: https://arxiv.org/abs/2408.07786

**Authors:** J Shepard Bryan IV, Pedro Pessoa, Meyam Tavakoli, Steve Presse

arXiv:2408.07786v2 Announce Type: replace-cross 
Abstract: Deep learning based approaches are now widely used across biophysics to help automate a variety of tasks including image segmentation, feature selection, and deconvolution. However, the presence of multiple competing deep learning architectures, each with its own unique advantages and disadvantages, makes it challenging to select an architecture best suited for a specific application. As such, we present a comprehensive comparison of common models. Here, we focus on the task of segmentation assuming the typically small training dataset sizes available from biophysics experiments and compare the following four commonly used architectures: convolutional neural networks, U-Nets, vision transformers, and vision state space models. In doing so, we establish criteria for determining optimal conditions under which each model excels, thereby offering practical guidelines for researchers and practitioners in the field.


---
# Constructing multicomponent cluster expansions with machine-learning and chemical embedding

## 通过机器学习和化学嵌入构建多组分簇扩展

Link: https://arxiv.org/abs/2409.06071

**Authors:** Yann L. M\"uller, Anirudh Raju Natarajan

arXiv:2409.06071v2 Announce Type: replace-cross 
Abstract: Cluster expansions are commonly employed as surrogate models to link the electronic structure of an alloy to its finite-temperature properties. Using cluster expansions to model materials with several alloying elements is challenging due to a rapid increase in the number of fitting parameters and training set size. We introduce the embedded cluster expansion (eCE) formalism that enables the parameterization of accurate on-lattice surrogate models for alloys containing several chemical species. The eCE model simultaneously learns a low dimensional embedding of site basis functions along with the weights of an energy model. A prototypical senary alloy comprised of elements in groups 5 and 6 of the periodic table is used to demonstrate that eCE models can accurately reproduce ordering energetics of complex alloys without a significant increase in model complexity. Further, eCE models can leverage similarities between chemical elements to efficiently extrapolate into compositional spaces that are not explicitly included in the training dataset. The eCE formalism presented in this study unlocks the possibility of employing cluster expansion models to study multicomponent alloys containing several alloying elements.


---
# An information-matching approach to optimal experimental design and active learning

## 优化实验设计和主动学习的信息匹配方法

Link: https://arxiv.org/abs/2411.02740

**Authors:** Yonatan Kurniawan (Brigham Young University, Provo, UT, USA), Tracianne B. Neilsen (Brigham Young University, Provo, UT, USA), Benjamin L. Francis (Achilles Heel Technologies, Orem, UT, USA), Alex M. Stankovic (SLAC National Accelerator Laboratory, Menlo Park, CA, USA), Mingjian Wen (University of Houston, Houston, TX, USA), Ilia Nikiforov (University of Minnesota, Minneapolis, MN, USA), Ellad B. Tadmor (University of Minnesota, Minneapolis, MN, USA), Vasily V. Bulatov (Lawrence Livermore National Laboratory), Vincenzo Lordi (Lawrence Livermore National Laboratory), Mark K. Transtrum (Brigham Young University, Provo, UT, USA, SLAC National Accelerator Laboratory, Menlo Park, CA, USA)

arXiv:2411.02740v2 Announce Type: replace-cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.


---
# Energy-based physics-informed neural network for frictionless contact problems under large deformation

## 基于能量的物理神经网络用于大变形下的无摩擦接触问题

Link: https://arxiv.org/abs/2411.03671

**Authors:** Jinshuai Bai, Zhongya Lin, Yizheng Wang, Jiancong Wen, Yinghua Liu, Timon Rabczuk, YuanTong Gu, Xi-Qiao Feng

arXiv:2411.03671v2 Announce Type: replace-cross 
Abstract: Numerical methods for contact mechanics are of great importance in engineering applications, enabling the prediction and analysis of complex surface interactions under various conditions. In this work, we propose an energy-based physics-informed neural network (PINNs) framework for solving frictionless contact problems under large deformation. Inspired by microscopic Lennard-Jones potential, a surface contact energy is used to describe the contact phenomena. To ensure the robustness of the proposed PINN framework, relaxation, gradual loading and output scaling techniques are introduced. In the numerical examples, the well-known Hertz contact benchmark problem is conducted, demonstrating the effectiveness and robustness of the proposed PINNs framework. Moreover, challenging contact problems with the consideration of geometrical and material nonlinearities are tested. It has been shown that the proposed PINNs framework provides a reliable and powerful tool for nonlinear contact mechanics. More importantly, the proposed PINNs framework exhibits competitive computational efficiency to the commercial FEM software when dealing with those complex contact problems. The codes used in this manuscript are available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code will be available after acceptance)


---
# Advancing Natural Orbital Functional Calculations Through Deep Learning-Inspired Techniques for Large-Scale Strongly Correlated Electron Systems

## 通过深度学习技术推进大规模强相关电子系统的自然轨道功能计算

Link: https://arxiv.org/abs/2411.18493

**Authors:** Juan Felipe Huan Lew-Yee, Jorge M. del Campo, Mario Piris

arXiv:2411.18493v2 Announce Type: replace-cross 
Abstract: Natural orbital functional (NOF) theory offers a promising approach for studying strongly correlated systems at an affordable computational cost, with an accuracy comparable to highly demanding wavefunction-based methods. However, its widespread adoption in cases involving a large number of correlated electrons has been limited by the extensive iterations required for convergence. In this work, we present a disruptive approach that embeds the techniques used for optimization in deep learning within the NOF calculation, constituting a substantial advance in the scale of accessible systems. The revamped procedure is based on the adaptive momentum technique for orbital optimization, alternated with the optimization of the occupation numbers, significantly improving the computational feasibility of challenging calculations. This work represents a complete change in the size scale of the systems that can be reached using NOF theory. We demonstrate this with three examples that involve a large number of electrons: (i) the symmetric dissociation of a large hydrogen cluster, (ii) an analysis of occupancies distribution in fullerenes, and (iii) a study of the singlet-triplet energy gap in linear acenes. Notably, the hydrogen cluster calculation, featuring 1000 electrons, represents the largest NOF calculation performed to date and one of the largest strongly correlated electron calculations ever reported. This system, which serves as an ideal model for a strongly correlated Mott insulator, illustrates a metal-to-insulator transition where all electrons participate in the correlation phenomenon, offering insight in a unique challenge. We anticipate that this work will enable the practical application of NOFs to increasingly complex and intriguing systems, leveraging the method's inherent scalability and accuracy.


---
# Machine learning-driven conservative-to-primitive conversion in hybrid piecewise polytropic and tabulated equations of state

## 混合分段多变和表格状态方程中机器学习驱动的保守到原始转换

Link: https://arxiv.org/abs/2412.07836

**Authors:** Semih Kacmaz, Roland Haas, E. A. Huerta

arXiv:2412.07836v2 Announce Type: replace-cross 
Abstract: We present a novel machine learning (ML) method to accelerate conservative-to-primitive inversion, focusing on hybrid piecewise polytropic and tabulated equations of state. Traditional root-finding techniques are computationally expensive, particularly for large-scale relativistic hydrodynamics simulations. To address this, we employ feedforward neural networks (NNC2PS and NNC2PL), trained in PyTorch and optimized for GPU inference using NVIDIA TensorRT, achieving significant speedups with minimal accuracy loss. The NNC2PS model achieves $ L_1 $ and $ L_\infty $ errors of $ 4.54 \times 10^{-7} $ and $ 3.44 \times 10^{-6} $, respectively, while the NNC2PL model exhibits even lower error values. TensorRT optimization with mixed-precision deployment substantially accelerates performance compared to traditional root-finding methods. Specifically, the mixed-precision TensorRT engine for NNC2PS achieves inference speeds approximately 400 times faster than a traditional single-threaded CPU implementation for a dataset size of 1,000,000 points. Ideal parallelization across an entire compute node in the Delta supercomputer (Dual AMD 64 core 2.45 GHz Milan processors; and 8 NVIDIA A100 GPUs with 40 GB HBM2 RAM and NVLink) predicts a 25-fold speedup for TensorRT over an optimally-parallelized numerical method when processing 8 million data points. Moreover, the ML method exhibits sub-linear scaling with increasing dataset sizes. We release the scientific software developed, enabling further validation and extension of our findings. This work underscores the potential of ML, combined with GPU optimization and model quantization, to accelerate conservative-to-primitive inversion in relativistic hydrodynamics simulations.


---
# Bayesian Flow Is All You Need to Sample Out-of-Distribution Chemical Spaces

## 贝叶斯流是采样分布外化学空间所需的全部

Link: https://arxiv.org/abs/2412.11439

**Authors:** Nianze Tao

arXiv:2412.11439v2 Announce Type: replace-cross 
Abstract: Generating novel molecules with higher properties than the training space, namely the out-of-distribution generation, is important for ${de~novo}$ drug design. However, it is not easy for distribution learning-based models, for example diffusion models, to solve this challenge as these methods are designed to fit the distribution of training data as close as possible. In this paper, we show that Bayesian flow network is capable of effortlessly generating high quality out-of-distribution samples that meet several scenarios. We introduce a semi-autoregressive training/sampling method that helps to enhance the model performance and surpass the state-of-the-art models.


---
# Applications of machine learning in ion beam analysis of materials

## 机器学习在材料离子束分析中的应用

Link: https://arxiv.org/abs/2412.12312

**Authors:** Tiago Fiorini da Silva

arXiv:2412.12312v2 Announce Type: replace-cross 
Abstract: Ion Beam Analysis (IBA) is an established tool for material characterization, providing precise information on elemental composition, depth profiles, and structural information in the region near the surface of materials. However, traditional data processing methods can be slow and computationally intensive, limiting the efficiency and speed of the analysis. This article explores the current landscape of applying Machine Learning Algorithms (MLA) in the field of IBA, demonstrating the immense potential to optimize and accelerate processes. We present how ML has been employed to extract valuable insights from large datasets, automate repetitive tasks, and enhance the interpretability of results, with practical examples of applications in various IBA techniques, such as RBS, PIXE, and others. Finally, perspectives on using MLA to approach open problems in IBA are also discussed.


---
# Bayesian Illumination: Inference and Quality-Diversity Accelerate Generative Molecular Models

## 贝叶斯照明: 推理和质量多样性加速生成分子模型

Link: https://dx.doi.org/10.26434/chemrxiv-2024-tqf0x-v3?rft_dat=source%3Ddrss

**Authors:** Jonas, Verhellen

In recent years, there have been considerable academic and industrial research efforts to develop novel generative models for high-performing, small molecules. Traditional, rules-based algorithms such as genetic algorithms [Jensen, Chem. Sci., 2019, 12, 3567-3572] have, however, been shown to rival deep learning approaches in terms of both efficiency and potency. In previous work, we showed that the addition of a quality-diversity archive to a genetic algorithm resolves stagnation issues and substantially increases search efficiency [Verhellen, Chem. Sci., 2020, 42, 11485-11491]. In this work, we expand on these insights and leverage the availability of bespoke kernels for small molecules [Griffiths, Adv. Neural. Inf. Process. Syst., 2024, 36] to integrate Bayesian optimisation into the quality-diversity process. This novel generative model, which we call Bayesian Illumination, produces a larger diversity of high-performing molecules than standard quality-diversity optimisation methods. In addition, we show that Bayesian Illumination further improves search efficiency com- pared to previous generative models for small molecules, including deep learning approaches, genetic algorithms, and standard quality-diversity methods.


---
# ART-SM: Boosting Fragment-based Backmapping by Machine Learning

## Art-sm: 通过机器学习提升基于片段的反向映射

Link: https://dx.doi.org/10.26434/chemrxiv-2024-mcv45-v2?rft_dat=source%3Ddrss

**Authors:** Benjamin, Unger

In sequential multiscale molecular dynamics simulations, which advantageously combine the increased sampling and dynamics at coarse-grained resolution with the higher accuracy of atomistic simulations, the resolution is altered over time. While coarse-graining is straightforward once the mapping between atomistic and coarse-grained resolution is defined, reintroducing the atomistic details is still a non-trivial process called backmapping. Here, we present ART-SM, a fragment-based backmapping framework that learns from atomistic simulation data to seamlessly switch from coarse-grained to atomistic resolution. ART-SM requires minimal user input and goes beyond state-of-the-art fragment-based approaches by selecting from multiple conformations per fragment via machine learning to simultaneously reflect the coarse-grained structure and the Boltzmann distribution. Additionally, we introduce a novel refinement step to connect individual fragments by optimizing specific bonds, angles, and dihedral angles in the backmapping process.     We demonstrate that our algorithm accurately restores the atomistic bond length, angle, and dihedral angle distributions for various small and linear molecules from Martini coarse-grained beads and that the resulting high-resolution structures are representative of the input coarse-grained conformations.      Moreover, the reconstruction of the TIP3P water model is fast and robust, and we demonstrate that ART-SM can be applied to larger linear molecules as well.     To illustrate the efficiency of the local and autoregressive approach of ART-SM, we simulated a large realistic system containing the surfactants TAPB and SDS in solution using the Martini3 force field. The self-assembled micelles of various shapes were backmapped with ART-SM after training on only short atomistic simulations of a single water-solvated SDS or TAPB molecule.     Together, these results indicate the potential for the method to be extended to more complex molecules such as lipids, proteins, macromolecules, and materials in the future.


---
# Investigation of Arenes and Heteroarenes Nitration supported by High-Throughput Experimentation and Machine Learning

## 高通量实验和机器学习支持的芳烃和杂芳烃硝化研究

Link: https://dx.doi.org/10.26434/chemrxiv-2025-5t1h2-v2?rft_dat=source%3Ddrss

**Authors:** Clément, Wespiser

Access to the nitro functional group is a very common and longstanding transformation of interest in many fields of chemistry. However, the robustness and specificity of this transformation can remain challenging, particularly in the case of heteroarene nitration. From this observation, a large investigation was initiated to screen nitration conditions on various arenes and heteroarenes. The systematical and diverse study of both nitrating agents and activating reagents was conducted using high-throughput experimentation, to afford high quantity and high quality data generation. General trends have been identified and correlated to the electronic property of the heteroarene, notably the difficult nitration of electron-poor heteroarenes was highlighted. Original combinations of reagents were found to perform well in nitration reactions. The obtained data were also used to design a predictive tool relying on machine learning in order to provide the best nitration reaction conditions depending on the targeted substrate. The limited predictive efficiency obtained pointed out the importance of the diversification and the chemically relevant encoding of the data set.


---
# Deep Learning-based Image Caption Generator for Real-time Monitoring and Predictive Control of Concentration of Polluting gases

## 基于深度学习的图像字幕生成器，用于实时监测和预测控制污染气体的浓度

Link: https://dx.doi.org/10.26434/chemrxiv-2025-45zp2?rft_dat=source%3Ddrss

**Authors:** Kedarnath, Senapati

The automatic generation of image captions in natural language is a critical and challenging task, particularly in the context of environmental monitoring and control. This paper presents a novel deep learning-driven image captioning system designed for real-time monitoring and predictive control of pollutant gas concentrations. The proposed system leverages advanced machine learning techniques to analyze images captured during gas capture processes, generating semantically rich and grammatically accurate captions that describe the visual content. At the core of the system is a hybrid architecture that integrates a Convolutional Neural Network (CNN) for high-level feature extraction from input images and a Gated Recurrent Unit (GRU) for sequential caption generation. The CNN effectively identifies and extracts relevant features from the images, while the GRU models the temporal dependencies inherent in the data, allowing for the generation of coherent and contextually appropriate captions. This dual approach not only enhances the accuracy of the captions but also facilitates a deeper understanding of the processes being monitored. In addition to caption generation, the system incorporates a predictive control module that utilizes the generated captions to forecast future behaviors of the gas capture processes. This predictive capability enables operators to make informed decisions, optimizing the efficiency and effectiveness of pollutant gas management in industrial applications. The proposed system demonstrates significant potential for real-time applications, providing a robust tool for environmental monitoring and control. By enabling the efficient and sustainable utilization of gases, this innovative approach contributes to the broader goal of reducing environmental impact and promoting cleaner industrial practices. The results indicate that deep learning techniques can significantly enhance the capabilities of image captioning systems, paving the way for their application in various domains beyond environmental monitoring.


---
# Data-Driven Kinetic Reaction Networks for Separation Chemistry

## 数据驱动的分离化学动力学反应网络

Link: https://dx.doi.org/10.26434/chemrxiv-2025-g7gp3?rft_dat=source%3Ddrss

**Authors:** Danny, Perez

Understanding complex, multi-step chemical reactions at the molecular level is a major challenge whose solution would greatly benefit the design and optimization of numerous chemical processes. The separation of rare-earth (4f) and actinide (5f) elements is an example where improving our chemical understanding is important for designing and optimizing new chemistries, even with a limited number of observations. In this work, we leverage data-driven artificial intelligence and machine-learning approaches to develop kinetic reaction networks that describe the liquid-liquid extraction mechanism of uranium using N,N-di-2-ethylhexyl-isobutyramide (DEHiBA). Specifically, we compare and contrast the properties of two classes of models: (1) purely data-driven models that are regularized using chemistry-agnostic, L1 regression and (2) chemistry-informed models which are regularized using relative reaction energies provided by quantum mechanical calculations. We observe that purely data-driven models are unbiased, simple, and accurate in their predictions of experimental measurements when provided with sufficient data but are difficult to fully constrain and interpret. In contrast, chemistry-informed models exhibit significantly improved chemical interpretability and consistency, providing a detailed description of the separation process, while achieving high accuracy through ensemble averaging. Overall, the dominant species predicted to be extracted into the organic phase is UO2(NO3)2(DEHiBA)2, agreeing with experimental slope analysis, thermodynamic modeling, EXAFS, and crystal structures. This work demonstrates that leveraging the fundamental structure of the problem can lead to efficient learning schemes that provide both accurate predictions and chemical insights at low computational cost.


---
# Molecular Simulations with a Pretrained Neural Network and Universal Pairwise Force Fields

## 具有预训练神经网络和通用成对力场的分子模拟

Link: https://dx.doi.org/10.26434/chemrxiv-2024-bdfr0-v2?rft_dat=source%3Ddrss

**Authors:** Alexandre, Tkatchenko

Machine Learning Force Fields (MLFFs) promise to enable general molecular simulations that can simultaneously achieve efficiency, accuracy, transferability, and scalability for diverse molecules, materials, and hybrid interfaces. A key step toward this goal has been made with the GEMS approach to biomolecular dynamics [Sci. Adv. 10, eadn4397 (2024)]. This work introduces the SO3LR method that integrates the fast and stable SO3krates neural network for semi-local interactions with universal pairwise force fields designed for short-range repulsion, long-range electrostatics, and dispersion interactions. SO3LR is trained on a diverse set of 4 million neutral and charged molecular complexes computed at the PBE0+MBD level of quantum mechanics, ensuring a comprehensive coverage of covalent and non-covalent interactions. Our approach is characterized by computational and data efficiency, scalability to 200 thousand atoms on a single GPU, and reasonable to high accuracy across the chemical space of organic (bio)molecules. SO3LR is applied to study units of four major biomolecule types, polypeptide folding, and nanosecond dynamics of larger systems such as a protein, a glycoprotein, and a lipid bilayer, all in explicit solvent. Finally, we discuss the future challenges toward truly general molecular simulations by combining MLFFs with traditional atomistic models.


---
# Deep Learning Applications in the Resilience Critical Infrastructure Systems&mdash;A Systematic Review

## 深度学习在弹性关键基础设施系统中的应用 -- 系统性综述

Link: https://www.researchsquare.com/article/rs-5923379/latest

Technological advancements like AI, blockchain, and IoT are merging to bring about a new level of digital change. Critical infrastructure systems (CISs) are vital to modern society, as they support crucial social functions, economic organization, and national defense. Recently, the resilience of CISs has garnered attention in academic and policy fields, particularly in light of increased natural and technological disasters. However, assessing CIS resilience remains challenging, particularly in its practical application to operational risk management. Integrating advanced technologies with critical infrastructure (CI) can significantly enhance the quality of life and boost national economic productivity. Nevertheless, the lack of robust cybersecurity in CI has given rise to advanced threats and vulnerabilities, undermining these potential benefits. The paper explores cyber vulnerabilities and dangers in various critical structures, including the financial, agricultural, energy, and health systems. Moreover, we examine the positive aspects of artificial intelligence and provide a rich taxonomy of solutions that show how well AI-based approaches deal with different types of cyberattacks on critical infrastructure.


---
# Attention-Based Deep Learning Models: A Comparative Study of VGG19 and MobileNet for Chest X-Ray Image Classification

## 基于注意的深度学习模型: VGG19和MobileNet在胸部x线图像分类中的比较研究

Link: https://www.researchsquare.com/article/rs-5902187/latest

This study looks into a cutting-edge deep learning system to sort chest X-ray (CXR) pictures into four groups: Normal, Pneumonia, COVID-19, and Other Lung Diseases. The research team boosted VGG19 and Mobile Net designs with Multi-Head Attention tricks to get better at pulling out features and zeroing in on areas that matter for spotting diseases.  They worked with a dataset of 15,000 tagged images, which they cleaned up using standardization and tweaking methods to make the models work better across the board. Tests showed that Mobile Net beat VGG19 hitting 98.1% accuracy, 0.97 precision, and 0.96 recall. Adding attention tricks made the diagnosis more precise for tricky cases like COVID-19. Plus, Mobile Net got up to speed faster and didn't need as much computing power making it a better fit for on-the-spot use. This work highlights how attention-boosted lightweight models could streamline how doctors diagnose issues, take some pressure off radiologists, and bring better care to places without a lot of resources. The next steps include fine-tuning the model, growing the dataset, and putting it to work in the real world to help with automated diagnosis support.


---
# Predicting Euler Characteristics Using Machine Learning and Skyrmion Number Computation

## 使用机器学习和Skyrmion数计算预测Euler特性

Link: https://www.researchsquare.com/article/rs-5892442/latest

Our study investigates the method to obtain topological properties of input images with neural networks, not requiring training datasets. In the field of solid-state physics, research has been conducted to obtain topological properties of magnetic structures by analyzing the spin fields. Utilizing the approaches, our model generates a unit vector field interpreted as spin fields from various images and predicts the Euler characteristic of input images by computing the skyrmion number of the generated vector field. Even if the networks are trained by a single image of a fixed Euler characteristic, they successfully predict the Euler characteristics of the various images. The resulting spin configurations from independently trained neural networks are not unique due to the remaining degrees of freedom in the spin configuration. To further control the spin configuration by confining these degrees of freedom, we incorporate a magnetic Hamiltonian as an additional loss function, which includes exchange Interaction, Dzyaloshinskii-Moriya (DM) Interaction, and anisotropy. We validate the model on more complex geometrical shapes and apply it to practical tasks.


---
# IntelliStream: Leveraging Machine Learning for Enhanced Throughput, Performance Of Brokers By Log Analysis

## Intellisream: 利用机器学习提高吞吐量，通过日志分析提高经纪人的性能

Link: https://www.researchsquare.com/article/rs-5888416/latest

Optimizing the performance of real-time data streaming platforms is crucial in managing diverse and demanding workloads. This paper presents an innovative approach to auto-tune such platforms for enhanced throughput and overall performance using machine learning techniques. By analyzing garbage collection (GC) logs and broker logs, by employing regression models to identify performance bottlenecks and predict optimal configuration settings. The methodology involves extracting key metrics from the logs, training regression models to understand the relationship between these metrics and system performance, and then applying the models to fine-tune system parameters automatically. The proposed solution demonstrates potential to develop significant improvements in throughput and stability, offering a robust framework for dynamic performance optimization in complex data environ-ments. This approach not only enhances efficiency but also reduces the need for manual tuning, paving the way for more intelligent and autonomous data streaming infrastructures.


---
# Multi-scale and Multi-feature fusion speech emotion recognition based on cross-attention

## 基于交叉注意的多尺度多特征融合语音情感识别

Link: https://www.researchsquare.com/article/rs-5859778/latest

Speech Emotion Recognition (SER) which aims to help the machine to understand human emotions from speech, has emerged as an integral component within Human-computer Interaction (HCI). There are two critical challenges in the SER field. One is that rich emotional features at different scales cannot be well captured due to the restrictions of existing CNNs. The other is that due to the limitations of existing methods, it is difficult to fuse multiple feature information effectively. A multi-scale and multi-feature fusion speech emotion recognition model based on cross-attention is proposed in this paper. First, according to the characteristics of MFCC and log Mel spectrogram, 1D convolution and 2D convolution were used to extract their advanced features, respectively. Second, adding residual multi-scale module to convolutional neural networks aims at high-level emotional features at different scales and obtain richer fine-grained emotional features. Third, the features obtained after the convolutional neural network are fused using the cross-attention module, which aims to explicitly simulate the fine-grained interaction between multiple features and improve the effectiveness of multi-feature fusion. Finally, the fused features are fed to BiLSTM to extract temporal features, and it is fed into a fully connected classifier for emotion recognition. The experimental results on the benchmark dataset IEMOCAP show that this method improves WA and UA by 1.67% and 2.20% compared with other methods, respectively.


---
# A Face Recognition Based Attendance System with Geolocation and Real-Time Action Logging

## 基于人脸识别的具有地理定位和实时动作记录的考勤系统

Link: https://www.researchsquare.com/article/rs-5931462/latest

This paper introduces a cutting-edge face recognition-based attendance system, designed to address the limitations of traditional attendance methods through the integration of advanced machine learning, computer vision, and geospatial APIs. The system streamlines the attendance process by automating the identification and logging of attendees with high accuracy and efficiency. Key features include live video recognition for real-time face identification, an intuitive user registration module for enrolling new individuals, CSV-based logging for seamless data export and management, and geolocation-aware attendance tracking to ensure that records are not only time-accurate but also location-specific. This geospatial context provides valuable insights, particularly for distributed teams or multi-location setups. The implementation leverages Python, a versatile programming language, and integrates OpenCV for real-time video processing and face detection, ensuring quick and reliable face recognition even in dynamic environments. The graphical user interface (GUI) is developed using PyQt5, allowing for a user-friendly and responsive experience. This combination of powerful technologies ensures that the system is both scalable and adaptable, able to integrate easily into various organizational workflows, from small educational institutions to large-scale corporate environments. The system's practical application is validated through experimental results conducted in diverse settings, including workplaces, academic institutions, and security-sensitive environments. These results highlight the system&amp;rsquo;s exceptional accuracy, even under challenging conditions such as low lighting or crowded spaces. Furthermore, the system demonstrates its potential to enhance operational efficiency, reduce administrative overhead, and improve security by providing a reliable, context-aware solution for attendance management. In conclusion, this face recognition-based attendance system offers a modern, automated solution that combines the power of machine learning and computer vision with geospatial data, creating an intelligent, highly effective tool for attendance tracking across a wide range of industries and applications.


---
# Research on Employment Sentiment Analysis of College Graduates Based on Global and Local Key Fusion Features

## 基于全局与局部关键融合特征的高校毕业生就业情感分析研究

Link: https://www.researchsquare.com/article/rs-5824878/latest

The increasingly fierce competition in the job market has brought unprecedented pressure and challenges to college students who are struggling to find a job. In order to address the manual analysis insufficiency of the mental state of college graduates who are struggling to find a job, this paper proposes a method based on global and local key fusion features, in order to provide necessary manual intervention. Based on the rough set theory, the importance of employment sentiment-related words for college graduates is defined, and a local key information module is constructed to extract important words from interview data. Secondly, convolutional neural networks are used to mine the potential information regarding sentiment features of college graduates at both global and local scales. A channel attention module is introduced to enhance the model's ability to focus on sentiment features of job hunters without increasing the model size. At the same time, the pooling layer is adjusted to an overlapping pooling layer, and the network feature extraction performance is improved by combining the pooling strategy of multi-level pyramids. Finally, in order to effectively utilize the global information of the text and the local information of words, the sentiment information of the global and local regions is integrated to achieve multi-dimensional analysis of sentiment data collected by interviewing college graduates. The experimental results show that the algorithm can effectively obtain semantic information about the mood of college students counseled and accurately warn of the data reflecting negative emotion.


---
# Integrating AI-Driven Emotional Intelligence in Language Learning Platforms to Improve English Speaking Skills through Real-Time Adaptive Feedback

## 将AI驱动的情商整合到语言学习平台中，通过实时自适应反馈提高英语口语技能

Link: https://www.researchsquare.com/article/rs-5919944/latest

This groundbreaking study introduces the first-ever integration of emotional intelligence (EI) with artificial intelligence in English-speaking instruction through an emotionally adaptive language learning system. Through a mixed-method design, the research examined this innovative approach&rsquo;s impact on speaking proficiency among 40 high school students (aged 15-18) from Varamin County, Iran. The experimental group (n=20) engaged with the novel &ldquo;Amazon Alexa-Speak&rdquo; Speaking Assessment System, featuring AI-driven EI-based real-time feedback; in contrast, the control group (n=20) received conventional instruction over six sessions following a pretest to ensure group homogeneity. The study employed a concurrent mixed method design, collecting quantitative data through the &ldquo;Amazon Alexa-Speak&rdquo; Speaking Assessment System and the researcher-made perception questionnaire; qualitative data came from researcher-made classroom observation checklists and researcher-made semi-structured interviews (n=20), focusing on emotional state monitoring and anxiety reduction patterns. Statistical analyses revealed a significant positive correlation between EI and speaking performance (p &amp;lt; 0.05, &eta;2 = 0.42), with the experimental group showing substantially enhanced proficiency (F(1,38) = 24.63, p &amp;lt; 0.05). The system&rsquo;s emotional state detection algorithm demonstrated 94% accuracy in identifying and responding to learners&rsquo; affective states. This study presents a paradigm shift in language education technology by introducing the first system that simultaneously addresses cognitive and emotional aspects of language acquisition. The findings have significant implications for the global language learning market, particularly in addressing speaking anxiety and emotional barriers in language learning. This technology&rsquo;s scalability and cross-cultural applicability make it a potentially transformative solution for language education worldwide, opening new avenues for emotionally intelligent educational technology development.


---
# Digital Preservation of Microgestures in the Making Process of Indonesian Iconic Traditional Rattan Chair Using Immersive 360&deg; Learning Videos and Photogrammetry

## 使用沉浸式360 ° 学习视频和摄影测量法在印尼标志性传统藤椅的制作过程中微手势的数字保存

Link: https://www.researchsquare.com/article/rs-5876603/latest

Although rattan artifacts have been extensively archived, few studies have focused on documenting the knowledge and craftsmanship of artisans who create traditional rattan chairs. These skills often rely on tacit knowledge, which is challenging to capture and transfer. This study aimed to preserve the creation process of iconic Cirebon rattan chairs&amp;mdash;Papasan, Bahama, Kelek, Gentong, and Keong&amp;mdash;crafted for over 50 years by leveraging digitization techniques. By combining 360&amp;deg; video technology with photogrammetric techniques, the study produced immersive learning materials that effectively captured artisans' subtle and often difficult-to-observe micro-gestures. The 360&amp;deg; video technology recorded these intricate gestures, while photogrammetry generated realistic three-dimensional visualizations of the furniture and tools used. Visual recall testing demonstrated that these immersive learning videos effectively teach delicate and nuanced techniques unique to rattan chair-making, such as using the chest, knees, armpits, soles, and toes. Furthermore, the methods and findings of this study highlight the potential of 360&amp;deg; video technology in preserving other crafts that involve complex and precise manual skills.


---
# Integration of Historically Marginalized students&rsquo; and teachers&rsquo; identities, languages, and lived worlds in urban middle school science classrooms

## 城市中学科学教室中历史边缘化的学生和教师的身份，语言和生活世界的整合

Link: https://www.researchsquare.com/article/rs-4810023/latest

This qualitative case study explored the incorporation of students' funds of knowledge (FoK) by six middle school science teachers in diverse urban classrooms. Drawing from asset-based and culturally inclusive pedagogies, our study is based on the premise that students' diverse identities, languages, and lived experiences (i.e. FoK) are valuable resources for their learning. This study aimed to achieve three primary objectives: 1) explore how teachers recognized the diverse FoK of marginalized students, 2) examine the relationship between teachers' FoK and students' FoK, and 3) investigate the extent to which teachers integrated students' FoK into their teaching methods. Our analysis revealed that teachers' individual FoK backgrounds uniquely shaped how they identified and incorporated their students' FoK into the classroom, shedding light on the diverse approaches employed by teachers in delivering culturally relevant instruction.


---
# Research on Feature Scheduling Aggregation Clustering Model Based on Convolutional Neural Networks

## 基于卷积神经网络的特征调度聚合聚类模型研究

Link: https://www.researchsquare.com/article/rs-5889025/latest

This paper proposes a feature scheduling aggregation clustering model based on Convolutional Neural Networks (CNN), aiming to enhance the performance of clustering tasks using deep learning techniques. The model integrates the automatic feature extraction capability of CNN, the adaptive adjustment of feature scheduling, and the multi-band information integration of feature aggregation, thereby capturing the complex structures and subtle differences in data. Experimental results demonstrate the superiority of the model compared to existing algorithms and show good generalization ability. The model can effectively improve the effectiveness of cluster analysis, providing a new deep learning solution for data analysis.


---
# The Neuroeducation Approach to Language Learning: Exploring Learner Perception

## 语言学习的神经教育方法: 探索学习者的感知

Link: https://www.researchsquare.com/article/rs-5925283/latest

This study investigates learner perceptions of the LIRRA Neuroeducation Program (LIRRA-NP), a neuroeducation program designed to enhance second language (L2) acquisition and reading proficiency in intermediate undergraduate learners. Building upon previous research demonstrating the program's effectiveness (Yusuf, 2024), this study explores learner experiences with the program's implementation, content, design, and perceived impact on their language skills. Thirty intermediate-level English learners participated, completing an online questionnaire comprising scaled and open-ended questions where quantitative data were analyzed using descriptive statistics, and qualitative data were analyzed thematically. Results revealed overwhelmingly positive perceptions of the LIRRA-NP, with participants finding it interesting, motivating, relevant, and beneficial. They particularly appreciated the program's content, novelty, and engaging activities. This study contributes to the optimization of L2 acquisition through neuroeducation by providing valuable learner feedback to inform the development of future programs and enhance student-centered learning methods.


---
# Evaluating Gabor, Latent, and Fused Features for Zero-Shot DeepfakeDetection with Isolation Forest and OCSVM.A comparative Study

## 使用隔离森林和OCSV M.A比较研究评估零射击深度检测的Gabor，潜在和融合特征

Link: https://www.researchsquare.com/article/rs-5678475/latest

The prevalence of deepfake technology has led to increased risks to biometric security, social media integrity, and the useof audio and video content for disinformation. In response, studies have progressed to provide efficient detecting techniques.Specifically, this paper uses anomaly-based classifiers to give a comparative analysis of zero-shot learning-based deepfakedetection. We evaluate two classifiers: One-Class Support Vector Machine (OCSVM) and Isolation Forest (IF) with threedifferent feature settings: Gabor features, Latent features, and Fused features (a mix of Gabor and Latent features). Importantmeasures like F1 Score, Accuracy, Precision, and Recall are used to assess how well the classifiers perform. Our resultsprovide important insights and future directions into the relationship between feature types and classifier performance in thesetting of zero-shot learning.

