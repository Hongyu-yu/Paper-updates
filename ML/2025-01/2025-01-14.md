# Smooth Exact Gradient Descent Learning in Spiking Neural Networks

## 尖峰神经网络中的平滑精确梯度下降学习

Link: http://link.aps.org/doi/10.1103/PhysRevLett.134.027301

**Authors:** Christian Klos and Raoul-Martin Memmesheimer

Author(s): Christian Klos and Raoul-Martin Memmesheimer<br /><p>By incorporating electrical pulses with shapes similar to those of the spikes from biological neurons, researchers improved the ability to train energy-efficient types of neural networks.</p><img height="" src="http://cdn.journals.aps.org/journals/PRL/key_images/10.1103/PhysRevLett.134.027301.png" width="200" /><br />[Phys. Rev. Lett. 134, 027301] Published Mon Jan 13, 2025


---
# Inference of the Mass Composition of Cosmic Rays with Energies from ${10}^{18.5}$ to ${10}^{20}\text{ }\text{ }\mathrm{eV}$ Using the Pierre Auger Observatory and Deep Learning

## 使用Pierre Auger天文台和深度学习推断能量从 ${10 }^{ 18.5}$ 到 ${10 }^{ 20}\ text{ }\ mathrm{eV}$ 的宇宙射线的质量组成

Link: http://link.aps.org/doi/10.1103/PhysRevLett.134.021001

**Authors:** A. Abdul Halim <em>et al.</em> (Pierre Auger Collaboration)

Author(s): A. Abdul Halim <em>et al.</em> (Pierre Auger Collaboration)<br /><p>We present measurements of the atmospheric depth of the shower maximum ${X}_{\mathrm{max}}$, inferred for the first time on an event-by-event level using the surface detector of the Pierre Auger Observatory. Using deep learning, we were able to extend measurements of the ${X}_{\mathrm{max}}$ distrib…</p><br />[Phys. Rev. Lett. 134, 021001] Published Mon Jan 13, 2025


---
# Smooth Exact Gradient Descent Learning in Spiking Neural Networks

## 尖峰神经网络中的平滑精确梯度下降学习

Link: http://link.aps.org/doi/10.1103/PhysRevLett.134.027301

**Authors:** Christian Klos and Raoul-Martin Memmesheimer

Author(s): Christian Klos and Raoul-Martin Memmesheimer<br /><p>By incorporating electrical pulses with shapes similar to those of the spikes from biological neurons, researchers improved the ability to train energy-efficient types of neural networks.</p><img height="" src="http://cdn.journals.aps.org/journals/PRL/key_images/10.1103/PhysRevLett.134.027301.png" width="200" /><br />[Phys. Rev. Lett. 134, 027301] Published Mon Jan 13, 2025


---
# Spike Mechanism of Biological Neurons May Boost Artificial Neural Networks

## 生物神经元的尖峰机制可能会增强人工神经网络

Link: http://link.aps.org/doi/10.1103/Physics.18.5

**Authors:** Dominik Dold

Author(s): Dominik Dold<br /><p>By incorporating electrical pulses with shapes similar to those of the spikes from biological neurons, researchers improved the ability to train energy-efficient types of neural networks.</p><img height="" src="https://physics.aps.org/assets/10.1103/Physics.18.5/figure/1/thumb" width="200" /><br />[Physics 18, 5] Published Mon Jan 13, 2025


---
# Energy-efficient multimodal zero-shot learning using in-memory reservoir computing

## 使用内存储层计算的高能效多模态零射学习

Link: https://www.nature.com/articles/s43588-024-00762-w

<p>Nature Computational Science, Published online: 13 January 2025; <a href="https://www.nature.com/articles/s43588-024-00762-w">doi:10.1038/s43588-024-00762-w</a></p>To achieve an advanced neuromorphic computing system with brain-like energy efficiency and generalization capabilities, we propose a hardware–software co-design of in-memory reservoir computing. This co-design integrates a liquid state machine-based encoder with artificial neural network projections on a hybrid analog–digital system, demonstrating zero-shot learning for multimodal event data.


---
# [ASAP] CPconf_score: A Deep Learning Free Energy Function Trained Using Molecular Dynamics Data for Cyclic Peptides

## [ASAP] CPconf_score: 使用环肽的分子动力学数据训练的深度学习自由能函数

Link: http://dx.doi.org/10.1021/acs.jctc.4c01386

**Authors:** Qing Zeng, Jia-Nan Chen, Botao Dai, Fan Jiang, and Yun-Dong Wu

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acs.jctc.4c01386/asset/images/medium/ct4c01386_0007.gif" /></p><div><cite>Journal of Chemical Theory and Computation</cite></div><div>DOI: 10.1021/acs.jctc.4c01386</div>


---
# Extrapolation to the complete basis-set limit in density-functional theory using statistical learning

## 使用统计学习外推至密度泛函理论中的完整基集极限

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.9.013801

**Authors:** Daniel T. Speckhard, Christian Carbogno, Luca M. Ghiringhelli, Sven Lubeck, Matthias Scheffler, and Claudia Draxl

Author(s): Daniel T. Speckhard, Christian Carbogno, Luca M. Ghiringhelli, Sven Lubeck, Matthias Scheffler, and Claudia Draxl<br /><p>The numerical precision of density-functional-theory (DFT) calculations depends on a variety of computational parameters, one of the most critical being the basis-set size. The ultimate precision is reached in the limit of a complete basis set (CBS). Our aim in this work is to find a machine-learnin…</p><br />[Phys. Rev. Materials 9, 013801] Published Mon Jan 13, 2025


---
# Parameter uncertainties for imperfect surrogate models in the low-noise regime

## 低噪声状态下不完善代理模型的参数不确定性

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad9fce

**Authors:** Thomas D Swinburne and Danny Perez

Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, this loss ignores model form error, or misspecification, meaning parameter uncertainties are significantly underestimated and vanish in the large data limit. As misspecification is the main source of uncertainty for surrogate models of low-noise calculations, such as those arising in atomistic simulation, predictive uncertainties are systematically underestimated. We analyze the true generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show that posterior parameter distributions must cover every training point to avoid a divergence in the generalization error and design a compatible ansatz which incurs minimal overhead for linear models. The approach is demonstrated on model problems before application to thousand-dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors in terms of parameter uncertainties, allowing this important source of uncertainty to be incorporated in multi-scale computational workflows.


---
# Refinable modeling for unbinned SMEFT analyses

## 用于未装箱SMEFT分析的可细化建模

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad9fd1

**Authors:** Robert Schöfbeck

We present methods to estimate systematic uncertainties in unbinned large hadron collider (LHC) data analyses, focusing on constraining Wilson coefficients in the standard model effective field theory (SMEFT). Our approach also applies to broader parametric models of non-resonant phenomena beyond the standard model. By using machine-learned surrogates of the likelihood ratio, we extend well-established procedures from binned Poisson counting experiments to the unbinned case. This framework handles various theoretical, modeling, and experimental uncertainties, laying the foundation for future unbinned analyses at the LHC. We also introduce a tree-boosting algorithm that learns precise parametrizations of systematic effects, providing a robust, flexible alternative to neural networks for modeling systematics. We demonstrate this approach with an SMEFT analysis of highly energetic top quark pair production in proton–proton collisions.


---
# Automation of quantum dot measurement analysis via explainable machine learning

## 通过可解释的机器学习实现量子点测量分析的自动化

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada087

**Authors:** Daniel Schug, Tyler J Kovach, M A Wolfe, Jared Benson, Sanghyeok Park, J P Dodson, J Corrigan, M A Eriksson and Justyna P Zwolak

The rapid development of quantum dot (QD) devices for quantum computing has necessitated more efficient and automated methods for device characterization and tuning. Many of the measurements acquired during the tuning process come in the form of images that need to be properly analyzed to guide the subsequent tuning steps. By design, features present in such images capture certain behaviors or states of the measured QD devices. When considered carefully, such features can aid the control and calibration of QD devices. An important example of such images are so-called triangle plots, which visually represent current flow and reveal characteristics important for QD device calibration. While image-based classification tools, such as convolutional neural networks (CNNs), can be used to verify whether a given measurement is good and thus warrants the initiation of the next phase of tuning, they do not provide any insights into how the device should be adjusted in the case of bad images. This is because CNNs sacrifice prediction and model intelligibility for high accuracy. To ameliorate this trade-off, a recent study introduced an image vectorization approach that relies on the Gabor wavelet transform (Schug et al 2024 Proc. XAI4Sci: Explainable Machine Learning for Sciences Workshop (AAAI 2024) (Vancouver, Canada) pp 1–6). Here we propose an alternative vectorization method that involves mathematical modeling of synthetic triangles to mimic the experimental data. Using explainable boosting machines, we show that this new method offers superior explainability of model prediction without sacrificing accuracy. This work demonstrates the feasibility and advantages of applying explainable machine learning techniques to the analysis of QD measurements, paving the way for further advances in automated and transparent QD device tuning.


---
# A novel dynamic machine learning-based explainable fusion monitoring: application to industrial and chemical processes

## 一种新颖的基于动态机器学习的可解释融合监测: 在工业和化学过程中的应用

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada088

**Authors:** Husnain Ali, Rizwan Safdar, Yuanqiang Zhou, Yuan Yao, Le Yao, Zheng Zhang, Weilong Ding and Furong Gao

The complexity and fusion dynamism of the modern industrial and chemical sectors have been increasing with the rapid progress of IR 4.0–5.0. The transformative characteristics of Industry 4.0–5.0 have not been fully explored in terms of the fundamental importance of explainability. Traditional monitoring techniques for automatic anomaly detection, identifying the potential variables, and root cause analysis for fault information are not intelligent enough to tackle the intricate problems of real-time practices in the industrial and chemical sectors. This study presents a novel dynamic machine learning based explainable fusion approach to address the issues of process monitoring in industrial and chemical process systems. The methodology aims to detect faults, identify their key causes and feature variables, and analyze the root path of fault propagation with the time and magnitude of one cause variable to another impact. This study proposed using a time domain multivariate granger-entropy-aided dynamic independent component analysis (DICA)—distributed canonical correlation analysis approach, incorporating the dynamics time wrapping supported time delay-signed directed graph. The proposed methodology utilized the application to industrial and chemical processes and verified using the continuous stirred tank reactor and Tennessee Eastman process as practical application benchmarks. The framework’s validations and efficiency are evaluated using established techniques such as classic computed ICA and DICA as standard model scenarios. The outcomes and results showed that the newly developed strategy is preferable to previous approaches regarding explainability and robust detection and identification of the actual root causes with high FDRs and low FARs.


---
# New parameterized quantum gates design and efficient gradient solving based on variational quantum classification algorithm

## 基于变分量子分类算法的新型参数化量子门设计与高效梯度求解

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada0a4

**Authors:** Xiaodong Ding, FuDong Liu, Weilong Wang, Yu Zhu, Yifan Hou, Yizhen Huang, Jinchen Xu and Zheng Shan

Currently, variational quantum classification algorithms (VQCAs) generally rely on traditional optimization techniques such as Powell and SLSQP in the parameter optimization session. However, the performance of these methods shows limitations in practical applications. Although the parameter-shift rule can efficiently compute the parameter gradient with quantum circuits, it needs to run the quantum circuit twice repeatedly, which significantly reduces the computation efficiency. In order to overcome this challenge, this paper innovatively integrates the principle of unitary operation in quantum mechanics with the technical characteristics of superconducting quantum chips and elaborately designs some new parameterized quantum gates (PQGs). These PQGs strictly follow the rules of unitary operation, which ensures the stability and accuracy of quantum state evolution while realizing an efficient solution to the parameter gradient. Especially for the gradient calculation of a single qubit and single-angle PQGs, the new method can be completed with only a single quantum circuit run, which greatly improves the computation efficiency. Experimental validation on benchmark datasets such as breast cancer and iris shows that the method proposed in this paper exhibits excellent performance on quantum classification tasks. Compared with the parameter-shift rule, the computation efficiency of the new method is improved by 40%. And the classification accuracy, precision, and other key performance metrics are improved by an average of 5% in comparison with traditional optimization algorithms. This work not only enriches the methodology of quantum machine learning theoretically but also demonstrates its remarkable superiority in practical applications, which indicates that the method has great potential in scientific research and industrial applications.


---
# Self-adaptive physics-informed quantum machine learning for solving differential equations

## 求解微分方程的自适应物理通知量子机器学习

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada3ab

**Authors:** Abhishek Setty, Rasul Abdusalamov and Felix Motzoi

Chebyshev polynomials have shown significant promise as an efficient tool for both classical and quantum neural networks to solve linear and nonlinear differential equations (DEs). In this work, we adapt and generalize this framework in a quantum machine learning setting for a variety of problems, including the 2D Poisson’s equation, second-order linear DE, system of DEs, nonlinear Duffing and Riccati equation. In particular, we propose in the quantum setting a modified Self-Adaptive Physics-Informed Neural Network approach, where self-adaptive weights are applied to problems with multi-objective loss functions. We further explore capturing correlations in our loss function using a quantum-correlated measurement, resulting in improved accuracy for initial value problems. We analyse also the use of entangling layers and their impact on the solution accuracy for second-order DEs. The results indicate a promising approach to the near-term evaluation of DEs on quantum devices.


---
# Accelerated development of multi-component alloys in discrete design space using Bayesian multi-objective optimisation

## 使用贝叶斯多目标优化在离散设计空间中加速多组分合金的开发

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada47d

**Authors:** Osman Mamun, Markus Bause and Bhuiyan Shameem Mahmood Ebna Hai

Bayesian optimisation (BO) protocols grounded in active learning (AL) principles have gained significant recognition for their ability to efficiently optimize black-box objective functions. This capability is critical for advancing autonomous and high-throughput materials design and discovery processes. However, the application of these protocols in materials science, particularly in the design of novel alloys with multiple targeted properties, remains constrained by computational complexity and the absence of reliable and robust acquisition functions for multiobjective optimisation. Recent advancements have demonstrated that expected hypervolume-based geometrical acquisition functions outperform other multiobjective optimisation algorithms, such as Thompson Sampling Efficient Multiobjective optimisation and pareto efficient global optimisation (parEGO), in both performance and speed. This study evaluates several leading multiobjective BO acquisition functions–namely, parallel expected hypervolume improvement (qEHVI), noisy qEHVI, parallel parEGO, and parallel noisy parEGO (qNparEGO)–in optimizing the physical properties of multi-component alloys. Our findings highlight the superior performance of the qEHVI acquisition function in identifying the optimal Pareto front across 1-, 2-, and 3-objective aluminum alloy optimisation problems, all within a constrained evaluation budget and reasonable computational cost. Furthermore, we explore the impact of various surrogate model optimisation methods from both computational cost and efficiency perspectives. Finally, we demonstrate the effectiveness of a pool-based AL protocol in expediting the discovery process by executing multiple computational and experimental campaigns in each iteration. This approach is particularly advantageous for deployment in massively parallel high-throughput synthesis facilities and advanced computing architectures.


---
# Machine Learning‐Assisted High‐Throughput Screening of Nanozymes for Ulcerative Colitis

## 机器学习辅助的溃疡性结肠炎纳米酶高通量筛选

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202417536?af=R

**Authors:** Xianguang Zhao, 
Yixin Yu, 
Xudong Xu, 
Ziqi Zhang, 
Zhen Chen, 
Yubo Gao, 
Liang Zhong, 
Jiajie Chen, 
Jiaxin Huang, 
Jie Qin, 
Qingyun Zhang, 
Xuemei Tang, 
Dongqin Yang, 
Zhiling Zhu

Advanced Materials, EarlyView.


---
# An Analysis of Components and Enhancement Strategies for Advancing Memristive Neural Networks

## 用于推进忆阻神经网络的组件和增强策略的分析

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202412549?af=R

**Authors:** Hyungjun Park, 
Joon‐Kyu Han, 
Seongpil Yim, 
Dong Hoon Shin, 
Tae Won Park, 
Kyung Seok Woo, 
Soo Hyung Lee, 
Jae Min Cho, 
Hyun Wook Kim, 
Taegyun Park, 
Cheol Seong Hwang

Advanced Materials, EarlyView.


---
# Deep learning of phase transitions with minimal examples

## 用最少的例子对相变进行深度学习

Link: https://arxiv.org/abs/2501.05547

**Authors:** Ahmed Abuali, David A. Clarke, Morten Hjorth-Jensen, Ioannis Konstantinidis, Claudia Ratti, Jianyi Yang

arXiv:2501.05547v1 Announce Type: new 
Abstract: Over the past several years, there have been many studies demonstrating the ability of neural networks and deep learning methods to identify phase transitions in many physical systems, notably in classical statistical physics systems. One often finds that the prediction of deep learning methods trained on many ensembles below and above the critical temperature $T_{\mathrm{c}}$ behave analogously to an order parameter, and this analogy has been successfully used to locate $T_{\mathrm{c}}$ and estimate universal critical exponents. In this work, we pay particular attention to the ability of a convolutional neural network to capture these critical parameters for the 2-$d$ Ising model, when the network is trained on configurations at $T=0$ and $T=\infty$ only. We apply histogram reweighting to the neural network prediction and compare its capabilities when trained more conventionally at multiple temperatures. We find that the network trained on two temperatures is still able to identify $T_{\mathrm{c}}$ and $\nu$, while the extraction of $\gamma$ becomes more challenging.


---
# Development and Comparison of Model-Based and Data-Driven Approaches for the Prediction of the Mechanical Properties of Lattice Structures

## 开发和比较基于模型和数据驱动的方法来预测晶格结构的机械性能

Link: https://arxiv.org/abs/2501.05762

**Authors:** Chiara Pasini, Oscar Ramponi, Stefano Pandini, Luciana Sartore, Giulia Scalet

arXiv:2501.05762v1 Announce Type: new 
Abstract: Lattice structures have great potential for several application fields ranging from medical and tissue engineering to aeronautical one. Their development is further speeded up by the continuing advances in additive manufacturing technologies that allow to overcome issues typical of standard processes and to propose tailored designs. However, the design of lattice structures is still challenging since their properties are considerably affected by numerous factors. The present paper aims to propose, discuss, and compare various modeling approaches to describe, understand, and predict the correlations between the mechanical properties and the void volume fraction of different types of lattice structures fabricated by fused deposition modeling 3D printing. Particularly, four approaches are proposed: (i) a simplified analytical model; (ii) a semi-empirical model combining analytical equations with experimental correction factors; (iii) an artificial neural network trained on experimental data; (iv) numerical simulations by finite element analyses. The comparison among the various approaches, and with experimental data, allows to identify the performances, advantages, and disadvantages of each approach, thus giving important guidelines for choosing the right design methodology based on the needs and available data.


---
# Automatic detection of single-electron regime of quantum dots and definition of virtual gates using U-Net and clustering

## 使用u-net和聚类自动检测量子点的单电子状态并定义虚拟门

Link: https://arxiv.org/abs/2501.05878

**Authors:** Yui Muto, Michael R. Zielewski, Motoya Shinozaki, Kosuke Noro, Tomohiro Otsuka

arXiv:2501.05878v1 Announce Type: new 
Abstract: To realize practical quantum computers, a large number of quantum bits (qubits) will be required. Semiconductor spin qubits offer advantages such as high scalability and compatibility with existing semiconductor technologies. However, as the number of qubits increases, manual qubit tuning becomes infeasible, motivating automated tuning approaches. In this study, we use U-Net, a neural network method for object detection, to identify charge transition lines in experimental charge stability diagrams. The extracted charge transition lines are analyzed using the Hough transform to determine their positions and angles. Based on this analysis, we obtain the transformation matrix to virtual gates. Furthermore, we identify the single-electron regime by clustering the Hough transform outputs. We also show the single-electron regime within the virtual gate space. These sequential processes are performed automatically. This approach will advance automated control technologies for large-scale quantum devices.


---
# Discovery of sustainable energy materials via the machine-learned material space

## 通过机器学习的材料空间发现可持续能源材料

Link: https://arxiv.org/abs/2501.05903

**Authors:** Malte Grunert, Max Gro{\ss}mann, Erich Runge

arXiv:2501.05903v1 Announce Type: new 
Abstract: Does a machine learning model actually gain an understanding of the material space? We answer this question in the affirmative on the example of the OptiMate model, a graph attention network trained to predict the optical properties of semiconductors and insulators. By applying the UMAP dimensionality reduction technique to its latent embeddings, we demonstrate that the model captures a nuanced and interpretable representation of the materials space, reflecting chemical and physical principles, without any user-induced bias. This enables clustering of almost 10,000 materials based on optical properties and chemical similarities. Beyond this understanding, we demonstrate how the learned material space can be used to identify more sustainable alternatives to critical materials in energy-related technologies, such as photovoltaics. These findings demonstrate the dual utility of machine learning models in materials science: Accurately predicting material properties while providing insights into the underlying materials space. The approach demonstrates the broader potential of leveraging learned materials spaces for the discovery and design of materials for diverse applications, and is easily applicable to any state-of-the-art machine learning model.


---
# Inferring High-Order Couplings with Neural Networks

## 用神经网络推断高阶耦合

Link: https://arxiv.org/abs/2501.06108

**Authors:** Aur\'elien Decelle, Alfonso de Jes\'us Navas G\'omez, Beatriz Seoane

arXiv:2501.06108v1 Announce Type: new 
Abstract: Maximum-entropy methods, rooted in the inverse Ising/Potts problem from statistical mechanics, have become indispensable tools for modeling pairwise interactions in disciplines such as bioinformatics, ecology, and neuroscience. Despite their remarkable success, these methods often overlook high-order interactions that may be crucial in complex systems. Conversely, while modern machine learning approaches can capture such interactions, existing interpretable frameworks are computationally expensive, making it impractical to assess the relevance of high-order interactions in real-world scenarios. Restricted Boltzmann Machines (RBMs) offer a computationally efficient alternative by encoding statistical correlations via hidden nodes in a bipartite neural network. Here, we present a method that maps RBMs exactly onto generalized Potts models with interactions of arbitrary high order. This approach leverages large-$N$ approximations, facilitated by the simple architecture of the RBM, to enable the efficient extraction of effective many-body couplings with minimal computational cost. This mapping also enables the development of a general formal framework for the extraction of effective higher-order interactions in arbitrarily complex probabilistic models. Additionally, we introduce a robust formalism for gauge fixing within the generalized Potts model. We validate our method by accurately recovering two- and three-body interactions from synthetic datasets. Additionally, applying our framework to protein sequence data demonstrates its effectiveness in reconstructing protein contact maps, achieving performance comparable to state-of-the-art inverse Potts models. These results position RBMs as a powerful and efficient tool for investigating high-order interactions in complex systems.


---
# Multi-Phase Dataset for Ti and Ti-6Al-4V

## Ti和Ti-6Al-4V的多阶段数据集

Link: https://arxiv.org/abs/2501.06116

**Authors:** Connor S. Allen, Albert P. Bart\'ok

arXiv:2501.06116v1 Announce Type: new 
Abstract: Titanium and its alloys are technologically important materials that display a rich phase behaviour. In order to enable large-scale, realistic modelling of Ti and its alloys on the atomistic scale, Machine Learning Interatomic Potentials (MLIPs) are crucial, but rely on databases of atomic configurations. We report databases of such configurations that represent the {\alpha}, \b{eta}, {\omega} and liquid phases of Ti and the Ti-6Al-4V alloy, where we provide total energy, force and stress values evaluated by Density Functional Theory (DFT) using the PBE exchange-correlation functional. We have also leveraged and extended a data reduction strategy, via non-diagonal supercells, for the vibrational properties of Ti and sampling of atomic species within bulk crystalline data for Ti-6Al-4V. These configurations may be used to fit MLIP models that can accurately model the phase behaviour of Ti and Ti-6Al-4V across a broad range of thermodynamic conditions. To validate models, we assembled a set of benchmark protocols, which can be used to rapidly develop and evaluate MLIP models. We demonstrated the utility of our databases and validation tools by fitting models based on the Gaussian Approximation Potential (GAP) and Atomic Cluster Expansion (ACE) frameworks.


---
# Machine Learning Force-Field Approach for Itinerant Electron Magnets

## 用于巡回电子磁体的机器学习力场方法

Link: https://arxiv.org/abs/2501.06171

**Authors:** Sheng Zhang, Yunhao Fan, Kotaro Shimizu, Gia-Wei Chern

arXiv:2501.06171v1 Announce Type: new 
Abstract: We review the recent development of machine-learning (ML) force-field frameworks for Landau-Lifshitz-Gilbert (LLG) dynamics simulations of itinerant electron magnets, focusing on the general theory and implementations of symmetry-invariant representations of spin configurations. The crucial properties that such magnetic descriptors must satisfy are differentiability with respect to spin rotations and invariance to both lattice point-group symmetry and internal spin rotation symmetry. We propose an efficient implementation based on the concept of reference irreducible representations, modified from the group-theoretical power-spectrum and bispectrum methods. The ML framework is demonstrated using the s-d models, which are widely applied in spintronics research. We show that LLG simulations based on local fields predicted by the trained ML models successfully reproduce representative non-collinear spin structures, including 120$^\circ$, tetrahedral, and skyrmion crystal orders of the triangular-lattice s-d models. Large-scale thermal quench simulations enabled by ML models further reveal intriguing freezing dynamics and glassy stripe states consisting of skyrmions and bi-merons. Our work highlights the utility of ML force-field approach to dynamical modeling of complex spin orders in itinerant electron magnets.


---
# Neural Architecture Codesign for Fast Physics Applications

## 快速物理应用的神经体系结构协同设计

Link: https://arxiv.org/abs/2501.05515

**Authors:** Jason Weitz, Dmitri Demler, Luke McDermott, Nhan Tran, Javier Duarte

arXiv:2501.05515v1 Announce Type: cross 
Abstract: We develop a pipeline to streamline neural architecture codesign for physics applications to reduce the need for ML expertise when designing models for novel tasks. Our method employs neural architecture search and network compression in a two-stage approach to discover hardware efficient models. This approach consists of a global search stage that explores a wide range of architectures while considering hardware constraints, followed by a local search stage that fine-tunes and compresses the most promising candidates. We exceed performance on various tasks and show further speedup through model compression techniques such as quantization-aware-training and neural network pruning. We synthesize the optimal models to high level synthesis code for FPGA deployment with the hls4ml library. Additionally, our hierarchical search space provides greater flexibility in optimization, which can easily extend to other tasks and domains. We demonstrate this with two case studies: Bragg peak finding in materials science and jet classification in high energy physics, achieving models with improved accuracy, smaller latencies, or reduced resource utilization relative to the baseline models.


---
# Emergent weight morphologies in deep neural networks

## 深度神经网络中涌现的权值形态

Link: https://arxiv.org/abs/2501.05550

**Authors:** Pascal de Jong, Felix Meigel, Steffen Rulands

arXiv:2501.05550v1 Announce Type: cross 
Abstract: Whether deep neural networks can exhibit emergent behaviour is not only relevant for understanding how deep learning works, it is also pivotal for estimating potential security risks of increasingly capable artificial intelligence systems. Here, we show that training deep neural networks gives rise to emergent weight morphologies independent of the training data. Specifically, in analogy to condensed matter physics, we derive a theory that predict that the homogeneous state of deep neural networks is unstable in a way that leads to the emergence of periodic channel structures. We verified these structures by performing numerical experiments on a variety of data sets. Our work demonstrates emergence in the training of deep neural networks, which impacts the achievable performance of deep neural networks.


---
# Hierarchical Serpentine-like Organic Crystal Optical Waveguides for Artificial Neural Networks

## 用于人工神经网络的分层蛇形有机晶体光波导

Link: https://arxiv.org/abs/2501.05831

**Authors:** Avulu Vinod Kumar, Mehdi Rohullah, Melchi Chosenyah, Sinduja Gaddam, Rajadurai Chandrasekar

arXiv:2501.05831v1 Announce Type: cross 
Abstract: Optical components and circuits that deal with multiple signal generation and processing are quintessential for artificial neural networks. Herein, we present a proof-of-concept four-layered organic optical artificial neural network (ANN)-like architecture, constructed from flexible organic crystals of (E)-1-(((5-methylpyridin-2-yl)imino)methyl)naphthalene-2-ol (MPyIN), employing an atomic force microscopy cantilever tip-based mechanical micromanipulation technique. Initially, the strategic selection of four MPyIN crystal active waveguides of varying lengths, mechanically bending them into serpentine-like forms, followed by their hierarchical integration, creates neuron-like, four-layered interconnected optical waveguides with six optical synapses. The synapses in the ANN-like architecture enable parallel transmissions of passive optical signals via evanescent coupling across multiple paths through various layers of the serpentine-shaped optical waveguides. Notably, the feedforward mechanism allows the synapses to multiply and split the optical signal generated at any input into four diverging signals with varying magnitudes. Here, certain outputs deliver a mixed signal (passive and active) due to diverging and converging optical transmission paths. This hierarchical, ANN-like tiny architecture paves the way for the development of smart optical neural networks utilizing multiple emissive and phase-changing organic crystals.


---
# Autonomous scanning probe microscopy with hypothesis learning: Exploring the physics of domain switching in ferroelectric materials

## 具有假设学习的自主扫描探针显微镜: 探索铁电材料中畴切换的物理学

Link: https://arxiv.org/abs/2202.01089

**Authors:** Yongtao Liu, Anna Morozovska, Eugene Eliseev, Kyle P. Kelley, Rama Vasudevan, Maxim Ziatdinov, Sergei V. Kalinin

arXiv:2202.01089v2 Announce Type: replace 
Abstract: We report the development and implementation of a hypothesis learning based automated experiment, in which the microscope operating in the autonomous mode identifies the physical laws behind the material's response. Specifically, we explore the bias induced transformations that underpin the functionality of broad classes of devices and functional materials from batteries and memristors to ferroelectrics and antiferroelectrics. Optimization and design of these materials require probing the mechanisms of these transformations on the nanometer scale as a function of the broad range of control parameters such as applied potential and time, often leading to experimentally intractable scenarios. At the same time, often the behaviors of these systems are understood within potentially competing theoretical models, or hypotheses. Here, we develop a hypothesis list that covers the possible limiting scenarios for the domain growth, including thermodynamic, domain wall pinning, and screening limited. We further develop and experimentally implement the hypothesis driven automated experiment in Piezoresponse Force Microscopy, autonomously identifying the mechanisms of the bias induced domain switching. This approach can be applied for a broad range of physical and chemical experiments with relatively low dimensional control parameter space and for which the possible competing models of the system behavior that ideally cover the full range of physical eventualities are known or can be created. These include other scanning probe microscopy modalities such as force distance curve measurements and nanoindentation, as well as materials synthesis and optimization.


---
# Impact of dendritic non-linearities on the computational capabilities of neurons

## 树突状非线性对神经元计算能力的影响

Link: https://arxiv.org/abs/2407.07572

**Authors:** Clarissa Lauditi, Enrico M. Malatesta, Fabrizio Pittorino, Carlo Baldassi, Nicolas Brunel, Riccardo Zecchina

arXiv:2407.07572v2 Announce Type: replace-cross 
Abstract: How neurons integrate the myriad synaptic inputs scattered across their dendrites is a fundamental question in neuroscience. Multiple neurophysiological experiments have shown that dendritic non-linearities can have a strong influence on synaptic input integration. These non-linearities have motivated mathematical descriptions of single neuron as a two-layer computational units, which have been shown to increase substantially the computational abilities of neurons, compared to linear dendritic integration. However, current analytical studies are restricted to neurons with unconstrained synaptic weights and unplausible dendritic non-linearities. Here, we introduce a two-layer model with sign-constrained synaptic weights and a biologically plausible form of dendritic non-linearity, and investigate its properties using both statistical physics methods and numerical simulations. We find that the dendritic non-linearity enhances both the number of possible learned input-output associations and the learning velocity. We characterize how capacity and learning speed depend on the implemented non-linearity and the levels of dendritic and somatic inhibition. We calculate analytically the distribution of synaptic weights in networks close to maximal capacity, and find that a large fraction of zero-weight ('silent' or 'potential') synapses naturally emerge in neurons with sign-constrained synapses, as a consequence of non-linear dendritic integration. Non-linearly induced sparsity comes with a second central advantage for neuronal information processing, i.e. input and synaptic noise robustness. We test our model on standard real-world benchmark datasets and observe empirically that the non-linearity provides an enhancement in generalization performance, showing that it enables to capture more complex input/output relations.


---
# Machine-learned design principles for enhanced red emission from nitride quantum wells

## 氮化物量子阱增强红光发射的机器学习设计原理

Link: https://arxiv.org/abs/2410.23591

**Authors:** Nick Pant, Rob Armitage, Emmanouil Kioupakis

arXiv:2410.23591v4 Announce Type: replace-cross 
Abstract: Significant effort has been devoted toward mitigating polarization fields in nitride LEDs, as they are viewed as detrimental to light emission, albeit with limited success for red emission. Here, we show that such fields can unusually enhance the optical oscillator strength of red-emitting nitride quantum wells. This insight is enabled by machine-learned models trained on multi-scale quantum-mechanical simulations, allowing for a global exploration of the quantum-well design space at greatly reduced computational cost. Larger polarization fields correlate with higher wave-function overlaps for red emission, a consequence of the quantum-confined Stark effect enabling thinner quantum wells. This finding has implications for designing efficient red nitride LEDs, which are crucial for miniaturizing polychromatic LED pixels to the micron scale for extended-reality and biomedical applications. More broadly, this work highlights the power of machine learning in accelerating the discovery of unconventional paradigms for semiconductor design.


---
# Track reconstruction as a service for collider physics

## 轨道重建作为对撞机物理学的服务

Link: https://arxiv.org/abs/2501.05520

**Authors:** Yuan-Tang Chou, Miles Cochran-Branson, Javier Duarte, Yongbin Feng, Philip Harris, Shih-Chieh Hsu, Xiangyang Ju, Miaoyuan Liu, William Patrick McCormack, Kevin Pedro, Jan-Frederik Schulte, Nhan Tran, Yao Yao, Haoran Zhao

arXiv:2501.05520v1 Announce Type: new 
Abstract: Optimizing charged-particle track reconstruction algorithms is crucial for efficient event reconstruction in Large Hadron Collider (LHC) experiments due to their significant computational demands. Existing track reconstruction algorithms have been adapted to run on massively parallel coprocessors, such as graphics processing units (GPUs), to reduce processing time. Nevertheless, challenges remain in fully harnessing the computational capacity of coprocessors in a scalable and non-disruptive manner. This paper proposes an inference-as-a-service approach for particle tracking in high energy physics experiments. To evaluate the efficacy of this approach, two distinct tracking algorithms are tested: Patatrack, a rule-based algorithm, and Exa.TrkX, a machine learning-based algorithm. The as-a-service implementations show enhanced GPU utilization and can process requests from multiple CPU cores concurrently without increasing per-request latency. The impact of data transfer is minimal and insignificant compared to running on local coprocessors. This approach greatly improves the computational efficiency of charged particle tracking, providing a solution to the computing challenges anticipated in the High-Luminosity LHC era.


---
# Exploring Large Language Models (LLMs) through interactive Python activities

## 通过交互式Python活动探索大型语言模型 (llm)

Link: https://arxiv.org/abs/2501.05577

**Authors:** Eugenio Tufino

arXiv:2501.05577v1 Announce Type: new 
Abstract: This paper presents an approach to introduce physics students to the basic concepts of Large Language Models (LLMs) using Python-based activities in Google Colab. The teaching strategy integrates active learning strategies and combines theoretical ideas with practical, physics-related examples. Students engage with key technical concepts, such as word embeddings, through hands-on exploration of the Word2Vec neural network and GPT-2 - an LLM that gained a lot of attention in 2019 for its ability to generate coherent and plausible text from simple prompts.
  The activities highlight how words acquire meaning and how LLMs predict subsequent tokens by simulating simplified scenarios related to physics. By focusing on Word2Vec and GPT-2, the exercises illustrate fundamental principles underlying modern LLMs, such as semantic representation and contextual prediction. Through interactive experimenting in Google Colab, students observe the relationship between model parameters (such as temperature) in GPT-2 and output behaviour, understand scaling laws relating data quantity to model performance, and gain practical insights into the predictive capabilities of LLMs. This approach allows students to begin to understand how these systems work by linking them to physics concepts - systems that will shape their academic studies, professional careers and roles in society.


---
# Automatizing the search for mass resonances using BumpNet

## 使用BumpNet自动搜索质量共振

Link: https://arxiv.org/abs/2501.05603

**Authors:** Jean-Francois Arguin, Georges Azuelos, \'Emile Baril, Ilan Bessudo, Fannie Bilodeau, Maryna Borysova, Shikma Bressler, Samuel Calvet, Julien Donini, Etienne Dreyer, Michael Kwok Lam Chu, Eva Mayer, Ethan Meszaros, Nilotpal Kakati, Bruna Pascual Dias, Jos\'ephine Potdevin, Amit Shkuri, Muhammad Usman

arXiv:2501.05603v1 Announce Type: new 
Abstract: The search for resonant mass bumps in invariant-mass distributions remains a cornerstone strategy for uncovering Beyond the Standard Model (BSM) physics at the Large Hadron Collider (LHC). Traditional methods often rely on predefined functional forms and exhaustive computational and human resources, limiting the scope of tested final states and selections. This work presents BumpNet, a machine learning-based approach leveraging advanced neural network architectures to generalize and enhance the Data-Directed Paradigm (DDP) for resonance searches. Trained on a diverse dataset of smoothly-falling analytical functions and realistic simulated data, BumpNet efficiently predicts statistical significance distributions across varying histogram configurations, including those derived from LHC-like conditions. The network's performance is validated against idealized likelihood ratio-based tests, showing minimal bias and strong sensitivity in detecting mass bumps across a range of scenarios. Additionally, BumpNet's application to realistic BSM scenarios highlights its capability to identify subtle signals while managing the look-elsewhere effect. These results underscore BumpNet's potential to expand the reach of resonance searches, paving the way for more comprehensive explorations of LHC data in future analyses.


---
# All-optical computing with beyond 100-GHz clock rates

## 时钟速率超过100 GHz的全光计算

Link: https://arxiv.org/abs/2501.05756

**Authors:** Gordon H. Y. Li, Midya Parto, Jinhao Ge, Qing-Xin Ji, Maodong Gao, Yan Yu, James Williams, Robert M. Gray, Christian R. Leefmans, Nicolas Englebert, Kerry J. Vahala, Alireza Marandi

arXiv:2501.05756v1 Announce Type: new 
Abstract: A computer's clock rate ultimately determines the minimum time between sequential operations or instructions. Despite exponential advances in electronic computer performance owing to Moore's Law and increasingly parallel system architectures, computer clock rates have remained stagnant at $\sim5~\mathrm{GHz}$ for almost two decades. This poses an intractable problem for applications requiring real-time processing or control of ultrafast information systems. Here we break this barrier by proposing and experimentally demonstrating computing based on an end-to-end and all-optical recurrent neural network harnessing the ultrafast nature of linear and nonlinear optical operations while avoiding electronic operations. The all-optical computer realizes linear operations, nonlinear functions, and memory entirely in the optical domain with $>100~\mathrm{GHz}$ clock rates. We experimentally demonstrate a prototypical task of noisy waveform classification as well as perform ultrafast in-situ analysis of the soliton states from integrated optical microresonators. We further illustrate the application of the architecture for generative artificial intelligence based on quantum fluctuations to generate images even in the absence of input optical signals. Our results highlight the potential of all-optical computing beyond what can be achieved with digital electronics by utilizing ultrafast linear, nonlinear, and memory functions and quantum fluctuations.


---
# Hierarchical Serpentine-like Organic Crystal Optical Waveguides for Artificial Neural Networks

## 用于人工神经网络的分层蛇形有机晶体光波导

Link: https://arxiv.org/abs/2501.05831

**Authors:** Avulu Vinod Kumar, Mehdi Rohullah, Melchi Chosenyah, Sinduja Gaddam, Rajadurai Chandrasekar

arXiv:2501.05831v1 Announce Type: new 
Abstract: Optical components and circuits that deal with multiple signal generation and processing are quintessential for artificial neural networks. Herein, we present a proof-of-concept four-layered organic optical artificial neural network (ANN)-like architecture, constructed from flexible organic crystals of (E)-1-(((5-methylpyridin-2-yl)imino)methyl)naphthalene-2-ol (MPyIN), employing an atomic force microscopy cantilever tip-based mechanical micromanipulation technique. Initially, the strategic selection of four MPyIN crystal active waveguides of varying lengths, mechanically bending them into serpentine-like forms, followed by their hierarchical integration, creates neuron-like, four-layered interconnected optical waveguides with six optical synapses. The synapses in the ANN-like architecture enable parallel transmissions of passive optical signals via evanescent coupling across multiple paths through various layers of the serpentine-shaped optical waveguides. Notably, the feedforward mechanism allows the synapses to multiply and split the optical signal generated at any input into four diverging signals with varying magnitudes. Here, certain outputs deliver a mixed signal (passive and active) due to diverging and converging optical transmission paths. This hierarchical, ANN-like tiny architecture paves the way for the development of smart optical neural networks utilizing multiple emissive and phase-changing organic crystals.


---
# Resultant force on grains of a real sand dune: How to measure it?

## 真实沙丘颗粒上的合力: 如何测量？

Link: https://arxiv.org/abs/2501.05869

**Authors:** Renato F. Miotto, Carlos A. Alvarez, Danilo S. Borges, William R. Wolf, Erick M. Franklin

arXiv:2501.05869v1 Announce Type: new 
Abstract: Dunes are bedforms found on sandy terrains shaped by fluid flow on Earth, Mars, and other celestial bodies. Despite their prevalence, understanding dune dynamics at the grain scale is challenging due to the vast number of grains involved. In this study, we demonstrate a novel approach to estimate the forces acting on individual dune grains using images. By combining subaqueous experiments, high-speed camera recordings, discrete numerical simulations, and a specially trained convolutional neural network, we can quantify these forces with high accuracy. This method represents a breakthrough in studying granular dynamics, offering a new way to measure forces not only on dune grains but also on smaller objects, such as rocks, boulders, rovers, and man-made structures, observed in satellite images of both Earth and Mars. This technique expands our ability to analyze and understand fluid-grain interactions in diverse environments.


---
# Small Angle Neutron Scattering in McStas: optimization for high throughput virtual experiments

## Mcsta中的小角度中子散射: 高通量虚拟实验的优化

Link: https://arxiv.org/abs/2501.06054

**Authors:** Jose Robledo, Klaus Lieutenant, Peter Willendrup

arXiv:2501.06054v1 Announce Type: new 
Abstract: In this work we present the development of small angle scattering components in McStas that describe the neutron interaction with 70 different form and structure factors. We describe the considerations taken into account for the generation of these components, such as the incorporation of polydispersity and orientational distribution effects in the Monte Carlo simulation. These models can be parallelized by means of multi-core simulations and graphical processing units (GPUs). The acceleration schemes for the aforementioned models are benchmarked, and the resulting performance is presented. This allows for the estimation of computation times in high-throughput virtual experiments. The presented work enables the generation of large datasets of virtual experiments that can be explored and used by machine learning algorithms.


---
# Efficient Transition State Searches by Freezing String Method with Graph Neural Network Potentials

## 通过具有图神经网络势的冻结字符串方法进行有效的过渡态搜索

Link: https://arxiv.org/abs/2501.06159

**Authors:** Jonah Marks, Joseph Gomes

arXiv:2501.06159v1 Announce Type: new 
Abstract: Transition states are a critical bottleneck in chemical transformations. Significant efforts have been made to develop algorithms that efficiently locate transition states on potential energy surfaces. However, the computational cost of ab-initio potential energy surface evaluation limits the size of chemical systems that can routinely studied. In this work, we develop and fine-tune a graph neural network potential energy function suitable for describing organic chemical reactions and use it to rapidly identify transition state guess structures. We successfully refine guess structures and locate a transition state in each test system considered and reduce the average number of ab-initio calculations by 47% though use of the graph neural network potential energy function. Our results show that modern machine learning models have reached levels of reliability whereby they can be used to accelerate routine computational chemistry tasks.


---
# Neural Architecture Codesign for Fast Physics Applications

## 快速物理应用的神经体系结构协同设计

Link: https://arxiv.org/abs/2501.05515

**Authors:** Jason Weitz, Dmitri Demler, Luke McDermott, Nhan Tran, Javier Duarte

arXiv:2501.05515v1 Announce Type: cross 
Abstract: We develop a pipeline to streamline neural architecture codesign for physics applications to reduce the need for ML expertise when designing models for novel tasks. Our method employs neural architecture search and network compression in a two-stage approach to discover hardware efficient models. This approach consists of a global search stage that explores a wide range of architectures while considering hardware constraints, followed by a local search stage that fine-tunes and compresses the most promising candidates. We exceed performance on various tasks and show further speedup through model compression techniques such as quantization-aware-training and neural network pruning. We synthesize the optimal models to high level synthesis code for FPGA deployment with the hls4ml library. Additionally, our hierarchical search space provides greater flexibility in optimization, which can easily extend to other tasks and domains. We demonstrate this with two case studies: Bragg peak finding in materials science and jet classification in high energy physics, achieving models with improved accuracy, smaller latencies, or reduced resource utilization relative to the baseline models.


---
# OmniJet-${\alpha_{ C}}$: Learning point cloud calorimeter simulations using generative transformers

## OmniJet-${\ alpha_{ C }}$: 使用生成式变压器学习点云热量计模拟

Link: https://arxiv.org/abs/2501.05534

**Authors:** Joschka Birk, Frank Gaede, Anna Hallin, Gregor Kasieczka, Martina Mozzanica, Henning Rose

arXiv:2501.05534v1 Announce Type: cross 
Abstract: We show the first use of generative transformers for generating calorimeter showers as point clouds in a high-granularity calorimeter. Using the tokenizer and generative part of the OmniJet-${\alpha}$ model, we represent the hits in the detector as sequences of integers. This model allows variable-length sequences, which means that it supports realistic shower development and does not need to be conditioned on the number of hits. Since the tokenization represents the showers as point clouds, the model learns the geometry of the showers without being restricted to any particular voxel grid.


---
# Deep learning of phase transitions with minimal examples

## 用最少的例子对相变进行深度学习

Link: https://arxiv.org/abs/2501.05547

**Authors:** Ahmed Abuali, David A. Clarke, Morten Hjorth-Jensen, Ioannis Konstantinidis, Claudia Ratti, Jianyi Yang

arXiv:2501.05547v1 Announce Type: cross 
Abstract: Over the past several years, there have been many studies demonstrating the ability of neural networks and deep learning methods to identify phase transitions in many physical systems, notably in classical statistical physics systems. One often finds that the prediction of deep learning methods trained on many ensembles below and above the critical temperature $T_{\mathrm{c}}$ behave analogously to an order parameter, and this analogy has been successfully used to locate $T_{\mathrm{c}}$ and estimate universal critical exponents. In this work, we pay particular attention to the ability of a convolutional neural network to capture these critical parameters for the 2-$d$ Ising model, when the network is trained on configurations at $T=0$ and $T=\infty$ only. We apply histogram reweighting to the neural network prediction and compare its capabilities when trained more conventionally at multiple temperatures. We find that the network trained on two temperatures is still able to identify $T_{\mathrm{c}}$ and $\nu$, while the extraction of $\gamma$ becomes more challenging.


---
# Diving Deep: Forecasting Sea Surface Temperatures and Anomalies

## 潜水深度: 预测海面温度和异常

Link: https://arxiv.org/abs/2501.05731

**Authors:** Ding Ning, Varvara Vetrova, Karin R. Bryan, Yun Sing Koh, Andreas Voskou, N'Dah Jean Kouagou, Arnab Sharma

arXiv:2501.05731v1 Announce Type: cross 
Abstract: This overview paper details the findings from the Diving Deep: Forecasting Sea Surface Temperatures and Anomalies Challenge at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2024. The challenge focused on the data-driven predictability of global sea surface temperatures (SSTs), a key factor in climate forecasting, ecosystem management, fisheries management, and climate change monitoring. The challenge involved forecasting SST anomalies (SSTAs) three months in advance using historical data and included a special task of predicting SSTAs nine months ahead for the Baltic Sea. Participants utilized various machine learning approaches to tackle the task, leveraging data from ERA5. This paper discusses the methodologies employed, the results obtained, and the lessons learned, offering insights into the future of climate-related predictive modeling.


---
# Development and Comparison of Model-Based and Data-Driven Approaches for the Prediction of the Mechanical Properties of Lattice Structures

## 开发和比较基于模型和数据驱动的方法来预测晶格结构的机械性能

Link: https://arxiv.org/abs/2501.05762

**Authors:** Chiara Pasini, Oscar Ramponi, Stefano Pandini, Luciana Sartore, Giulia Scalet

arXiv:2501.05762v1 Announce Type: cross 
Abstract: Lattice structures have great potential for several application fields ranging from medical and tissue engineering to aeronautical one. Their development is further speeded up by the continuing advances in additive manufacturing technologies that allow to overcome issues typical of standard processes and to propose tailored designs. However, the design of lattice structures is still challenging since their properties are considerably affected by numerous factors. The present paper aims to propose, discuss, and compare various modeling approaches to describe, understand, and predict the correlations between the mechanical properties and the void volume fraction of different types of lattice structures fabricated by fused deposition modeling 3D printing. Particularly, four approaches are proposed: (i) a simplified analytical model; (ii) a semi-empirical model combining analytical equations with experimental correction factors; (iii) an artificial neural network trained on experimental data; (iv) numerical simulations by finite element analyses. The comparison among the various approaches, and with experimental data, allows to identify the performances, advantages, and disadvantages of each approach, thus giving important guidelines for choosing the right design methodology based on the needs and available data.


---
# Quantum Speedup for Nonreversible Markov Chains

## 不可逆马尔可夫链的量子加速

Link: https://arxiv.org/abs/2501.05868

**Authors:** Baptiste Claudon, Jean-Philip Piquemal, Pierre Monmarch\'e

arXiv:2501.05868v1 Announce Type: cross 
Abstract: Quantum algorithms can potentially solve a handful of problems more efficiently than their classical counterparts. In that context, it has been discussed that Markov chains problems could be solved significantly faster using quantum computing. Indeed, previous work suggests that quantum computers could accelerate sampling from the stationary distribution of reversible Markov chains. However, in practice, certain physical processes of interest are nonreversible in the probabilistic sense and reversible Markov chains can sometimes be replaced by more efficient nonreversible chains targeting the same stationary distribution. This study uses modern quantum algorithmic techniques and Markov chain theory to sample from the stationary distribution of nonreversible Markov chains with faster worst-case runtime and without requiring the stationary distribution to be computed up to a multiplicative constant. Such an up-to-exponential quantum speedup goes beyond the predicted quadratic quantum acceleration for reversible chains and is likely to have a decisive impact on many applications ranging from statistics and machine learning to computational modeling in physics, chemistry, biology and finance.


---
# Discovery of sustainable energy materials via the machine-learned material space

## 通过机器学习的材料空间发现可持续能源材料

Link: https://arxiv.org/abs/2501.05903

**Authors:** Malte Grunert, Max Gro{\ss}mann, Erich Runge

arXiv:2501.05903v1 Announce Type: cross 
Abstract: Does a machine learning model actually gain an understanding of the material space? We answer this question in the affirmative on the example of the OptiMate model, a graph attention network trained to predict the optical properties of semiconductors and insulators. By applying the UMAP dimensionality reduction technique to its latent embeddings, we demonstrate that the model captures a nuanced and interpretable representation of the materials space, reflecting chemical and physical principles, without any user-induced bias. This enables clustering of almost 10,000 materials based on optical properties and chemical similarities. Beyond this understanding, we demonstrate how the learned material space can be used to identify more sustainable alternatives to critical materials in energy-related technologies, such as photovoltaics. These findings demonstrate the dual utility of machine learning models in materials science: Accurately predicting material properties while providing insights into the underlying materials space. The approach demonstrates the broader potential of leveraging learned materials spaces for the discovery and design of materials for diverse applications, and is easily applicable to any state-of-the-art machine learning model.


---
# Complexity of Tensor Product Functions in Representing Antisymmetry

## 表示反对称性的张量积函数的复杂性

Link: https://arxiv.org/abs/2501.05958

**Authors:** Yuyang Wang, Yukuan Hu, Xin Liu

arXiv:2501.05958v1 Announce Type: cross 
Abstract: Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings uncover a fundamental incompatibility between antisymmetry and low-rank TPFs in high-dimensional contexts and offer new insights for further developments.


---
# SECRET: Stochasticity Emulator for Cosmic Ray Electrons

## 秘密: 宇宙射线电子的随机性仿真器

Link: https://arxiv.org/abs/2501.06011

**Authors:** Nikolas Frediani (RWTH Aachen), Michael Kr\"amer (RWTH Aachen), Philipp Mertsch (RWTH Aachen), Kathrin Nippel (RWTH Aachen)

arXiv:2501.06011v1 Announce Type: cross 
Abstract: The spectrum of cosmic-ray electrons depends sensitively on the history and spatial distribution of nearby sources. Given our limited observational handle on cosmic-ray sources, any model remains necessarily probabilistic. Previously, predictions were performed in a Monte Carlo fashion, summing the contributions from individual, simulated sources to generate samples from the statistical ensemble of possible electron spectra. Such simulations need to be re-run if the cosmic-ray transport parameters (e.g. diffusion coefficient, maximum energy) are changed, rendering any parameter study computationally expensive. In addition, a proper statistical analysis of observations and comparison with such probabilistic models requires the joint probability distribution of the full spectrum instead of only samples. Note that parametrising this joint distribution is rendered difficult by the non-Gaussian statistics of the cosmic-ray fluxes. Here, we employ machine learning to compute the joint probability distribution of cosmic-ray electron fluxes. Specifically, we employ masked autoregressive density estimation (MADE) for a representation of the high-dimensional joint probability distribution. In a first step, we train the network on a Monte Carlo simulation for a fixed set of transport parameters, thus significantly accelerating the generation of samples. In a second step, we extend this setup to SECRET (Stochasticity Emulator for Cosmic Ray Electrons), allowing to reliably interpolate over the space of transport parameters. We make the MADE and SECRET codes available at https://git.rwth-aachen.de/pmertsch/secret .


---
# Multi-Phase Dataset for Ti and Ti-6Al-4V

## Ti和Ti-6Al-4V的多阶段数据集

Link: https://arxiv.org/abs/2501.06116

**Authors:** Connor S. Allen, Albert P. Bart\'ok

arXiv:2501.06116v1 Announce Type: cross 
Abstract: Titanium and its alloys are technologically important materials that display a rich phase behaviour. In order to enable large-scale, realistic modelling of Ti and its alloys on the atomistic scale, Machine Learning Interatomic Potentials (MLIPs) are crucial, but rely on databases of atomic configurations. We report databases of such configurations that represent the {\alpha}, \b{eta}, {\omega} and liquid phases of Ti and the Ti-6Al-4V alloy, where we provide total energy, force and stress values evaluated by Density Functional Theory (DFT) using the PBE exchange-correlation functional. We have also leveraged and extended a data reduction strategy, via non-diagonal supercells, for the vibrational properties of Ti and sampling of atomic species within bulk crystalline data for Ti-6Al-4V. These configurations may be used to fit MLIP models that can accurately model the phase behaviour of Ti and Ti-6Al-4V across a broad range of thermodynamic conditions. To validate models, we assembled a set of benchmark protocols, which can be used to rapidly develop and evaluate MLIP models. We demonstrated the utility of our databases and validation tools by fitting models based on the Gaussian Approximation Potential (GAP) and Atomic Cluster Expansion (ACE) frameworks.


---
# Machine Learning Force-Field Approach for Itinerant Electron Magnets

## 用于巡回电子磁体的机器学习力场方法

Link: https://arxiv.org/abs/2501.06171

**Authors:** Sheng Zhang, Yunhao Fan, Kotaro Shimizu, Gia-Wei Chern

arXiv:2501.06171v1 Announce Type: cross 
Abstract: We review the recent development of machine-learning (ML) force-field frameworks for Landau-Lifshitz-Gilbert (LLG) dynamics simulations of itinerant electron magnets, focusing on the general theory and implementations of symmetry-invariant representations of spin configurations. The crucial properties that such magnetic descriptors must satisfy are differentiability with respect to spin rotations and invariance to both lattice point-group symmetry and internal spin rotation symmetry. We propose an efficient implementation based on the concept of reference irreducible representations, modified from the group-theoretical power-spectrum and bispectrum methods. The ML framework is demonstrated using the s-d models, which are widely applied in spintronics research. We show that LLG simulations based on local fields predicted by the trained ML models successfully reproduce representative non-collinear spin structures, including 120$^\circ$, tetrahedral, and skyrmion crystal orders of the triangular-lattice s-d models. Large-scale thermal quench simulations enabled by ML models further reveal intriguing freezing dynamics and glassy stripe states consisting of skyrmions and bi-merons. Our work highlights the utility of ML force-field approach to dynamical modeling of complex spin orders in itinerant electron magnets.


---
# Two-Stage Super-Resolution Simulation Method of Three-Dimensional Street-Scale Atmospheric Flows for Real-Time Urban Micrometeorology Prediction

## 用于城市微气象实时预测的三维街道尺度大气流两级超分辨率模拟方法

Link: https://arxiv.org/abs/2404.02631

**Authors:** Yuki Yasuda, Ryo Onishi

arXiv:2404.02631v3 Announce Type: replace 
Abstract: A two-stage super-resolution simulation method is proposed for street-scale air temperature and wind velocity, which considerably reduces computation time while maintaining accuracy. The first stage employs a convolutional neural network (CNN) to correct large-scale flows above buildings in the input low-resolution simulation results. The second stage uses another CNN to reconstruct small-scale flows between buildings from the output of the first stage, resulting in high-resolution inferences. The CNNs are trained using high-resolution simulation data for the second stage and their coarse-grained version for the first stage as the ground truth, where the high-resolution simulations are conducted independently of the low-resolution simulations used as input. This learning approach separates the spatial scales of inference in each stage. The effectiveness of the proposed method was evaluated using micrometeorological simulations in an actual urban area around Tokyo Station in Japan. The super-resolution simulation successfully inferred high-resolution atmospheric flows, reducing errors by approximately 50% compared to the low-resolution simulations. Furthermore, the two-stage approach enabled localized high-resolution inferences, reducing GPU memory usage to as low as 12% during training. The total wall-clock time for 60-min predictions was reduced to 6.83 min, which was 3.32% of the high-resolution simulation time.


---
# Machine-learned design principles for enhanced red emission from nitride quantum wells

## 氮化物量子阱增强红光发射的机器学习设计原理

Link: https://arxiv.org/abs/2410.23591

**Authors:** Nick Pant, Rob Armitage, Emmanouil Kioupakis

arXiv:2410.23591v4 Announce Type: replace 
Abstract: Significant effort has been devoted toward mitigating polarization fields in nitride LEDs, as they are viewed as detrimental to light emission, albeit with limited success for red emission. Here, we show that such fields can unusually enhance the optical oscillator strength of red-emitting nitride quantum wells. This insight is enabled by machine-learned models trained on multi-scale quantum-mechanical simulations, allowing for a global exploration of the quantum-well design space at greatly reduced computational cost. Larger polarization fields correlate with higher wave-function overlaps for red emission, a consequence of the quantum-confined Stark effect enabling thinner quantum wells. This finding has implications for designing efficient red nitride LEDs, which are crucial for miniaturizing polychromatic LED pixels to the micron scale for extended-reality and biomedical applications. More broadly, this work highlights the power of machine learning in accelerating the discovery of unconventional paradigms for semiconductor design.


---
# Providing Machine Learning Potentials with High Quality Uncertainty Estimates

## 提供具有高质量不确定性估计的机器学习潜力

Link: https://arxiv.org/abs/2501.05250

**Authors:** Zeynep Sumer, James L. McDonagh, Clyde Fare, Ravikanth Tadikonda, Viktor Zolyomi, David Bray, Edward Pyzer-Knapp

arXiv:2501.05250v2 Announce Type: replace 
Abstract: Computational chemistry has come a long way over the course of several decades, enabling subatomic level calculations particularly with the development of Density Functional Theory (DFT). Recently, machine-learned potentials (MLP) have provided a way to overcome the prevalent time and length scale constraints in such calculations. Unfortunately, these models utilise complex and high dimensional representations, making it challenging for users to intuit performance from chemical structure, which has motivated the development of methods for uncertainty quantification. One of the most common methods is to introduce an ensemble of models and employ an averaging approach to determine the uncertainty. In this work, we introduced Bayesian Neural Networks (BNNs) for uncertainty aware energy evaluation as a more principled and resource efficient method to achieve this goal. The richness of our uncertainty quantification enables a new type of hybrid workflow where calculations can be offloaded to a MLP in a principled manner.


---
# DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks with Graph Neural Networks

## DeepTrace: 学习使用图神经网络优化流行病网络中的接触者追踪

Link: https://arxiv.org/abs/2211.00880

**Authors:** Chee Wei Tan, Pei-Duo Yu, Siya Chen, H. Vincent Poor

arXiv:2211.00880v4 Announce Type: replace-cross 
Abstract: Digital contact tracing aims to curb epidemics by identifying and mitigating public health emergencies through technology. Backward contact tracing, which tracks the sources of infection, proved crucial in places like Japan for identifying COVID-19 infections from superspreading events. This paper presents a novel perspective of digital contact tracing as online graph exploration and addresses the forward and backward contact tracing problem as a maximum-likelihood (ML) estimation problem using iterative epidemic network data sampling. The challenge lies in the combinatorial complexity and rapid spread of infections. We introduce DeepTrace, an algorithm based on a Graph Neural Network (GNN) that iteratively updates its estimations as new contact tracing data is collected, learning to optimize the maximum likelihood estimation by utilizing topological features to accelerate learning and improve convergence. The contact tracing process combines either BFS or DFS to expand the network and trace the infection source, ensuring comprehensive and efficient exploration. Additionally, the GNN model is fine-tuned through a two-phase approach: pre-training with synthetic networks to approximate likelihood probabilities and fine-tuning with high-quality data to refine the model. Using COVID-19 variant data, we illustrate that DeepTrace surpasses current methods in identifying superspreaders, providing a robust basis for a scalable digital contact tracing strategy.


---
# Deep Learning the Forecast of Galactic Cosmic-Ray Spectra

## 深度学习银河宇宙射线光谱的预测

Link: https://arxiv.org/abs/2410.21046

**Authors:** Yi-Lun Du, Xiaojian Song, Xi Luo

arXiv:2410.21046v3 Announce Type: replace-cross 
Abstract: We introduce a novel deep learning framework based on Long Short-Term Memory (LSTM) networks to predict galactic cosmic-ray spectra on a one-day-ahead basis by leveraging historical solar activity data, overcoming limitations inherent in traditional transport models. By flexibly incorporating multiple solar parameters, such as the heliospheric magnetic field, solar wind speed, and sunspot numbers, our model achieves accurate short-term and long-term predictions of cosmic-ray flux. The addition of historical cosmic-ray flux data significantly enhances prediction accuracy, allowing the model to capture complex dependencies between past and future flux variations. Additionally, the model reliably predicts full cosmic-ray spectra for different particle species, enhancing its utility for comprehensive space weather forecasting. Our approach offers a scalable, data-driven alternative to traditional physics-based methods, ensuring robust daily and long-term forecasts. This work opens avenues for advanced models that can integrate broader observational data, with significant implications for space weather monitoring and mission planning.


---
# Noise Removal Tool for Compressible and Incompressible Flows Using a Physics-Informed Neural Network

## 使用物理信息神经网络的可压缩和不可压缩流的噪声去除工具

Link: https://dx.doi.org/10.26434/chemrxiv-2025-1qlft?rft_dat=source%3Ddrss

**Authors:** Jisha, C R

Noise removal from data or sensors is a crucial challenge in experimental studies, where traditional techniques such as filters and smoothers are commonly employed. However, these methods often lack a physics-based foundation, requiring either domain expertise or an extensive trial-and-error process to achieve satisfactory outcomes. Moreover, their performance deteriorates as noise levels increase, often leading to significant distortion of the original signal or derived quantity based on the signal. Physics-informed neural networks (PINNs) provide an innovative solution by integrating physical laws and governing equations into the machine learning framework. This study investigates the potential of PINNs to enhance noise removal compared to conventional numerical methods. Specifically, we assess the performance of numerical methods both with and without filtering alongside PINNs in the context of transport equations. We have studied the effectiveness of the above-mentioned techniques on synthetically generated subsonic and supersonic flows from numerical simulation. The results reveal that PINNs can effectively reconstruct pressure information from noisy velocity data, a task that traditional numerical methods do not perform adequately on noisy high Reynolds number cases. This finding highlights the superior capability of PINNs in addressing noise-related challenges in signal processing, particularly under high-noise conditions and high Reynolds number cases.


---
# ATAC-seq Guided Interpretable Machine Learning Reveals Cancer-Specific Chromatin Features in Cell-free DNA

## Atac-seq指导的可解释机器学习揭示无细胞DNA中的癌症特异性染色质特征

Link: https://www.researchsquare.com/article/rs-5485170/latest

Cell-free DNAs (cfDNAs) are DNA fragments found in blood. In healthy individuals, cfDNAs are primarily derived from immune cells, while in cancer patients, a significant fraction of cfDNAs originates from cancerous cells. These cancer-derived cfDNAs contain specific mutations, making cfDNA analysis a promising diagnostic biomarker. Recent studies have revealed that epigenetic information, such as DNA methylation and nucleosome positioning, is retained in cfDNAs, enhancing the accuracy of cell-of-origin predictions. This study aims to characterize the chromatin architecture preserved in cfDNAs by looking at nucleosomal DNA enrichment. Nucleosome fragments from both breast and pancreatic cancer patients are significantly enriched in open chromatin regions. A differential enrichment was observed between healthy donors and cancer patients at cell type-specific ATAC-seq peaks. Leveraging this pattern of open chromatin enrichment, we enhanced the prediction accuracy for identifying breast cancer-derived cfDNA through machine learning. Our analysis pipeline provides an interpretable machine learning platform that effectively detects cancer-specific nucleosome enrichment in cfDNAs.


---
# Gain neuromodulation mediates perceptual switches: evidence from pupillometry, fMRI, and RNN Modelling

## 增益神经调节介导感知开关: 来自瞳孔测量，fMRI和RNN建模的证据

Link: https://www.researchsquare.com/article/rs-2356429/latest

Perceptual updating has been proposed to rely upon evolving activity within a recurrent, distributed thalamocortical network whose interconnections are modulated by bursts of ascending neuromodulatory neurotransmitters, such as noradrenaline. To test this hypothesis mechanistically, we leveraged a combination of pupillometry, fMRI and recurrent neural network modelling of an ambiguous figures task. Qualitative shifts in the perceptual interpretation of an ambiguous image were associated with peaks in pupil diameter, an indirect readout of phasic bursts in neuromodulatory tone. We hypothesized that increases in neuromodulatory tone led to neural gain alteration so as to causally mediate perceptual switches. To test this hypothesis, we trained a recurrent neural network to perform an analogous perceptual categorisation task, and then manipulated the gain of the RNN to mimic the effect of neuromodulatory tone. As predicted, we observed an earlier perceptual shift as a function of heightened gain. Leveraging a low-dimensional readout of the RNN dynamics, we developed two novel predictions: perceptual switches should co-occur with peaks in low-dimensional brain state velocity and with flattened energy landscape dynamics. We used dimensionality-reduced summaries of whole-brain fMRI dynamics to independently confirm each of these predictions. These results support the role of the neuromodulatory system in the large-scale network reconfigurations that mediate abrupt changes in perception.


---
# Utilizing Machine Learning to Decode Growth Patterns and Yield Dynamics in Potato Cultivation

## 利用机器学习解码马铃薯栽培中的生长模式和产量动态

Link: https://www.researchsquare.com/article/rs-5766512/latest

Understanding growth patterns and yield dynamics in potato cultivation is essential for optimizing agricultural practices and improving productivity. This study leverages machine-learning techniques to analyze and predict potato growth stages and yield outcomes based on environmental and physiological data. Various machine-learning models were developed using multispectral imaging, soil parameters, and climatic factors collected across diverse cultivation environments. The models were evaluated for their accuracy in identifying growth stages and forecasting yield performance. Key physiological trends were identified during the tuber initiation, bulking, and maturation phases, correlating with specific environmental conditions. Predictions for tuber yield showed high accuracy, with models achieving R&amp;sup2; values above 0.90 across validation datasets. Additionally, the study highlights the importance of integrating machine learning with precision agriculture systems to enhance decision-making and resource management. The proposed methodology demonstrates significant potential for advancing potato-farming practices by providing actionable insights into growth and yield optimization.


---
# MH-YOLO: A Lightweight Traffic Sign Detection Method Based on YOLOv10n with Hybrid Attention Transformer and Multi-Scale Dilated&nbsp; Attention

## Mh-yolo: 一种基于YOLOv10n的混合注意力变换器和多尺度扩张注意力的轻量级交通标志检测方法

Link: https://www.researchsquare.com/article/rs-5801614/latest

In intelligent transportation systems, the accurate and real-time detection and recognition of traffic signs are crucial for autonomous and assisted driving. Despite improvements in efficiency and accuracy of existing deep learning object detection algorithms, challenges remain in detecting small objects, handling multi-scale targets, and achieving real-time detection in low computational resource environments. To address these challenges, we propose a lightweight YOLOv10n-based method that incorporates a Hybrid Attention Transformer (HAT) to enhance the super-resolution reconstruction of small targets, thereby improving detection accuracy. Additionally, we introduce a Multi-Scale Dilated Attention mechanism (MDA), embedded within the YOLOv10n model to capture multi-scale semantic information through self-attention mechanisms, effectively enhancing the model's detection performance. The proposed method, termed MH-YOLO, significantly improves detection effectiveness while maintaining low computational complexity. Furthermore, to address the lack of nighttime traffic sign data and region-specific sign data in existing datasets, we constructed the Chinese Traffic Sign Dataset (CTSDB), covering all time periods and various complex scenarios. Experimental results show that MH-YOLO achieves detection accuracy comparable to more complex models while maintaining model lightweightness.


---
# A Dual-Branch Approach with Multi-Stage Semantic Integration and Dual Optical Flow for Micro- Expression Recognition

## 基于多阶段语义融合和双光流的双分支微表情识别方法

Link: https://www.researchsquare.com/article/rs-5801228/latest

Micro-expression can reveal a person's true feelings and possesses significant importance in fields such as police interrogation and psychological counseling. However, due to the subtlety and complexity of micro-expression, comprehensively understanding its features remains a considerable challenge. To address this challenge, this paper proposes a dual-branch network structure that integrates traditional optical flow with deep learning-based optical flow. The micro-expression features are extracted and processed in separate branches, thereby harnessing the complementary advantages of the two optical flow methods. The first branch employs the proposed Multi-Scale Patch Attention Convolution Network (MPACNet), which is designed to process Farneback optical flow by capturing local details. The second branch utilizes the Swin Transformer network with FlowNet2 optical flow, demonstrating outstanding performance in extracting global dynamic information. In addition, this framework effectively combines local information from traditional convolutional networks with both local and global information from the Swin Transformer, achieving multi-level feature fusion. Following the standards of Comprehensive Database Evaluation (CDE) and Single Database Evaluation (SDE), extensive experiments have been conducted on four datasets&amp;mdash;SMIC-HS, CASME II, SAMM, and CAS(ME)3. The results demonstrate that the proposed method outperforms other state-of-the-art approaches across various evaluation metrics.


---
# Integrated Stochastic Modeling and Neural Networks for Inverse Prediction of Elastic Modulus in Beams

## 集成随机建模和神经网络用于梁弹性模量的逆预测

Link: https://www.researchsquare.com/article/rs-5799356/latest

In this work we have obtained elastic modulus from the eigen frequencies of a cantilever beam. The elastic modulus of the beam has random elastic modulus haing exponential covariance function. We have used Monte Carlo simulations with cholesky decomposition to obtain the elastic modulus and eigen frequency data. The data driven non intrusive polynomial chaos is used to obtain eigen elastic modulus from the eigen frequencies. The difference between the elastic modulus data obtained from MCS and NiPCE are used to train a neural network. For new prediction the elastic modulus data from PCE and the difference from neural network are added. The final results shows remarkable resemble with actual data or MCs data. Also the computational time of our proposed method is significantly lower than mcs time as the neural network once trained need smaller time to give the output.


---
# Research on safe path planning for unmanned aerial vehicles based on an Improved Pied Kingfisher Optimization Algorithm

## 基于改进Pied翠鸟优化算法的无人机安全航迹规划研究

Link: https://www.researchsquare.com/article/rs-5739312/latest

The safety route planning problem in UAVs (Unmanned Aerial Vehicles)missions is the subject of this paper, which suggests a method based on an improved Pied Kingfisher Optimization algorithm (IPKO) algorithm. By adding collision avoidance restrictions to the swarm scenario, the study expands the single UAVs path planning problem to improve flight safety. In order to reduce the problem of decreased convergence speed in the PKO algorithm, population diversity is increased and premature convergence to the local optimum is prevented by using mirror reflection learning. Furthermore, the algorithm is improved with a crash mechanism model and a fish hawk hunting approach, which allows UAVs to react in real time to environmental changes and avoid hazards. The IPKO algorithm performs better than conventional algorithms in terms of path efficiency and safety, as evidenced by experimental results, which also provide a fresh view of UAV safety path planning.


---
# The Role of Digitalization on Carbon Emissions: Spatial DDML Test and Neural Networks Prediction

## 数字化对碳排放的作用: 空间DDML测试一下和神经网络预测

Link: https://www.researchsquare.com/article/rs-5755594/latest

Based on the Chinese provincial panel data from 2011 to 2022, this paper innovatively use the spatial double/debiased machine learning (DDML) model, planar and spatial mediating model to study the effect, mediating mechanisms of the digitalization on carbon emissions in both local and surrounding areas. The empirical studies show that digitalization significantly reduces carbon emissions in the local area. Digitalization reduces local carbon emissions by promoting the transformation of energy industrial structure and green technological innovation, reduces carbon emissions in the surrounding regions by promoting the improvement of energy utilization efficiency and green technological progress, improve the industrial intensification in local and surrounding areas thus reducing carbon emissions. Prediction by using the LSTM and neural network shows that for 30 provinces in China except Tibet in 2030, peak carbon dioxide emissions is achievable. For digitally developed regions, or where digitization is lagging behind but developing rapidly, digitization can help these provinces achieve peak carbon dioxide emissions with less emissions. For provinces where digitization is relatively undeveloped, digitization makes little difference in reducing carbon emissions in the process of achieving peak carbon dioxide emissions. For regions where digitization is lagging behind and developing slowly, due to the extensiveness of the industrial model in these provinces, digitization shows a rebound effect, making these regions put more energy demand into the produce, and thus carbon emissions will increase.


---
# Empowering Energy-Efficient Resource Allocation in Mobile Networks with Deep Q-Learning Intelligence

## 基于深度Q学习智能的移动网络节能资源分配

Link: https://www.researchsquare.com/article/rs-5780317/latest

Mobile networks are in a demanding situation due to various users and requirements as well as optimization of resources to make it energy efficient. As a reaction to these challenges, this research advocates a new method based on DQL, which relies on deep reinforcement learning, for resource allocation in mobile networks. The purpose is to improve energy efficiency and throughput by applying learned intelligence into resource allocation. Achieve this by dynamically, on the basis of learned intelligence, allocating resources to the most important tasks. The proposed framework encompasses several key components: data collection for determining state of the network and user needs, infrastructural setup (including simulation environments), reinforcement learning application (for optimizing resources allocation policies), the model's architecture, training, and evaluation are carefully designed to adapt to dynamic channel conditions and diverse simulation environments. To further enhance the model's performance, additional settings and techniques can be employed The presented optimized techniques subject to DQL are finally capable of showing that the recommended resource allocation framework indeed works. After considerable improvements are experienced to end up with energy efficiency, throughput, fairness index, and capacity compared with the traditional regimes. Implementing intelligent and adaptive resource management techniques in networks represents a significant enhancement to the current state-of-the-art in smart networks, offering a valuable addition to existing capabilities. By leveraging dynamic methods, networks can optimize resource allocation, improve efficiency, and adapt to changing conditions, ultimately leading to enhanced performance, reliability, and user experience The proposed framework can be a good solution for allocating the resources of mobile networks in a way that meets the network&amp;rsquo;s performance needs promptly and steadily, which leads to efficient and sustainable network operations. From the foregoing, this study has far-reaching implications for the future of mobile communication networks, as it demonstrates the potential of deep reinforcement learning methods to revolutionize resource allocation optimization. By harnessing the power of artificial intelligence, network operators can unlock significant improvements in efficiency, performance, and user experience, ultimately paving the way for more robust, adaptive, and intelligent mobile networks that can meet the evolving demands of a connected world.


---
# Gut microbiota in young adults with high-functioning autism spectrum disorder and its performance as diagnostic biomarkers

## 年轻成人高功能自闭症谱系障碍的肠道菌群及其作为诊断生物标志物的表现

Link: https://www.researchsquare.com/article/rs-5753373/latest

Although autism spectrum disorder (ASD) starts in the early developmental period, symptoms may not become fully apparent until adulthood in patients with high-functioning ASD. Diagnosing ASD in adults presents unique challenges and there are currently no specific biomarkers for this condition. Most existing studies on gut microbiota in ASD are conducted in children; however, the composition of the gut microbiota in children differs significantly from that of adults. This study aimed to study young adults with high-functioning ASD on their gut microbiota. Using metagenomic sequencing, we evaluated the gut microbiota in 45 adults with high-functioning ASD and 45 matched healthy controls. Adjusting for sociodemographic information, dietary habits, and clinical data, we observed a distinct microbiota profile between adults with ASD and controls, with their autistic symptom severity strongly correlating to microbial diversity (correlation coefficient = -0.351, p-value &amp;lt;0.001). Despite a similar dietary pattern, the ASD group exhibited more gastrointestinal symptoms than the healthy controls. An internally validated machine-learning predictive model that combines the Autism Spectrum Quotient questionnaire score and microbial features could achieve an area under the receiver operating characteristic curve (AUC) of 0.955 in diagnosing ASD in adults. This study evaluates the gut microbiota in adult ASD and highlights its potential as a non-invasive biomarker to enhance diagnosis of ASD in this population group.


---
# Identification of pancreatic nonfunctional neuroendocrine tumors and solid pseudopapillary tumors via the construction of a consensus clustering model based on enhanced CT images

## 通过基于增强CT图像的共识聚类模型的构建识别胰腺无功能神经内分泌肿瘤和实性假乳头状肿瘤

Link: https://www.researchsquare.com/article/rs-5782491/latest

Background: Unsupervised clustering has played a greater role in the diagnosis and differential diagnosis of pancreatic tumors in recent years. This study aimed to investigate the value of constructing a c[1]lustering model for unsupervised learning based on enhanced CT to identify pancreatic nonfunctional neuroendocrine tumors (NF-pNETs) and solid pseudopapillary tumors (SPTs).
Methods: 45 patients with SPTs and 47 patients with NF-psNETs were retrospectively analyzed. The data were randomly divided into a training set and a validation set at a ratio of 7:3. One-way logistic regression was performed for each clinical variable to assess its relationship with the clustered labels, and a logistic regression model was fitted with the clustered labels as the dependent variable and the clinical variables as independent variables. Variables with P values &amp;lt;0.1 were selected for further analysis. Multifactorial logistic regression models were fitted via the clinical variables selected in the univariate analysis, ridge regularization (L2 penalty) was used to prevent overfitting and address potential multicollinearity, with the strength of regularization (alpha) set to a default value of 1. Clinical variables that were meaningful in the multifactorial logistic regression analyses were used to construct the final logistic regression model, which was used to predict individual clinical-based group labeling on the basis of individual clinical characteristics. For imaging, the optimal number of clusters k selected by the covariance coefficient was used to build the clustering model via unsupervised classification of the lesions through consensus clustering analysis fusing the imaging histological features of arterial-phase, venous-phase, and delayed-phase images. The clinical factors with a final p value &amp;lt; 0.2 were subsequently combined with the clustering model to perform stepwise multivariate logistic regression analyses, thereby establishing a joint model. The performance of the three models was assessed via AUC values, and column line plots were generated to visualize the models. Finally, the clinical validity of the models was assessed via decision curve analysis (DCA).
Results:&amp;nbsp; The AUCs of the clustered and clinical models were 0.70 and 0.74 (95% CI: 0.66&ndash;0.81) in the training set and 0.65 and 0.75 (95% CI: 0.64&ndash;0.87) in the validation set, and the AUCs of the training and test sets in the joint model were 0.88 (95% CI: 0.81&ndash;0.94) and 0.85 (95% CI: 0.71&ndash;0.96), respectively. Decision curve analysis revealed that the joint clinical-clustering model had a greater net benefit when the high-risk threshold probability was in the range of 0--1.
Conclusions: Unsupervised clustering models based on enhanced CT have potential for discriminating between SPTs and NF-PNETs, which can inform clinical decision-making.


---
# A Grounded Theory Investigation into the Otolaryngology Resident Learning Experience

## 耳鼻咽喉科住院医师学习体验的扎根理论调查

Link: https://www.researchsquare.com/article/rs-5760451/latest

Background
Otolaryngologic residency operative education is a unique process that teaches technical and reasoning skills during high-stakes situations. However, there is no consensus on what qualities of a teacher or environment create a positive surgical learning experience. This study aims to use qualitative assessment to identify key elements of effective otolaryngologic residency education.
Methods
Purposive sampling was used to select a heterogeneous cohort from our institution&rsquo;s Otolaryngology department between March and December 2023. Interviewees were categorized as either &ldquo;Learners&rdquo; (residents) or &ldquo;Teachers&rdquo; (attending) and either &ldquo;Junior&rdquo; or &ldquo;Senior.&rdquo; A trained interviewer conducted semi-structured interviews until thematic saturation was reached. Constant comparative analysis using coding, memoing, and categorization was conducted using grounded theory methodology.
Results
Twenty-one participants completed interviews, averaging 42 minutes. A total of 87 codes and 15 concepts were extracted from the data. Advanced coding and theoretical integration revealed four themes that are essential to the creation of a positive teaching experience: &ldquo;Investment in Learner/Education,&rdquo; &ldquo;Communication,&rdquo; &ldquo;Discerning Learner Capacity,&rdquo; and &ldquo;Creation of Learning Environment.&rdquo; &ldquo;Investment&rdquo; and &ldquo;Discerning Capacity&rdquo; represent the ability and desire of the teacher to assess and advance learner progress during surgery. &ldquo;Communication&rdquo; refers to the ability to convey information clearly and succinctly. &ldquo;Creation&rdquo; reflects the ability of the teacher/surgeon to navigate the complex operative environment to create a safe and effective learning experience within the context of a surgical operation.
Conclusions
This study suggests that positive operative learning experiences rely on four thematic elements. A teacher's conscious attention to these elements and feedback from learners targeting them may assist in creating a more effective surgical learning environment. Further research is needed to understand the nuance of learner and teacher experience and how best to optimize and operationalize these concepts in diverse surgical educational settings.
Clinical trial number: not applicable


---
# Integrated photonic 3D tensor processing engine

## 集成光子3D张量处理引擎

Link: https://www.researchsquare.com/article/rs-5399911/latest

Optical computing leverages high bandwidth, low latency, and power efficiency, which is considered as one of the most effective solutions for accelerating deep learning tasks. However, mainstream photonic hardware accelerators are primarily optimized for two-dimensional (2D) matrix-vector multiplications (MVMs). To implement three-dimensional (3D) convolutional neural networks (CNNs), high-order tensors must be reshaped, duplicated, and cached in the electrical domain according to the size of the accelerators before computation, leading to extra memory usage and time overheads. Additionally, synchronization across multiple channels depends on external electronic clocks, which increases the complexity of the system. In this work, we propose an integrated photonic 3D tensor processing engine (3D-TPE) based on the interweaving of time, wavelength, and space. Data caching, computation, and synchronization are realized in the optical domain, reducing memory and time usage, and simplifying the system. Optical caching and synchronization are achieved with an optical tunable delay line chip supporting versatile clock frequencies up to 200 GHz, and optical computing is accomplished with a dual-coupled micro-ring resonators (MRRs) based crossbar chip with a 3-dB passband width of 50 GHz. We verify the processing capabilities of the 3D-TPE at clock frequencies ranging from 10 GHz to 30 GHz and perform a proof-of-concept experiment for a LiDAR 3D point cloud image recognition task operating at 20 GHz, achieving a recognition accuracy of 97.06%. The proposed 3D-TPE is anticipated to facilitate high-order tensor convolutions, playing an important role in autonomous driving, healthcare, video analytics, virtual reality, etc.


---
# Using Cumulative summation analysis (CUSUM) for the learning curve of robotic docking time in radical prostatectomy with the HUGO RAS System

## 使用HUGO RAS系统对根治性前列腺切除术中机器人对接时间的学习曲线进行累积求和分析 (cu sum)

Link: https://www.researchsquare.com/article/rs-5782260/latest

Minimally invasive surgery like robotic surgery is known to yield better outcomes in terms of blood loss, blood transfusion, and length of stay, and robot-assisted radical prostatectomy provides a clear example compared to open surgery. It is still constrained by issues related to platform availability and cost-effectiveness. Introducing new robotic platforms, such as the HUGO&amp;trade; Robot-Assisted Surgery (RAS) System, could lead to longer operating times caused by the surgeon's learning curve, system configuration, adjustment of robotic devices, and robotic docking. Several studies have assessed the influence of resident physicians on outcomes in urological surgeries. Our main objective was to evaluate the learning curve of the docking time for 195 radical prostatectomies performed in our hospital. The results of our research indicate that the setup and docking process with the HUGO RAS system can be accomplished with ease, and the learning curve for robotic docking is consistent with the available data for other robotic platforms. Our training facilitated a rapid docking process and seamless completion of the surgery.


---
# Accuracy and Reliability of 3D Cephalometric Landmark Detection with Deep Learning

## 基于深度学习的三维头影测量界标检测准确性和可靠性

Link: https://www.researchsquare.com/article/rs-5777684/latest

Objective: Three-dimensional (3D) landmark detection is essential for assessing craniofacial growth and planning surgeries such as orthodontic, orthognathic, traumatic, and plastic procedures. This study aimed to develop an automatic 3D landmarking model for oral and maxillofacial regions and to validate its accuracy, robustness, and generalizability in both spiral computed tomography (SCT, 41 landmarks) and cone-beam computed tomography (CBCT, 14 landmarks) scans.
Methods: The model was constructed using an optimized lightweight 3D U-Net network architecture. Its accuracy, robustness, and generalizability were thoroughly evaluated and validated through a multicenter retrospective diagnostic study. The internal dataset included 480 SCT and 240 CBCT cases. For external validation, 320 SCT and 150 CBCT cases were assessed using mean radial error (MRE) and success detection rate within 2-, 3-, and 4-mm error thresholds as the primary evaluation metrics. Error analyses for landmark detection along each coordinate axis were performed. Consistency tests among index observers were conducted.
Results: The average MRE for both SCT and CBCT was consistently below 1.3 mm and, notably, below 1.4 mm in complex conditions such as malocclusion, missing dental landmarks, and the presence of metal artifacts. No significant differences in MRE and SDR at 2-4 mm were observed between external and internal SCT and CBCT sets. SCT bone landmarks were more precise than dental ones, with no difference between bone/soft tissue and dental/soft tissue. CBCT dental landmarks exhibited greater precision compared to bone landmarks. A detailed error analysis across the coordinate axes showed that the coronal axis had the highest error rates. The implementation of this model significantly improved the landmarking proficiency of senior and junior specialists by 15.9% and 28.9%, respectively, while also accelerating the process by a factor of 6 to 9.5 times.
Conclusions: This study shows that the AI-driven model delivers high-precision 3D localization of oral and maxillofacial structures, even in complex scenarios. The model can aid specialists across all experience levels in conducting accurate and efficient localization analyses, owing to its strong clinical utility, robustness, and generalizability.
Clinical Relevance: 3D cephalometric landmark detection is crucial for assessing craniofacial growth and planning diverse surgical procedures, such as orthodontic, orthognathic, trauma, and aesthetic interventions. The traditional manual landmark identification is time-consuming and requires significant expertise. This proposed AI method provides accurate measurements for both soft and hard tissues, streamlines digital planning, decreases reliance on expert knowledge, and enhances the efficiency and success of treatments.


---
# A learning-driven algorithm for maintenance team and UAV collaboration in restoring power network

## 一种学习驱动的电力网络维修团队与无人机协同恢复算法

Link: https://www.researchsquare.com/article/rs-5708499/latest

Power networks are highly vulnerable to disruptions caused by natural and man-made disasters, necessitating prompt restoration of damaged power supply. This research addresses the challenge of efficiently restoring large-scale power networks, which often involve numerous unknown or uninspected faulty nodes. Leveraging advancements in unmanned aerial vehicles (UAVs) technology, this study facilitates the inspection of these nodes and subsequent manual maintenance. However, coordinating maintenance teams and UAVs is complex due to the intricate network structure and scheduling correlations. We propose a learning-driven (LD) algorithm to enhance human-UAV collaboration for effective power network restoration. The algorithm includes an initialization method to generate promising initial solutions, followed by the use of search operators as basic action elements and a learning engine to guide search directions based on state assessments. Comprehensive experiments validate the algorithm&rsquo;s effectiveness in improving the restoration process.


---
# Spatio-temporal analysis of wetland loss in the lower Mekong River Basin based on surface water detection datasets and machine learning

## 基于地表水检测数据和机器学习的湄公河下游湿地流失时空分析

Link: https://www.researchsquare.com/article/rs-4781968/latest

Wetland loss and degradation is a major global issue in which its detailed estimation of spatio-temporal distribution will be a key for understanding the dynamics and subsequent impact assessment studies. This study aimed to estimate the spatio-temporal distributions of wetland loss, analyze its geographical characteristics, and quantify the likelihood of loss occurrence for existing wetlands in the lower Mekong River Basin in Cambodia. Using the global surface water detection datasets, the spatiotemporal distribution of wetland loss with high resolution (30m) over the entire study area (140km&amp;times;210km) during 1984&amp;ndash;2021 was estimated. Statistically significant differences were found in the distance from urban areas and distance from river channels for the existing wetlands and lost wetlands as of 2021, in which the lost wetlands tend to locate closer to urban areas. Subsequent Land Use/Land Cover after the wetland loss was found to be mainly croplands (72.2%) in the study area. Though our estimate overall agrees with the recent global-scale estimate, our estimate resulted in notable ratio of rangelands (11.3%), which represents the unique characteristics of floodplain wetlands in the lower Mekong River Basin. The Random Forest and Light GBM algorithms-based wetland loss prediction models resulted in good statistical evaluation metrics. In both models, the distance from river channels was found to be the most important feature for classifying existing wetlands and lost wetlands. Application of the developed models successfully provided the map of likelihood of wetland loss for existing wetlands in the study area.


---
# Design and optimization of energy-efficient wireless sensor networks for industrial automation

## 面向工业自动化的高能效无线传感器网络设计与优化

Link: https://www.researchsquare.com/article/rs-5731209/latest

In order to improve the overall performance of edge-integrated edge IoT networks, this research introduces a combined technique based on profound learning for booking assets. If an IoT network wants to finish a task quickly and effectively, it has to get the greatest resources from the edge layer. Thorough asset booking is crucial to the identification and transfer of optimal assets. The integration of edge networks with IoT applications and the reduction of data transmission latency were previously addressed using profound learning algorithms. If we want to make an Internet of Things application more feasible and provide better service overall, we should think about other metrics like reaction time, waiting time, and bandwidth needs. Combining a convolutional neural network with a gated repeating unit in a certain manner achieves this enhanced performance. The suggested asset booking model considers the features and requirements of the assets in order to select the most suitable ones from the pool and allocate them to the IoT networks. Here, we give a comprehensive analysis of the method-data combination.


---
# Cognitive Agent based Data Processing in Ubiquitous Network using Reinforcement Learning Approach

## 泛在网络中基于认知Agent的强化学习数据处理

Link: https://www.researchsquare.com/article/rs-5755530/latest

In the present era of heterogeneous networks, the data will be gathered from various diverse sources with varying data formats. Sometimes the data is used to make immediate decision making, such as adjusting environmental controls based on sensors or ubiquitous devices inputs or triggering alerts of devices in response to certain events. Hence, data processing is an essential task to contextualize information by analyzing various data points together. By processing data efficiently, UNT can optimize resource usage. The proposed work aims to tackle the problems of processing both real-time and non-real-time using a Cognitive Agents based machine learning approach for predictive analysis for the processing of data and evaluated against existing methods, comparing factors such as data processing time, query response time, energy consumption, throughput and computation overhead.


---
# Brain-Guided Convolutional Neural Networks Reveal Task-Specific Representations in Scene Processing

## 脑引导卷积神经网络揭示场景处理中特定于任务的表征

Link: https://www.researchsquare.com/article/rs-5753306/latest

Scene categorization is the dominant proxy for visual understanding, yet humans can perform a large number of visual tasks within any scene. Consequently, we know little about how different tasks change how the is scene processed, represented, and its features ultimately used.&nbsp; Here, we developed a novel brain-guided convolutional neural network (CNN) where each convolutional layer was separately guided by neural responses taken at different time points while observers performed two different tasks on the same set of images.&nbsp; We then reconstructed each layer&rsquo;s activation maps via deconvolution to spatially assess how different features were used as a function of task.&nbsp; The brain-guided CNN made use of image features that human observers identified as being crucial to complete each task starting around 244 ms and persisted to 402 ms. Critically, because the same images were used across the two tasks, the CNN could only succeed if the neural data captured task-relevant differences.&nbsp; Our analyses of the activation maps across layers revealed that the brain&rsquo;s spatiotemporal representation of local image features evolves systematically over time. This underscores how distinct image features emerge at different stages of processing, shaped by the observer&rsquo;s goals and behavioral context.


---
# Establishing a Periodic SM Profile Model Based on Fourier Analysis using Hydrologic Soil Groups

## 利用水文土壤组建立基于傅里叶分析的周期性SM剖面模型

Link: https://www.researchsquare.com/article/rs-5771651/latest

Accurately predicting global soil moisture (SM) is crucial for sustainable agriculture and water resource management. Recognizing the challenges posed by the heterogeneity of SM's spatiotemporal variability, this study proposes a novel approach that leverages Fourier analysis to decompose the periodic fluctuations in SM, revealing underlying trends and cycles. This approach is integrated with Long Short Term Memory (LSTM) networks to enhance the accuracy of global SM prediction. Fourier analysis transforms time series data of SM into frequencies and amplitudes, capturing its intrinsic periodic characteristics. This transformation reveals both variable and invariant features representing changes within and between periods. By fusing these periodic features within the cycle. By integrating these periodic features with sequence data and leveraging the memory and sequence learning capabilities of LSTM neural networks, the accuracy and reliability of global SM prediction can be enhanced. Our experiments on the LandBench1.0 dataset demonstrate that the proposed model reduces the root mean square error by 0.4% to 1.1% compared to the state-of-the-art methods. This study underscores that the LSTM with periodic features of SM can adapt to the inherent complex spatial-temporal patterns in SM dynamics, especially in scenarios characterized by rapid environmental changes and subtle temporal dynamics.


---
# Anston: An Attention Mechanism Network Model for Structured Data Classification

## Anston: 一种用于结构化数据分类的注意力机制网络模型

Link: https://www.researchsquare.com/article/rs-5766278/latest

To reduce the pressure on public health services caused by the aging population, nursing homes need to predict disease risks for the elderly periodically. To improve the disease risks predicting ability of nursing homes, we designed Anston (An Attention Mechanism Network Model for Structured Data Classification) in the application scenario of innovative elderly care. The Anston model can use the physiological indicators and pathogenic factors easily collected by nursing homes to predict disease risks. In the study of disease risk prediction based on physiological indicators and pathogenic factors for thoughtful elderly care, we designed a data enhancement method, a feature weight automatic update method, and a multi-layer perceptron neural network to solve the problems of sample shortage, inconsistent feature weights, and sample imbalance. At the same time, we designed an attention mechanism network model for structured data classification based on the multi-layer perceptron neural network developed in this paper. To fit the application scenario of competent elderly care, we propose a disease risk prediction model, Anston, based on the data enhancement method, feature automatic update method, and structured data classification attention mechanism network designed in this paper. We use public data sets and subject data as sample data in the experiment. The experimental results show that the Anston model has an accuracy of 95%, a precision of 92%, a recall of 91%, a specificity of 93%, an F1 score of 91%, and an AUC of 93% in predicting disease risks in the experiment, which have achieved the SOTA result.


---
# Transfer Learning on Protein Language Models Improves Antimicrobial Peptide Classification

## 蛋白质语言模型上的迁移学习改善了抗菌肽分类

Link: https://www.researchsquare.com/article/rs-5768912/latest

Antimicrobial peptides (AMPs) are essential components of the innate immune system in humans and other organisms, exhibiting potent activity against a broad spectrum of pathogens. Their potential therapeutic applications, particularly in combating antibiotic resistance, have rendered AMP classification a vital task in computational biology. However, the scarcity of labeled AMP sequences, coupled with the diversity and complexity of AMPs, poses significant challenges for the training of standalone AMP classifiers. Self-supervised learning has emerged as a powerful paradigm in addressing such challenges across various fields, leading to the development of Protein Language Models (PLMs). These models leverage vast amounts of unlabeled protein sequences to learn biologically relevant features, providing transferable protein sequence representations (embeddings), that can be fine-tuned for downstream tasks even with limited labeled data. This study evaluates the performance of several publicly-available PLMs in AMP classification utilizing transfer learning techniques and benchmarking them against state-of-the-art neural-based classifiers. Our key findings include: (a) Model scale is crucial, with classification performance consistently improving with increasing model size; (b) State-of-the-art results are achieved with minimal effort utilizing PLM embedding representations alongside shallow classifiers; and (c) Classification performance is further enhanced through efficient fine-tuning of PLMs&rsquo; parameters. Code showcasing our pipelines is available at https://github.com/EliasGeorg/PLM_AMP_Classification.


---
# Computational and Machine Learning Approaches for Optimizing Anti-CD3&epsilon; Nanobody: Humanization and Characterization for Enhanced Therapeutic Efficacy

## 优化Anti-CD3和 ε 的计算和机器学习方法; 纳米抗体: 增强治疗效果的人源化和表征

Link: https://www.researchsquare.com/article/rs-5769566/latest

This study presents a comprehensive machine-learning-driven approach for the in silico humanization and characterization of anti-CD3&epsilon; nanobodies. Nanobodies, single-domain antibodies derived from camelids, hold immense therapeutic potential due to their small size, high solubility, and exceptional stability. However, their camelid origin necessitates humanization to minimize immunogenicity in therapeutic applications. Using state-of-the-art computational tools such as NanoNet, RoseTTAFold, and PyDock, we modeled and analyzed both wild type and humanized anti-CD3&epsilon; nanobody variants. Key metrics, including structural stability, binding efficiency, thermal stability, and aggregation propensity, were evaluated. Humanization achieved enhanced humanness scores, increased thermal stability, and retained strong binding interactions with CD3&epsilon; while preserving the nanobody&amp;rsquo;s structural integrity. Molecular dynamics simulations confirmed minimal deviations in structural flexibility and binding-site compatibility post-humanization. These findings support the efficacy of computational methods in optimizing nanobody therapeutics for clinical applications, paving the way for advanced immunotherapy strategies targeting immune-related disorders. The results demonstrate that the humanized anti-CD3&epsilon; nanobody exhibits enhanced thermal stability, reduced aggregation propensity, improved humanness scores, and comparable binding efficiency to the wild type nanobody, making it a promising therapeutic candidate.


---
# An X-linked long non-coding RNA, PTCHD1-AS, regulates autistic behaviors in humans and in mice

## PTCHD1-AS，X-连接的长链非编码RNA调节人类和小鼠的自闭症行为

Link: https://www.researchsquare.com/article/rs-5619348/latest

There are ~100 genes or copy number variants (CNVs) used in genetic testing for Autism Spectrum Disorder (ASD, or autism). These genes are protein-coding, and the associated phenotypes often extend beyond socio-behavioral traits seen in autism including cognitive/medical complexities, epilepsy, and ADHD. Here, we characterize 27 males with ASD through whole genome sequencing (WGS), delineating X-chromosome microdeletions that implicate the long non-coding RNA (lncRNA) PTCHD1-AS as an ASD-susceptibility gene (OR=2.56, p=0.01). Two Ptchd1-as knockout (KO) murine models, created by removing the evolutionarily conserved exon-3, show ASD-like features in males, increasing repetitive behaviors and impairing typical social behavior and communication without overt cognitive comorbidities or ADHD-like behaviors. Hippocampus-dependent synaptic function, complex learning, and locomotor activity are unaffected in KO mice. Native nuclear-enriched mouse Ptchd1-as showed sustained expression from post-natal day-7 onward in the dorsal striatum, a predominantly GABAergic brain region implicated in ASD. Multi-omics revealed transcriptomic alterations in striatal oligodendrocyte, astrocyte and neurons impacting myelination and plasticity pathways. Disrupting Ptchd1-as led to reductions in conventional Protein Kinase-C, altered Src and GSK3&alpha;/&beta; phosphorylation, and an enhancement of synaptic plasticity (long-term potentiation and long-term depression). Together, these findings implicate striatal molecular and circuit level dysregulation via Ptchd1-as in ASD etiology.


---
# Volcano Monitoring System for Long-Term Eruption Forecasting Using Multiple Data Sources

## 使用多数据源进行长期喷发预报的火山监测系统

Link: https://www.researchsquare.com/article/rs-5787009/latest

Accurately forecasting volcanic eruptions is challenging due to the complexity of precursory signals. Here, we develop a machine learning-based long-term eruption forecasting model for Mount Aso, Japan, by integrating multiple observational datasets&mdash;seismic tremors, magnetic field, crater wall temperature, thermal pool temperature and volume, tilt, and volcanic gas amount&mdash;at the characteristic temporal scales of the underlying physical phenomena. The temporal scales are aligned with the intrinsic dynamics captured by each dataset to enhance the model's predictive capability. We construct a theoretical framework to quantify the predictive performance improvement. Our proposed model significantly improves predictive performance, increasing the Matthews correlation coefficient by 0.65 compared to the conventional seismic-tremor-based model, and achieving a precision of &gt;70% in predicting volcanic eruptions. Our findings demonstrate that an ensemble of multiple data sources over optimized temporal scales, underpinned by a theoretical ensemble framework, enables high-precision, interpretable eruption forecasts months in advance and makes effective disaster mitigation planning possible.


---
# A Fault Diagnosis Method for Analog Circuits Based on VMD-CFOA-ELM

## 基于vmd-cfoa-elm的模拟电路故障诊断方法

Link: https://www.researchsquare.com/article/rs-5769828/latest

Fault feature extraction of analog circuits is the main factor affecting their fault diagnosis accuracy. Therefore, in order to increase the accuracy of analog circuit fault diagnosis, this paper proposes a fault diagnosis method for analog circuit based on VMD-CFOA-ELM and DGCCA(Deep Generalized Canonical Correlation Analysis,DGCCA). The method firstly performs VMD(Variational Mode Decomposition,VMD) on the fault time-domain response signal to obtain all the IMF (Intrinsic Mode Function,IMF) components and calculates the CMSE(Composite Multi-Scale Entropy,CMSE) of each IMF component, treating this as a separate subset of fault features. Next, it extracts the time-frequency domain characteristic features of the fault response signal and uses the DGCCA algorithm for supervised feature fusion extraction, constructing a shared representation feature matrix G, which is spliced with the subset of fault features as the input features of the classifier. Finally, the CFOA(Catch Fish Optimization Algorithm, CFOA)algorithm is relied upon to optimize the ELM (Extreme Learning Machine,ELM) classifier to have good classification accuracy to diagnose the type of faults in the test circuits. Fault simulation diagnostics on a Sallen-Key bandpass filter circuit show that, compared to methods such as KPCA-ELM, KSLPP-ELM, EEMD multi-scale entropy-LSSVM, and WP-ICA energy spectrum-SVM, the proposed method achieves the highest accuracy, reaching 99.20%. Additionally, this method is portable and applicable to fault diagnosis of other analog circuits.

