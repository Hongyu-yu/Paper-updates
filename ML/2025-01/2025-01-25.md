# Machine Learning Predicts Liquid–Gas Transition

## 机器学习预测液-气转换

Link: http://link.aps.org/doi/10.1103/Physics.18.17

**Authors:** Mark Buchanan

Author(s): Mark Buchanan<br /><p>Conventional theory has trouble predicting the conditions that will cause a liquid to boil, but a neural-network-based approach performs better.</p><img height="" src="https://physics.aps.org/assets/10.1103/Physics.18.17/figure/1/thumb" width="200" /><br />[Physics 18, 17] Published Fri Jan 24, 2025


---
# A dual-domain compute-in-memory system for general neural network inference

## 用于通用神经网络推理的双域内存计算系统

Link: https://www.nature.com/articles/s41928-024-01315-9

**Authors:** Huaqiang Wu

<p>Nature Electronics, Published online: 24 January 2025; <a href="https://www.nature.com/articles/s41928-024-01315-9">doi:10.1038/s41928-024-01315-9</a></p>An analogue–digital unified compute-in-memory architecture can offer native support for floating-point-based complex regression tasks, providing improved accuracy and energy efficiency compared with pure analogue compute-in-memory systems.


---
# Accelerating Discovery of Solid-State Thin-Film Metal Dealloying for 3D Nanoarchitecture Materials Design through Laser Thermal Gradient Treatment

## 通过激光热梯度处理加速发现用于3D纳米结构材料设计的固态薄膜金属脱合金

Link: https://arxiv.org/abs/2501.13245

**Authors:** Cheng-Chu Chung, Ruipeng Li, Gabriel M. Veith, Honghu Zhang, Fernando Camino, Ming Lu, Nikhil Tiwale, Sheng Zhang, Kevin Yager, Yu-chen Karen Chen-Wiegart

arXiv:2501.13245v1 Announce Type: new 
Abstract: Thin-film solid-state metal dealloying (thin-film SSMD) is a promising method for fabricating nanostructures with controlled morphology and efficiency, offering advantages over conventional bulk materials processing methods for integration into practical applications. Although machine learning (ML) has facilitated the design of dealloying systems, the selection of key thermal treatment parameters for nanostructure formation remains largely unknown and dependent on experimental trial and error. To overcome this challenge, a workflow enabling high-throughput characterization of thermal treatment parameters while probing local nanostructures of thin-film samples is needed. In this work, a laser-based thermal treatment is demonstrated to create temperature gradients on single thin-film samples of Nb-Al/Sc and Nb-Al/Cu. This continuous thermal space enables observation of dealloying transitions and the resulting nanostructures of interest. Through synchrotron X-ray multimodal and high-throughput characterization, critical transitions and nanostructures can be rapidly captured and subsequently verified using electron microscopy. The key temperatures driving chemical reactions and morphological evolutions are clearly identified within this framework. While the oxidation process may contribute to nanostructure formation during thin-film treatment, the dealloying process at the dealloying front involves interactions solely between the dealloying elements, highlighting the availability and viability of the selected systems. This approach enables efficient exploration of the dealloying process and validation of ML predictions, thereby accelerating the discovery of thin-film SSMD systems with targeted nanostructures.


---
# Stress Predictions in Polycrystal Plasticity using Graph Neural Networks with Subgraph Training

## 使用具有子图训练的图神经网络进行多晶塑性应力预测

Link: https://arxiv.org/abs/2409.05169

**Authors:** Hanfeng Zhai

arXiv:2409.05169v4 Announce Type: replace 
Abstract: Numerical modeling of polycrystal plasticity is computationally intensive. We employ Graph Neural Networks (GNN) to predict stresses on complex geometries for polycrystal plasticity from Finite Element Method (FEM) simulations. We present a novel message-passing GNN that encodes nodal strain and edge distances between FEM mesh cells, and aggregates to obtain embeddings and combines the decoded embeddings with the nodal strains to predict stress tensors on graph nodes. The GNN is trained on subgraphs generated from FEM mesh graphs, in which the mesh cells are converted to nodes and edges are created between adjacent cells. We apply the trained GNN to periodic polycrystals with complex geometries and learn the strain-stress maps based on crystal plasticity theory. The GNN is accurately trained on FEM graphs, in which the $R^2$ for both training and testing sets are larger than 0.99. The proposed GNN approach speeds up more than 150 times compared with FEM on stress predictions. We also apply the trained GNN to unseen simulations for validations and the GNN generalizes well with an overall $R^2$ of 0.992. The GNN accurately predicts the von Mises stress on polycrystals. The proposed model does not overfit and generalizes well beyond the training data, as the error distributions demonstrate. This work outlooks surrogating crystal plasticity simulations using graph data.


---
# Two-dimensional ferroelectric crystal with temperature-invariant ultralow thermal conductivity

## 具有温度不变的超低热导率的二维铁电晶体

Link: https://arxiv.org/abs/2501.09990

**Authors:** Wenjie Zhou, Shi Liu

arXiv:2501.09990v2 Announce Type: replace 
Abstract: We report the discovery of temperature-invariant ultralow thermal conductivity ($\kappa$) in monolayer $\beta'$-In$_2$Se$_3$, a two-dimensional ferroelectric crystal with in-plane polarization. Using a combination of generalized Wigner transport equation theory and machine-learning-assisted molecular dynamics simulations, we reveal that the balance between particle-like phonon propagating and wave-like tunneling transport mechanisms results in a propagating-tunneling-invariant (PTI) ultralow thermal conductivity of approximately 0.6 W/mK (comparable to that of glass) over a broad temperature range ($150<800$~K). This behavior stems from intrinsic strong lattice anharmonicity driven by ferroelectric dipolar fluctuations, eliminating the need for extrinsic structural modifications. In contrast, the $\alpha$-In$_2$Se$_3$~monolayer, which shares the same stoichiometry, exhibits a conventional temperature-dependent thermal conductivity, $\kappa (T) \propto T^{-1}$, typical of simple crystals. Furthermore, we demonstrate that the anharmonicity in $\beta'$-In$_2$Se$_3$~can be precisely modulated by an external electric field, enabling on-demand control of thermal transport properties, including modifying the temperature scaling behavior of heat conductivity and achieving a large thermal switching ratio of $\approx$2.5. These findings provide fundamental insights into the interplay between field-tunable lattice anharmonicity, phonon dynamics, and thermal transport mechanisms.


---
# Physics-Informed Neural Networks for microflows: Rarefied Gas Dynamics in Cylinder Arrays

## 用于微流的物理通知神经网络: 气缸阵列中的稀有气体动力学

Link: https://arxiv.org/abs/2501.13108

**Authors:** Jean-Michel Tucny, Marco Lauricella, Mihir Durve, Gianmarco Guglielmo, Andrea Montessori, Sauro Succi

arXiv:2501.13108v1 Announce Type: new 
Abstract: Accurate prediction of rarefied gas dynamics is crucial for optimizing flows through microelectromechanical systems, air filtration devices, and shale gas extraction. Traditional methods, such as discrete velocity and direct simulation Monte Carlo (DSMC), demand intensive memory and computation, especially for microflows in non-convex domains. Recently, physics-informed neural networks emerged as a meshless and adaptable alternative for solving non-linear partial differential equations. We trained a PINN using a limited number of DSMC-generated rarefied gas microflows in the transition regime with Knudsen number from 0.1 to 3, incorporating continuity and Cauchy momentum exchange equations in the loss function. The PINN achieved under 2 percent error on these residuals and effectively filtered DSMC intrinsic statistical noise. Predictions remained strong for a tested flow field with Kn equal to 0.7, and showed limited extrapolation performance on a flow field with Kn equal to 5 with a local overshoot of about 20 percent, while maintaining physical consistency. Notably, each DSMC field required about 20 hours on 4 graphics processing units (GPU), while the PINN training took less than 2 hours on one GPU, with evaluations under 2 seconds.


---
# Predicting Turbulence Structure In Street-Canyon Flows using Deep Generative Modeling

## 使用深度生成模型预测街道峡谷流中的湍流结构

Link: https://arxiv.org/abs/2501.13415

**Authors:** Tomek Jaroslawski, Aakash Patil, Beverley McKeon

arXiv:2501.13415v1 Announce Type: new 
Abstract: The high dimensionality and complex dynamics of turbulent flows in urban street canyons present significant challenges for wind and environmental engineering, particularly in addressing air quality, pollutant dispersion, and extreme wind events. This study introduces a deep learning framework to predict spatio-temporal flow behavior in street canyons with varying geometric configurations and upstream roughness conditions. A convolutional encoder-decoder transformer model, trained on particle image velocimetry (PIV) data from wind tunnel experiments, is employed with autoregressive training to predict flow characteristics. The training dataset contains diverse flow regimes, with a focus on the wall-parallel plane near the canyon roof, a critical region for pollutant exchange between the outer flow and the canyon interior. The model accurately reproduces key flow features, including mean turbulent statistics, two-point correlations, quadrant analysis, and dominant flow structures, while demonstrating strong agreement with experimental data in capturing the temporal evolution of flow dynamics. These findings demonstrate the potential of deep learning models to enhance predictive capabilities for urban canyon flows, offering a pathway toward improved urban design, sustainable environmental management, and more effective pollutant dispersion modeling.


---
# Solving continuum and rarefied flows using differentiable programming

## 使用可微编程解决连续体和稀薄流

Link: https://arxiv.org/abs/2501.13478

**Authors:** Tianbai Xiao

arXiv:2501.13478v1 Announce Type: new 
Abstract: Accurate and efficient prediction of multi-scale flows remains a formidable challenge. Constructing theoretical models and numerical methods often involves the design and optimization of parameters. While gradient descent methods have been mainly manifested to shine in the wave of deep learning, composable automatic differentiation can advance scientific computing where the application of classical adjoint methods alone is infeasible or cumbersome. Differentiable programming provides a novel paradigm that unifies data structures and control flows and facilitates gradient-based optimization of parameters in a computer program. This paper addresses the notion and implementation of the first solution algorithm for multi-scale flow physics across continuum and rarefied regimes based on differentiable programming. The fully differentiable simulator provides a unified framework for the convergence of computational fluid dynamics and machine learning, i.e., scientific machine learning. Specifically, parameterized mechanical-neural flow models and numerical methods can be constructed for forward physical processes, while the parameters can be trained on the fly with the help of the gradients that are taken through the backward passes of the whole simulation program, a.k.a., end-to-end optimization. As a result, versatile data-driven modeling and simulation can be achieved for physics discovery, surrogate modeling, and simulation acceleration. The fundamentals and implementation of the solution algorithm are demonstrated in detail. Numerical experiments, including forward and inverse problems for hydrodynamic and kinetic equations, are presented to demonstrate the performance of the numerical method. The open-source codes to reproduce the numerical results are available under the MIT license.


---
# Scalable dataset acquisition for data-driven lensless imaging

## 用于数据驱动无透镜成像的可扩展数据集采集

Link: https://arxiv.org/abs/2501.13334

**Authors:** Clara S. Hung, Leyla A. Kabuli, Vasilisa Ponomarenko, Laura Waller

arXiv:2501.13334v1 Announce Type: cross 
Abstract: Data-driven developments in lensless imaging, such as machine learning-based reconstruction algorithms, require large datasets. In this work, we introduce a data acquisition pipeline that can capture from multiple lensless imaging systems in parallel, under the same imaging conditions, and paired with computational ground truth registration. We provide an open-access 25,000 image dataset with two lensless imagers, a reproducible hardware setup, and open-source camera synchronization code. Experimental datasets from our system can enable data-driven developments in lensless imaging, such as machine learning-based reconstruction algorithms and end-to-end system design.


---
# DoMINO: A Decomposable Multi-scale Iterative Neural Operator for Modeling Large Scale Engineering Simulations

## DoMINO: 一种用于大规模工程仿真建模的可分解多尺度迭代神经算子

Link: https://arxiv.org/abs/2501.13350

**Authors:** Rishikesh Ranade, Mohammad Amin Nabian, Kaustubh Tangsali, Alexey Kamenev, Oliver Hennigh, Ram Cherukuri, Sanjay Choudhry

arXiv:2501.13350v1 Announce Type: cross 
Abstract: Numerical simulations play a critical role in design and development of engineering products and processes. Traditional computational methods, such as CFD, can provide accurate predictions but are computationally expensive, particularly for complex geometries. Several machine learning (ML) models have been proposed in the literature to significantly reduce computation time while maintaining acceptable accuracy. However, ML models often face limitations in terms of accuracy and scalability and depend on significant mesh downsampling, which can negatively affect prediction accuracy and generalization. In this work, we propose a novel ML model architecture, DoMINO (Decomposable Multi-scale Iterative Neural Operator) developed in NVIDIA Modulus to address the various challenges of machine learning based surrogate modeling of engineering simulations. DoMINO is a point cloudbased ML model that uses local geometric information to predict flow fields on discrete points. The DoMINO model is validated for the automotive aerodynamics use case using the DrivAerML dataset. Through our experiments we demonstrate the scalability, performance, accuracy and generalization of our model to both in-distribution and out-of-distribution testing samples. Moreover, the results are analyzed using a range of engineering specific metrics important for validating numerical simulations.


---
# Anomaly Detection for Automated Data Quality Monitoring in the CMS Detector

## 用于CMS检测器中自动数据质量监控的异常检测

Link: https://arxiv.org/abs/2501.13789

**Authors:** Andrew Brinkerhoff, Chosila Sutantawibul, Robert White, Caio Daumann, Chad Freer, Indara Suarez, Samuel May, Vivan Nguyen, Jonathan Guiang, Bennett Marsh, Darin Acosta, Alex Aubuchon, Emanuela Barberis, Aaron Bundock, Evan Collins, Preston Epps, Johannes Erdmann, Henning Flaecher, Junshen Huang, Ryan Nie, Sudarshan Paramesvaran, John Rotter, Kaitlin Salyer, Siddhesh Sawant, Tanvi Sheokand, Darien Wood

arXiv:2501.13789v1 Announce Type: cross 
Abstract: Successful operation of large particle detectors like the Compact Muon Solenoid (CMS) at the CERN Large Hadron Collider requires rapid, in-depth assessment of data quality. We introduce the ``AutoDQM'' system for Automated Data Quality Monitoring using advanced statistical techniques and unsupervised machine learning. Anomaly detection algorithms based on the beta-binomial probability function, principal component analysis, and neural network autoencoder image evaluation are tested on the full set of proton-proton collision data collected by CMS in 2022. AutoDQM identifies anomalous ``bad'' data affected by significant detector malfunction at a rate 4 -- 6 times higher than ``good'' data, demonstrating its effectiveness as a general data quality monitoring tool.


---
# Quantitative Assessment of PINN Inference on Experimental Data for Gravity Currents Flows

## 对重力流实验数据的PINN推断的定量评估

Link: https://arxiv.org/abs/2307.14794

**Authors:** Micka\"el Delcey, Yoann Cheny, Jean Schneider, Simon Becker, S\'ebastien Kiesgen De Richter

arXiv:2307.14794v3 Announce Type: replace 
Abstract: In this paper, we apply Physics Informed Neural Networks (PINNs) to infer velocity and pressure field from Light Attenuation Technique (LAT) measurements for gravity current induced by lock-exchange. In a PINN model, physical laws are embedded in the loss function of a neural network, such that the model fits the training data but is also constrained to reduce the residuals of the governing equations. PINNs are able to solve ill-posed inverse problems training on sparse and noisy data, and therefore can be applied to real engineering applications. The noise robustness of PINNs and the model parameters are investigated in a 2 dimensions toy case on a lock-exchange configuration, employing synthetic data. Then we train a PINN with experimental LAT measurements and quantitatively compare the velocity fields inferred to Particle Image Velocimetry (PIV) measurements performed simultaneously on the same experiment.The results state that accurate and useful quantities can be derived from a PINN model trained on real experimental data which is encouraging for a better description of gravity currents.


---
# Validating Deep Learning Weather Forecast Models on Recent High-Impact Extreme Events

## 在近期高影响极端事件中验证深度学习天气预报模型

Link: https://arxiv.org/abs/2404.17652

**Authors:** Olivier C. Pasche, Jonathan Wider, Zhongwei Zhang, Jakob Zscheischler, Sebastian Engelke

arXiv:2404.17652v2 Announce Type: replace 
Abstract: The forecast accuracy of machine learning (ML) weather prediction models is improving rapidly, leading many to speak of a "second revolution in weather forecasting". With numerous methods being developed and limited physical guarantees offered by ML models, there is a critical need for a comprehensive evaluation of these emerging techniques. While this need has been partly fulfilled by benchmark datasets, they provide little information on rare and impactful extreme events or on compound impact metrics, for which model accuracy might degrade due to misrepresented dependencies between variables. To address these issues, we compare ML weather prediction models (GraphCast, PanguWeather, and FourCastNet) and ECMWF's high-resolution forecast system (HRES) in three case studies: the 2021 Pacific Northwest heatwave, the 2023 South Asian humid heatwave, and the North American winter storm in 2021. We find that ML weather prediction models locally achieve similar accuracy to HRES on the record-shattering Pacific Northwest heatwave but underperform when aggregated over space and time. However, they forecast the compound winter storm substantially better. We also highlight structural differences in how the errors of HRES and the ML models build up to that event. The ML forecasts lack important variables for a detailed assessment of the health risks of the 2023 humid heatwave. Using a possible substitute variable, prediction errors show spatial patterns with the highest danger levels over Bangladesh being underestimated by the ML models. Generally, case-study-driven, impact-centric evaluation can complement existing research, increase public trust, and aid in developing reliable ML weather prediction models.


---
# AI Discovering a Coordinate System of Chemical Elements: Dual Representation by Variational Autoencoders

## AI发现化学元素的坐标系: 变分自动编码器的对偶表示

Link: https://arxiv.org/abs/2011.12090

**Authors:** Alex Glushkovsky

arXiv:2011.12090v5 Announce Type: replace-cross 
Abstract: The periodic table is a fundamental representation of chemical elements that plays essential theoretical and practical roles. The research article discusses the experiences of unsupervised training of neural networks to represent elements on the 2D latent space based on their electron configurations. To emphasize chemical properties of the elements, the original data of electron configurations has been realigned towards valence orbitals. Recognizing seven shells and four subshells, the input data has been arranged as 7x4 images. Latent space representation has been performed using a convolutional beta variational autoencoder (beta-VAE). Despite discrete and sparse input data, the beta-VAE disentangles elements of different periods, blocks, groups, and types. The unsupervised representation of elements on the latent space reveals pairwise symmetries of periods and elements related to the invariance of quantum numbers of corresponding elements. In addition, it isolates outliers that turned out to be known cases of Madelung's rule violations for lanthanide and actinide elements. Considering the generative capabilities of beta-VAE, the supervised machine learning has been set to find out if there are insightful patterns distinguishing electron configurations between real elements and decoded artificial ones. Also, the article addresses the capability of dual representation by autoencoders. Conventionally, autoencoders represent observations of input data on the latent space. By transposing and duplicating original input data, it is possible to represent variables on the latent space which can lead to the discovery of meaningful patterns among input variables. Applying that unsupervised learning for transposed data of electron configurations, the order of input variables that has been arranged by the encoder on the latent space has turned out to exactly match the sequence of Madelung's rule.


---
# MeshMask: Physics-Based Simulations with Masked Graph Neural Networks

## MeshMask: 使用掩蔽图神经网络进行基于物理的仿真

Link: https://arxiv.org/abs/2501.08738

**Authors:** Paul Garnier, Vincent Lannelongue, Jonathan Viquerat, Elie Hachem

arXiv:2501.08738v2 Announce Type: replace-cross 
Abstract: We introduce a novel masked pre-training technique for graph neural networks (GNNs) applied to computational fluid dynamics (CFD) problems. By randomly masking up to 40\% of input mesh nodes during pre-training, we force the model to learn robust representations of complex fluid dynamics. We pair this masking strategy with an asymmetric encoder-decoder architecture and gated multi-layer perceptrons to further enhance performance. The proposed method achieves state-of-the-art results on seven CFD datasets, including a new challenging dataset of 3D intracranial aneurysm simulations with over 250,000 nodes per mesh. Moreover, it significantly improves model performance and training efficiency across such diverse range of fluid simulation tasks. We demonstrate improvements of up to 60\% in long-term prediction accuracy compared to previous best models, while maintaining similar computational costs. Notably, our approach enables effective pre-training on multiple datasets simultaneously, significantly reducing the time and data required to achieve high performance on new tasks. Through extensive ablation studies, we provide insights into the optimal masking ratio, architectural choices, and training strategies.


---
# Unified 3D MRI Representations via Sequence-Invariant Contrastive Learning

## 基于序列不变对比学习的统一3D MRI表示

Link: https://arxiv.org/abs/2501.12057

**Authors:** Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner

arXiv:2501.12057v2 Announce Type: replace-cross 
Abstract: Self-supervised deep learning has accelerated 2D natural image analysis but remains difficult to translate into 3D MRI, where data are scarce and pre-trained 2D backbones cannot capture volumetric context. We present a sequence-invariant self-supervised framework leveraging quantitative MRI (qMRI). By simulating multiple MRI contrasts from a single 3D qMRI scan and enforcing consistent representations across these contrasts, we learn anatomy-centric rather than sequence-specific features. This yields a robust 3D encoder that performs strongly across varied tasks and protocols. Experiments on healthy brain segmentation (IXI), stroke lesion segmentation (ARC), and MRI denoising show significant gains over baseline SSL approaches, especially in low-data settings (up to +8.3% Dice, +4.2 dB PSNR). Our model also generalises effectively to unseen sites, demonstrating potential for more scalable and clinically reliable volumetric analysis. All code and trained models are publicly available.


---
# Artificial Intelligence Driven Prediction of Aqueous Solubility of Drug Molecules Using Molecular Descriptors and Optimized ANN Architectures

## 使用分子描述符和优化的ANN结构对药物分子的水溶性进行人工智能驱动的预测

Link: https://dx.doi.org/10.26434/chemrxiv-2025-1pnxw?rft_dat=source%3Ddrss

**Authors:** Yulianna, Velina

Accurate prediction of aqueous solubility (logS) is a cornerstone of drug development, influencing bioavailability, pharmacokinetics, and therapeutic efficacy. Traditional models, such as ESOL, often exhibit limited accuracy across diverse chemical datasets, whereas Artificial Neural Networks (ANNs) offer a robust alternative by capturing complex non-linear relationships in molecular descriptors derived from SMILES representations. This study evaluates the performance of various ANN architectures against baseline models, including Random Forest (RF) and Linear Regression (LR), demonstrating the superior accuracy of ANNs, which achieved the lowest mean error and most consistent error distribution. Nonetheless, model performance was influenced by the logS range and architectural complexity, with deeper networks prone to overfitting and simpler architectures susceptible to underfitting. These findings position ANNs as powerful tools for solubility prediction, underscoring the importance of balanced model design and expanded datasets to enhance generalization. AI-driven approaches offer transformative potential to accelerate drug discovery, reduce costs, and optimize therapeutic outcomes.


---
# Wiggle150: Benchmarking Density Functionals And Neural Network Potentials On Highly Strained Conformers

## Wiggle150: 在高度应变的构象体上对密度函数和神经网络潜力进行基准测试

Link: https://dx.doi.org/10.26434/chemrxiv-2025-4mbsk-v2?rft_dat=source%3Ddrss

**Authors:** Wyatt, Simmons

Accurate benchmarks are key to assessing the accuracy and robustness of computational methods, yet most available benchmark sets focus on equilibrium geometries, limiting their utility for applications involving non-equilibrium structures such as ab initio molecular dynamics and automated reaction-path exploration. To address this gap, we introduce Wiggle150, a benchmark comprising 150 highly strained conformations of adenosine, benzylpenicillin, and efavirenz. These geometries—generated via metadynamics and scored using DLPNO-CCSD(T)/CBS reference energies—exhibit substantially larger deviations in bond lengths, angles, dihedrals, and relative energies than other conformer benchmarks. We evaluate a diverse array of computational methods, including density-functional theory, composite quantum chemical methods, semiempirical models, neural network potentials, and force fields, on predicting relative energies for this challenging benchmark set. The results highlight multiple methods along the speed–accuracy Pareto frontier and identify AIMNet2 as particularly robust among the NNPs surveyed. We anticipate that Wiggle150 will be used to validate computational protocols involving non-equilibrium systems and guide the development of new density functionals and neural network potentials.


---
# The Nature of Chemical Bonds in the Age of Artificial Intelligence: Revisiting Electronegativity of Organic
 Molecules

## 人工智能时代化学键的性质: 重新审视有机物的电负性
分子

Link: https://dx.doi.org/10.26434/chemrxiv-2025-02krr-v2?rft_dat=source%3Ddrss

**Authors:** Da Bean, Han

Electronegativity can be considered a data-driven concept that is widely used since Pauling proposed
 this property. However, updating the electronegativity based on the vast amount of high quality
 experimental and computational data has been overlooked. Thus, advances in artificial intelligence
 (AI), with its ability to manage large datasets and identify underlying patterns, necessitate reconsid
ering data-driven concepts such as electronegativity. In this work, we present a data-driven method
 to generate more informative multidimensional electronegativity of organic molecules using graph
 neural networks. Focusing on two-dimensional electronegativity, we were able to do a more detailed
 classification of the atoms and their covalent bonds. By replacing the conventional electronegativity
 with the newly proposed one, we demonstrated the performance improvement in molecular machine
 learning tasks. We believe that our findings will be useful in understanding of electronegativity and
 chemical bonds by judiciously applying AI-driven methods to chemical studies.


---
# Data-driven massive reaction networks reveal new pathways underlying catalytic CO2 hydrogenation

## 数据驱动的大规模反应网络揭示了催化CO2加氢的新途径

Link: https://dx.doi.org/10.26434/chemrxiv-2025-pnh6l?rft_dat=source%3Ddrss

**Authors:** Amol, Amrute

Heterogeneous catalytic pathways for clean energy conversion involve thousands of elementary steps, but most quantum-mechanical models involve only a few dozen reactions. We combine extensive density functional theory (DFT) calculations, machine learning (ML) for activation barrier prediction, and human intelligence-inspired reaction enumeration and elementary reaction identification. This enables automated kinetic modeling of CO2 hydrogenation on copper, a key process to produce fuels and chemicals. We construct the largest dataset of 152 elementary CO2 reduction reactions and experimentally determine CO2 conversion, finding that even large networks with 100+ reactions are insufficient. In contrast, our approach reveals 9389 elementary reactions, reducing human bias in the reaction pathway. We unravel 40-fold higher CO2 conversion rates, following experimental trends of methanol and CO production. We establish the crucial role of intermolecular hydrogen transfer and hydrogenation by molecular hydrogen, a surprising ML-enabled discovery validated post-facto. The proposed strategy to comprehensively model complex catalytic mechanisms will significantly advance catalysis research and carbon conversion processes.


---
# Efficient Black-Box Prediction of Hydrogen-Bond-Acceptor Strength

## 氢键受体强度的有效黑盒预测

Link: https://dx.doi.org/10.26434/chemrxiv-2025-kv6d6?rft_dat=source%3Ddrss

**Authors:** Corin, Wagen

Hydrogen-bond-acceptor strength is a critical determinant of physicochemical properties and binding affinity in drug discovery, but computationally predicting the strength of different hydrogen-bond acceptors remains challenging and inaccessible to non-experts. Here, we report a robust black-box workflow for predicting site-specific pKBHX values in organic molecules with minimal computational cost. Our approach begins with rapid conformer generation and optimization with neural network potentials, followed by a single density-functional-theory calculation of the electrostatic potential. We then calibrate these results against an extensive reference set of experimentally determined pKBHX data, achieving sub-0.2 pKBHX-unit accuracy. We illustrate the power of this tool in multiple published drug discovery programs, highlighting how per-site pKBHX tuning can improve bioavailability, minimize efflux, and enhance selectivity


---
# Predicting High Confidence ctDNA Somatic Variants with Ensemble Machine Learning Models

## 用集成机器学习模型预测高置信度ctDNA体细胞变异

Link: https://www.researchsquare.com/article/rs-5735554/latest

Circulating tumour DNA (ctDNA) is a minimally invasive cancer biomarker that can be used to inform treatment of cancer patients. The utility of ctDNA as a cancer biomarker depends on the ability to accurately detect somatic variants associated with cancer. Accurate somatic variant detection in circulating cell free DNA (cfDNA) NGS data requires filtering strategies to remove germline variants, and NGS artifacts. Rule-based variant filtering methods either remove a substantial number of true positive ctDNA variants along with false variant calls or retain an implausibly large number of total variants. Machine Learning (ML) enables identification of complex patterns which may improve ability to distinguish between real somatic ctDNA variants and false positive calls. We built two Random Forest (RF) models for predicting high confidence somatic ctDNA variants in low and high depth cfDNA NGS data. Low depth models were fitted and evaluated on whole exome sequencing (WES) cfDNA data at depths of approximately 10X while the high depth data was sequenced at approximately 500X. Both models utilise a set of 15 features from variants detected by bcftools, FreeBayes, LoFreq and Mutect2. High confidence ground truth sets were obtained from matched tissue biopsy samples. We benchmarked our models against rule-based filtering with a set of hard, medium, and soft thresholds. Precision-recall curves showed the high depth model outperformed rule-based filtering at all thresholds in validation data (PR-AUC 0.71). Partial dependence plots showed membership in the COSMIC database, absence from the dbSNP common variants database, and increasing read depth increased mean probability of high confidence somatic variant prediction in both models. Our results demonstrate the utility of supervised ML models for filtering variants in cfDNA data.


---
# Knowledge, Attitudes and Practices Towards Human Papillomavirus (HPV) and HPV Vaccination among Students at Higher Institutions of Learning in Buea, South West Region of Cameroon: A Cross-Sectional Study

## 喀麦隆西南地区Buea高等学府学生对人乳头瘤病毒 (HPV) 和HPV疫苗接种的知识，态度和实践: 横断面研究

Link: https://www.researchsquare.com/article/rs-5833643/latest

Background Human papillomavirus (HPV) is the most common viral sexually transmitted infection (STI) of the reproductive tract, causing a range of diseases in men and women. HPV causes almost half a million cases of cervical cancer and 250,000 related deaths, 80% of which occur in developing countries. This study aimed to assess the knowledge, attitudes and practices towards HPV and HPV vaccination among students at higher institutions of learning in Buea.Methods A cross-sectional study design was used, where participants were selected from nine higher institutions of learning in Buea by means of random sampling. A self-administered structured questionnaire was used to collect information from 414 participants. A descriptive summary of the data was presented via frequency tables, percentages and graphs via Microsoft Excel. The descriptive statistics were mostly used to describe the outcome variables as percentages. The logistic regression model was used to test for associations between knowledge, attitudes and practices and the sociodemographic characteristics of the participants, and Pearson&amp;rsquo;s chi square test was used to examine the associations between the dependent variables and sex. A P-value&amp;thinsp;&amp;lt;&amp;thinsp;0.05 was considered statistically significant. The data were analysed via Microsoft Excel 2013 and the statistical software R studio version 4.2.1.Results Among the respondents, 56% (231/414) were females and 44% (183/414) were males, of whom only 1% (4/414) had good knowledge of HPV and its vaccination, and 11.8% (49/414) and 87.2% (361/414) had moderate and poor knowledge, respectively. With respect to attitudes towards HPV and HPV vaccination, 37% (153/414) and 63% (261/414) demonstrated negative and positive attitudes, respectively, whereas 86.2% (357/417) and 13.8% (57/414) demonstrated adequate and inadequate practices, respectively. There was a statistically significant association between knowledge and sex (P&amp;thinsp;=&amp;thinsp;0.032, &chi;2&amp;thinsp;=&amp;thinsp;6.857) and between attitudes and sex (P&amp;thinsp;=&amp;thinsp;0.007, &chi; 2&amp;thinsp;=&amp;thinsp;6.857). However, there was not a statistically significant association between practice and sex (P&amp;thinsp;=&amp;thinsp;0.438, &chi;2&amp;thinsp;=&amp;thinsp;0.438).Conclusions Generally, this study revealed that students at higher institutions of learning in Buea do not have sufficient knowledge about HPV and HPV vaccination. However, this study highlights the need for more health campaigns to increase awareness of the disease in schools.


---
# An unsupervised learning model that integrates clinical and MRI radiomics features outperforms existing models in predicting the 5-year progression-free survival of prostate cancer patients after prostatectomy: a multicenter study

## 整合临床和MRI影像组学特征的无监督学习模型在预测前列腺癌患者前列腺切除术后5年无进展生存期方面优于现有模型: 一项多中心研究

Link: https://www.researchsquare.com/article/rs-5864691/latest

Background Prostate cancer (PCa) is the second most common male cancer. Despite undergoing radical prostatectomy (RP), 20&amp;ndash;30% of patients experience recurrence within 5 years. Unsupervised learning method based on radiomics features has proved its efficiency for predicting recurrence in patients with breast and lung cancer. In this study, we sought to identify subgroups of PCa patients after RP using an unsupervised clustering method based on clinical and MRI radiomics features, and further evaluate the prognostic value in predicting 5-year progression-free survival (PFS).Materials: Preoperative MRI and clinical data from 400 PCa patients (185 with recurrence) were collected from three centers (one training and two external validation groups). Radiomics features were extracted from index lesions. PFS-associated clinical and radiomics features were selected by least absolute shrinkage and selection operator (LASSO)-Cox analysis. The K-means clustering method was used to identify subgroups and construct a Radiomic-Clinical model. PFS differences across subgroups were assessed using Kaplan-Meier survival analyses. The predictive performance of the Radiomic-Clinical model was compared with the European Association of Urology (EAU), University of California, San Francisco (UCSF) Cancer of the Prostate Risk Assessment (CAPRA), and PIPEN models using the concordance index (C-index).Results Five clinical and 13 radiomics features were selected, and three distinct prognostic subgroups were identified within the Radiomic-Clinical model. The Radiomic-Clinical model demonstrated superior predictive accuracy with C-indices of 0.82 (training group), 0.78 (validation group 1), and 0.79 (validation group 2), outperforming the EAU (0.68, 0.70, 0.65), CAPRA (0.71, 0.67, 0.70), and PIPEN models (0.71, 0.70, 0.68) (p&amp;thinsp;&amp;lt;&amp;thinsp;0.05).Conclusion Unsupervised learning using radiomics and clinical data effectively identifies distinct prognostic subgroups in PCa patients after RP, offering superior predictive performance over existing models for 5-year PFS.


---
# Estimate of the Reduction in the Impact of Rainwater on Road Degradation in the Mbanya Catchment Area

## 估计减少雨水对Mbanya集水区道路退化的影响

Link: https://www.researchsquare.com/article/rs-5849140/latest

This article is part of the sustainable development of road infrastructure. It assesses the effects of rainwater on unpaved roads in the Mbanya catchment area between January 2019 and December 2023, and proposes mitigation measures. July is the month when the risk of deterioration on these unsealed roads is highest. The aim of the work is to limit the impact of rainwater on the deterioration of roads in the Mbanya catchment area. To this end, an experimental study was carried out to determine the initial water content in the soil and the quantity of quicklime needed to stabilise the soil. Genetic algorithms and neural networks were used to estimate the water content at different depths in the soil. The square correlation coefficient, with a value of around 0.72, and the root mean square error, with a value of around 0.37 on all the test data are performance indicators that demonstrate the high accuracy of the coupled genetic algorithm-neural network model. Porosity and the quantity of lime were used as input parameters for the model, and the results show that porosity and the quantity of lime have an influence on the evolution of the water content in the soil. The pavement construction project is possible on these unsealed roads in the Mbanya watershed, as the soils have a bearing capacity P&amp;thinsp;&amp;ge;&amp;thinsp;.20MPa. However, the increase in water content can weaken as well as reduce the bearing capacity of the soil. Treating the soil with quicklime can lower the water content after water consumption and strengthen the bearing capacity.


---
# The role of geology in flood risk assessments: a systematic literature review and a comprehensive bibliometric analysis

## 地质学在洪水风险评估中的作用: 系统的文献综述和综合的文献计量分析

Link: https://www.researchsquare.com/article/rs-5866366/latest

Floods have emerged as a critical global issue due to climate change, leading to increased research interest across various fields. However, the complex relationship between floods and geological factors remains insufficiently explored in the literature. This bibliometric analysis addresses this gap by examining the intellectual structure of research on floods and geology through a systematic review of 71 articles published between 1989 and 2024. The study reveals that environmental science dominates the field (44%), followed by earth and planetary sciences (16%), engineering (12%), and computer sciences (7%). Analysis of research terms demonstrates the field's breadth, with hydrology-related keywords comprising 58.4% of total terms, while flood-related and geology-related terms represent 21.9% and 19.7%, respectively. This study was conducted using data from the Scopus database, and co-word, co-citation, and co-author network analysis were performed through VOSviewer software. Key topics, influential publications, citation patterns, and international collaborations were identified and visualized using VOSviewer. The United States leads with 22 publications and 771 citations, followed by China with 15 publications and 117 citations. The analysis identified seven distinct international collaboration clusters, highlighting the global nature of flood research while also revealing geographical disparities in coverage. Notably, previous research demonstrates that integrating geological layers into hydrological models yields results closely matching real flood measurements, even in basins lacking measurement stations. This finding emphasizes the significance of understanding lithological characteristics for enhanced flood risk assessment. The analysis highlights an increasing application of advanced technologies, such as remote sensing, GIS, and machine learning, particularly in post-2020 studies, marking a shift toward data-driven approaches.


---
# Machine Learning-Based Prediction of Exercise Intensity Using Skin Entropy During Incremental Cycling

## 基于机器学习的增量自行车运动强度皮肤熵预测

Link: https://www.researchsquare.com/article/rs-5193135/latest

Skin entropy, derived from skin temperature, is considered an intuitive indicator of dynamic physiological states during exercise. This study investigates the association between skin entropy and exercise intensity. Forty young males performed incremental cycling, during which physiological measurements (heart rate, oxygen consumption, pulmonary ventilation, and respiratory exchange ratio) and skin temperatures at three predetermined regions of interest (ROIs: forehead, chest, and abdomen) were recorded. Skin temperature data were transformed into entropy values, and comparative analyses were conducted to assess changes in skin temperature and entropy values at the three ROIs before and after exercise. Post-exercise, skin temperatures on the chest and abdomen significantly decreased, while the forehead remained unchanged. Conversely, entropy values at all three ROIs significantly increased after exercise. Correlation analysis revealed significant associations between skin entropy and physiological parameters, rather than temperature. Additionally, the XGBoost machine learning classification model was trained using chest and forehead entropy data to predict exercise intensity, achieving accuracies of 86.06% and 70.03%, respectively. In conclusion, skin entropy shows considerable potential as an alternative method for monitoring exercise intensity.


---
# A Low-Cost and Scalable Landslide Monitoring and Early Warning System for Mountainous Regions Using Deep Learning-based Computer Vision

## 使用基于深度学习的计算机视觉的低成本和可扩展的山区滑坡监测和预警系统

Link: https://www.researchsquare.com/article/rs-5744473/latest

Landslides pose severe risks to lives, property, and infrastructure, particularly in mountainous regions where monitoring is hindered by harsh environmental conditions and complex terrains. This study proposes a scalable, low-cost landslide monitoring and early warning system that integrates deep learning and computer vision technologies. Using a single optical camera, time-lapse images of slopes were captured and processed through advanced alignment, masking, and histogram equalization to maintain accuracy under adverse conditions. The system combines static monitoring via image differencing with dynamic monitoring using a RAFT-based optical flow model to detect surface deformations and real-time displacements. Field tests conducted on Washington Makahdiot Cliff demonstrated the system&amp;rsquo;s capability to identify landslide risks across three deformation phases. Static analysis detected significant grayscale changes (&amp;gt;&amp;thinsp;100) linked to actual slope deformations, while dynamic monitoring achieved a displacement detection accuracy of 94.6% for movements up to 25 cm. A novel early warning algorithm, based on thresholds for abnormal pixel changes, successfully classified risk levels, with landslide risk coefficients exceeding 0.4 during landslide events and remaining below 0.1 otherwise. The system proved resilient to environmental challenges, such as fog and strong winds, and demonstrated a positive correlation between landslide risk coefficients and rainfall, underscoring the importance of integrating real-time environmental data. This method provides an effective, robust, and cost-efficient solution for landslide monitoring and mitigation in complex terrains.


---
# A Deep Learning-Based Model for Financial Crisis Prediction

## 基于深度学习的金融危机预测模型

Link: https://www.researchsquare.com/article/rs-5829931/latest

Deep learning (DL) is becoming more widespread in the banking and finance industries. There is currently no thorough analysis of deep learning's uses in banking and finance in the corpus of extant literature. This study examines the literature on the application of model evaluation, input data evaluation, and model preprocessing evaluation. This study gives scholars and practitioner&rsquo;s guidance and insight into the current status of deep learning model application in the banking and finance industries. Two recurrent neural network architectures are compared in this study: the recurrent neural network (RNN) and the short-term memory (LSTM), the results show that deep learning is superior for financial crisis prediction. RNN has a 99.2% precision rate.


---
# Decoding Innovation Potential of Japanese Firms with A Machine Learning Approach

## 用机器学习方法解码日本企业的创新潜力

Link: https://www.researchsquare.com/article/rs-5863941/latest

This study proposes an efficiency technique for predicting firm-level innovation capabilities utilizing machine learning models for improving the forecast accuracy. The study employed boosted trees and neural boosting models and compared them with traditional statistical regression methods in anticipating a firm&rsquo;s innovation potential represented by patent applications. The 8 financial internal resources were used as a predictor that emerged from 1991 to 2019. Two key findings of validation are merged to predict an internal indicator of innovation capability. First, firm size is the most important predictor, contributing over half of the predictive power according to the model, followed by R&amp;D intensity and efficiency. Second, as the most effective machine learning model for prediction results, the boosted tree model outperformed the neural boosting model and fixed effect regression, as evidenced by higher R-squared values and lower RASE, demonstrating its ability to capture the complexity of invention activity. These findings provide a solid foundation for future research on firm-level innovation prediction, demonstrating the effectiveness of machine learning algorithms in recognizing complex innovation patterns. The findings also show that selected internal resources could strategically invest in innovation to promote the firm's innovation development.


---
# Dynamic evaluation of landslide susceptibility in a large-scale region based on time-series InSAR and multi-temporal cataloguing: a case study in Heifangtai, Gansu province

## 基于时间序列InSAR和多时相编目的大尺度区域滑坡易发性动态评价 -- 以甘肃省黑坊台为例

Link: https://www.researchsquare.com/article/rs-5755339/latest

Landslide disasters are common in the mountainous regions of western China, making accurate classification of landslide hazard risk levels essential for effective geological disaster management. Data-driven models have achieved notable advancements in landslide susceptibility evaluation. However, they still encounter challenges such as a lack of dynamic feature data and an over-reliance on sample quality, which limits their effectiveness for large-scales. To address these issues, this paper introduces an integrated evaluation approach that combines time-series InSAR deformation data with data-driven models. This method initially incorporated time-series InSAR deformation monitoring data as dynamic factors, which were filtered through multivariate covariance analysis to construct a dynamic landslide susceptibility evaluation system. Additionally, only landslide samples were adopted to conduct large-scale landslide susceptibility analysis. Various machine learning algorithms, based on landslide and non-landslide samples, were also applied for model comparison. Building upon this foundation, the evaluation of landslide susceptibility was performed by integrating InSAR deformation data with multi-temporal cataloging. The Heifangtai region in Gansu Province was chosen as a case study. The results indicate that the maximum entropy (Maxent) model achieved the highest accuracy for large-scale susceptibility assessments. Incorporating time-series InSAR deformation into the dynamic landslide susceptibility model improved accuracy by about 0.36%, compared to models without this data. Additionally, the proportion of landslides identified in high and very high susceptibility zones increased by 4.29%. By using eight years of landslide catalog data as positive samples, the presented model achieved an accuracy of 99.26%, demonstrating that long-term, high-quality positive samples improve the precision and reliability of regional predictions. This study advances large-scale landslide risk assessment by integrating a dynamic evaluation system that accounts for data across multiple time periods.


---
# Dynamicasome! Comprehensive Mutational Analysis and AI-Driven Prediction of PMM2 Pathogenicity: Integrating Molecular Dynamics Simulations with Machine Learning Models

## 动感快到!PMM2致病性的综合突变分析和AI驱动预测: 将分子动力学模拟与机器学习模型相结合

Link: https://www.researchsquare.com/article/rs-5538161/latest

Advances in genomic medicine have accelerated the identification of mutations in disease- associated genes, but the pathogenicity of many mutations remains unknown, hindering their use in diagnostics and clinical decision-making. Predictive AI models have been generated to combat this issue, but current tools display low accuracy when tested against functionally validated datasets. We show that integrating detailed conformational data extracted from molecular dynamics simulations (MDS) into advanced AI-based models can increase their predictive power. We carried out an exhaustive mutational analysis of the disease gene PMM2 and subjected structural models of each variant to MDS. AI models trained on this dataset outperformed existing tools when predicting the known pathogenicity of mutations. Our best performing model, a neuronal networks model, was also able to predict the pathogenicity of several PMM2 mutations currently considered of unknown significance. We believe this new model will help alleviate the burden of unknown variants in genomic medicine.


---
# Metacognition&rsquo;s Moderation Effect between Engagement with Large Language Model and Reflection of Its Usage in EFL Writing among Chinese University Students

## 元认知在中国大学生大语言模式参与中的调节作用及其在英语写作中的反映

Link: https://www.researchsquare.com/article/rs-5861238/latest

As a contributor to success in EFL (English as a foreign language) learning, the function of metacognition in digital intelligence era needs exploration. The study aimed to explore whether metacognition was functional when manipulating Large Language Models (LLM) to EFL writing. The present study adopted the moderation modeling approach to examine the interactive effect of metacognition implied between Chinese university students&rsquo; engagement with LLM and their reflection of LLM usage in EFL writing. 212 Students who graduated from Chinese tertiary institutions and studied at Chinese tertiary institutions currently are recruited as participants. They were required to complete a modified questionnaire containing 20 5-point Likert items to investigate whether their engagement with LLM could positively affect their reflection of LLM usage in EFL writing, and whether or not an effect is significant in predicting reflection of LLM usage when looking at the interaction effect between engagement with LLM and metacognition. The potential influence between engagement with LLM and reflection of LLM usage in EFL writing was statistically significant via simple linear regression. Moderation analysis retrieved from Sato&rsquo;s (2023) research examined metacognition as an interaction term between engagement with LLM and reflection of LLM usage, however, the role of metacogntion was also not effective. Findings suggest that LLM is effective for EFL writing class, while what kind of factor on reflection of LLM usage will be influenced by metacognition still needs further exploration.


---
# UNICORN: Towards Universal Cellular Expression Prediction with an Explainable Multi-Task Learning Framework

## 独角兽: 通过可解释的多任务学习框架实现通用细胞表达预测

Link: https://www.researchsquare.com/article/rs-5754185/latest

Sequence-to-function analysis is a challenging task in human genetics, especially in predicting cell-type-specific multi-omic phenotypes from biological sequences such as individualized gene expression. Here, we present UNICORN, a new method with improved prediction performances than the existing methods. UNICORN takes the embeddings from biological sequences as well as external knowledge from pre-trained foundation models as inputs and optimizes the predictor with carefully-designed loss functions. We demonstrate that UNICORN outperforms the existing methods in both gene expression prediction and multi-omic phenotype prediction at the cellular level and the cell-type level, and it can also generate uncertainty scores of the predictions. Moreover, UNICORN is able to link personalized gene expression profiles with corresponding genome information. Finally, we show that UNICORN is capable of characterizing complex biological systems for different disease states or perturbations. Overall, embeddings from foundation models can facilitate the understanding of the role of biological sequences in the prediction task, and incorporating multi-omic information can enhance prediction performances.

