# Dynamic selectout and voting-based federated learning for enhanced medical image analysis

## ç”¨äºå¢å¼ºåŒ»å­¦å›¾åƒåˆ†æçš„åŠ¨æ€é€‰æ‹©å’ŒåŸºäºæŠ•ç¥¨çš„è”é‚¦å­¦ä¹ 

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada0a6

**Authors:** Saeed Iqbal, Adnan N Qureshi, Musaed Alhussein, Khursheed Aurangzeb, Atif Mahmood and Saaidal Razalli Bin Azzuhri

Federated learning (FL) is a promising technique for training machine learning models on distributed, privacy-aware datasets. Nevertheless, FL faces difficulties with agent/client participation, model performance, and the heterogeneous nature of networked data sources when it comes to distributed healthcare systems. When these agents work together in the system, it is imperative to tackle the complexities of distributed deep learning. We suggest a novel approach that uses a voting mechanism and dynamic SelectOut inside the FL framework to address these problems. Local medical imaging datasets frequently show diversity in distribution and data imbalances. In certain situations, traditional FL techniques like FedProx and federated averaging, which depend on data size to weight contributions, might not be the optimal choice. In order to improve parameter aggregation and client selection unpredictability and increase the modelâ€™s adaptability to imbalanced and heterogeneous datasets, our proposed FedVoteNet model introduces SelectOut techniques based on voting methodology. Based on how much their local performance has improved from the last communication cycle, we arbitrarily remove clients. Additionally eliminated are clients whose model weights when combined with the global model adversely affect its performance. Our method is further enhanced by the inclusion of a voting mechanism. At the conclusion of each communication cycle, clients that improve both their local performance and their contribution to the global model are awarded higher voting values. This encourages more significant and effective contributions from clients by providing incentives for them to actively increase the diversity of their training data. We assess our approach on a dataset of medical images, including magnetic resonance imaging scans, and find that the FL model performs noticeably better (F1 Score = 0.968, Sensitivity = 0.977, Specificity = 0.945, and AUC = 0.950). The voting system and the dynamic SelectOut algorithms improve the convergence of the FL model and successfully handle the difficulties presented by uneven and heterogeneous datasets. To sum up, our proposed approach uses voting and dynamic SelectOut techniques to improve FL performance on a variety of uneven, distributed, and varied datasets. This strategy has a lot of potential to improve FL across a range of applications, especially those that prioritize data privacy, diversity, and performance.


---
# rule4ml: an open-source tool for resource utilization and latency estimation for ML models on FPGA

## rule4ml: FPGAä¸ŠMLæ¨¡å‹çš„èµ„æºåˆ©ç”¨ç‡å’Œå»¶è¿Ÿä¼°è®¡çš„å¼€æºå·¥å…·

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ada71c

**Authors:** Mohammad Mehdi Rahimifar, Hamza Ezzaoui Rahali and Audrey C Therrien

Implementing machine learning (ML) models on field-programmable gate arrays (FPGAs) is becoming increasingly popular across various domains as a low-latency and low-power solution that helps manage large data rates generated by continuously improving detectors. However, developing ML models for FPGAs is time-consuming, as optimization requires synthesis to evaluate FPGA area and latency, making the process slow and repetitive. This paper introduces a novel method to predict the resource utilization and inference latency of neural networks (NNs) before their synthesis and implementation on FPGA. We leverage HLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS) code, to synthesize a diverse dataset of NN architectures and train resource utilization and inference latency predictors. While HLS4ML requires full synthesis to obtain resource and latency insights, our method uses trained regression models for immediate pre-synthesis predictions. The prediction models estimate the usage of block RAM, digital signal processors, flip-flops, and look-Up tables, as well as the inference clock cycles. The predictors were evaluated on both synthetic and existing benchmark architectures and demonstrated high accuracy with R2 scores ranging between 0.8 and 0.98 on the validation set and sMAPE values between 10% and 30%. Overall, our approach provides valuable preliminary insights, enabling users to quickly assess the feasibility and efficiency of NNs on FPGAs, accelerating the development and deployment processes. The open-source repository can be found at https://github.com/IMPETUS-UdeS/rule4ml, while the datasets are publicly available at https://borealisdata.ca/dataverse/rule4ml.


---
# Inâ€Depth Discussion on Electrocatalytic Barrier with Electron Structure of Highâ€Entropy Alloy Predicted by Transfer Learning and Neural Networks

## è½¬ç§»å­¦ä¹ å’Œç¥ç»ç½‘ç»œé¢„æµ‹é«˜ç†µåˆé‡‘ç”µå­ç»“æ„ç”µå‚¬åŒ–åŠ¿å’çš„æ·±å…¥æ¢è®¨

Link: https://advanced.onlinelibrary.wiley.com/doi/10.1002/adfm.202423732?af=R

**Authors:** Chen Li, 
Rui Zhang, 
Peijie Ma, 
Kun Zheng

Advanced Functional Materials, EarlyView.


---
# Two-dimensional ferroelectric crystal with temperature-invariant ultralow thermal conductivity

## å…·æœ‰æ¸©åº¦ä¸å˜çš„è¶…ä½çƒ­å¯¼ç‡çš„äºŒç»´é“ç”µæ™¶ä½“

Link: https://arxiv.org/abs/2501.09990

**Authors:** Wenjie Zhou, Shi Liu

arXiv:2501.09990v1 Announce Type: new 
Abstract: We report the discovery of temperature-invariant ultralow thermal conductivity ($\kappa$) in monolayer \bpinse, a two-dimensional ferroelectric crystal with in-plane polarization. Using a combination of generalized Wigner transport equation theory and machine-learning-assisted molecular dynamics simulations, we reveal that the balance between particle-like phonon propagating and wave-like tunneling transport mechanisms results in a propagating-tunneling-invariant (PTI) ultralow thermal conductivity of approximately 0.6 W/mK (comparable to that of glass) over a broad temperature range ($150<800$~K). This behavior stems from intrinsic strong lattice anharmonicity driven by ferroelectric dipolar fluctuations, eliminating the need for extrinsic structural modifications. In contrast, the \ainse~monolayer, which shares the same stoichiometry, exhibits a conventional temperature-dependent thermal conductivity, $\kappa (T) \propto T^{-1}$, typical of simple crystals. Furthermore, we demonstrate that the anharmonicity in \bpinse~can be precisely modulated by an external electric field, enabling on-demand control of thermal transport properties, including modifying the temperature scaling behavior of heat conductivity and achieving a large thermal switching ratio of $\approx$2.5. These findings provide fundamental insights into the interplay between field-tunable lattice anharmonicity, phonon dynamics, and thermal transport mechanisms.


---
# Experimental realization of the ground state for the antiferromagnetic Ising model on a triangular lattice

## ä¸‰è§’æ™¶æ ¼ä¸Šåé“ç£ä¼Šè¾›æ¨¡å‹åŸºæ€çš„å®éªŒå®ç°

Link: https://arxiv.org/abs/2501.10026

**Authors:** Ke Wang, Xing-Jian Liu, Li-Ming Tu, Jia-Jie Zhang, Vladimir N. Gladilin, Jun-Yi Ge

arXiv:2501.10026v1 Announce Type: new 
Abstract: The antiferromagnetic Ising model on a triangular lattice (AFIT) exemplifies the most classical frustration system, arising from its triangular geometry that prevents all interactions from being simultaneously satisfied. Understanding geometric frustration in AFIT is crucial for advancing our knowledge of materials science and complex phases of matter. Here, we present a simple platform to study AFIT by arranging cylindrical magnets in vertical cavities of a triangular lattice, where magnets can slide along the cavity axis and stabilize either at the bottom or at the top of the cavity, analogous to the bistability of the Ising spin. The strong interactions of the magnets and the unique growing process allow the frustrated behavior and its ground state configurations to be directly observed. Notably, we observe a curved stripe phase, which is exotic to the Ising model. An effective thermalization process is developed to minimize the interaction energy, facilitating the evolution of various magnetic states, thereby visually realizing the ground state antiferromagnetic Ising model. Theoretical simulations and machine learning are performed concurrently to reveal the ground state and its evolution under effective thermal fluctuations, which are remarkably consistent with experimental results. Our system provides a unique platform to study frustrated systems and pave the way for future explorations in complex geometries.


---
# Surrogate-based multiscale analysis of experiments on thermoplastic composites under off-axis loading

## åŸºäºä»£ç†çš„çƒ­å¡‘æ€§å¤åˆææ–™åœ¨ç¦»è½´è½½è·ä¸‹å®éªŒçš„å¤šå°ºåº¦åˆ†æ

Link: https://arxiv.org/abs/2501.10193

**Authors:** M. A. Maia, I. B. C. M. Rocha, D. Kova\v{c}evi\'c, F. P. van der Meer

arXiv:2501.10193v1 Announce Type: cross 
Abstract: In this paper, we present a surrogate-based multiscale approach to model constant strain-rate and creep experiments on unidirectional thermoplastic composites under off-axis loading. In previous contributions, these experiments were modeled through a single-scale micromechanical simulation under the assumption of macroscopic homogeneity. Although efficient and accurate in many scenarios, simulations with low-off axis angles showed significant discrepancies with the experiments. It was hypothesized that the mismatch was caused by macroscopic inhomogeneity, which would require a multiscale approach to capture it. However, full-field multiscale simulations remain computationally prohibitive. To address this issue, we replace the micromodel with a Physically Recurrent Neural Network (PRNN), a surrogate model that combines data-driven components with embedded constitutive models to capture history-dependent behavior naturally. The explainability of the latent space of this network is also explored in a transfer learning strategy that requires no re-training. With the surrogate-based simulations, we confirm the hypothesis raised on the inhomogeneity of the macroscopic strain field and gain insights into the influence of adjustment of the experimental setup with oblique end-tabs. Results from the surrogate-based multiscale approach show better agreement with experiments than the single-scale micromechanical approach over a wide range of settings, although with limited accuracy on the creep experiments, where macroscopic test effects were implicitly taken into account in the material properties calibration.


---
# Entanglement transitions induced by quantum-data collection

## é‡å­æ•°æ®é‡‡é›†å¼•èµ·çš„çº ç¼ è·ƒè¿

Link: https://arxiv.org/abs/2310.03061

**Authors:** Shane P. Kelly, Jamir Marino

arXiv:2310.03061v4 Announce Type: replace-cross 
Abstract: We present an entanglement transition in an array of qubits, induced by the transfer of quantum information from a system to a quantum computer. This quantum-data collection is an essential protocol in quantum machine learning algorithms that promise exponential advantage over their classical counterparts. In this and an accompanying work [Phys. Rev. A 111, 012425 (2025)], we identify sufficient conditions for an entanglement transition to occur in the late time state of the system and quantum computer. In this letter, we present an example entanglement transition occurring in a system comprised of a 1D chain of qubits evolving under a random brickwork circuit. After each layer, a fraction $p$ of sites undergo noisy quantum transduction in which quantum information is transferred to a quantum computer but at the cost of introducing noise from an environment. For an entanglement transition to occur, we argue that the environment must obtain the same amount of information as gained by the computer. Under this condition, the circuit shows a transition from volume law to area law entanglement as the rate $p$ is increased above a critical threshold. Our work delineates the prerequisites for quantum-data collection to induce entanglement transitions, thereby establishing a foundational framework for emergent entanglement phenomena in protocols relevant to quantum machine learning.


---
# Two halves don't make a whole: instability and idleness emerging from the co-evolution of the production and innovation processes

## ä¸¤åŠä¸æ˜¯ä¸€ä¸ªæ•´ä½“: ç”Ÿäº§å’Œåˆ›æ–°è¿‡ç¨‹çš„å…±åŒè¿›åŒ–ä¸­å‡ºç°çš„ä¸ç¨³å®šå’Œé—²ç½®

Link: https://arxiv.org/abs/2501.09778

**Authors:** Patrick Llerena, Corentin Lobet, Andr\'e Lorentz

arXiv:2501.09778v1 Announce Type: new 
Abstract: We propose a disaggregated representation of production using an agent-based fund-flow model that emphasizes inefficiencies, such as factor idleness and production instability, and allows us to explore their emergence through simulations. The model incorporates productivity dynamics (learning and depreciation) and is extended with time-saving process innovations. Specifically, we assume workers possess inherent creativity that flourishes during idle periods. The firm, rather than laying off idle workers, is assumed to harness this potential by involving them in the innovation process. Results show that a firm's organizational and managerial decisions, the temporal structure of the production system, the degree of workers' learning and forgetting, and the pace of innovation are critical factors influencing production efficiency in both the short and long term. The coevolution of production and innovation processes emerges in our model through the two-sided effects of idleness: the loss of skills through forgetting and the deflection of time from the production of goods to the production of ideas giving birth to idleness-driven innovations. In doing so, it allows us to question the status of labour as an adjustment variable in a productive organisation. The paper concludes by discussing potential solutions to this issue and suggesting avenues for future research.


---
# High-Accuracy Physical Property Prediction for Organics via Molecular Representation Learning: Bridging Data to Discovery

## é€šè¿‡åˆ†å­è¡¨å¾å­¦ä¹ å¯¹æœ‰æœºç‰©è¿›è¡Œé«˜ç²¾åº¦ç‰©ç†æ€§è´¨é¢„æµ‹: å°†æ•°æ®ä¸å‘ç°è”ç³»èµ·æ¥

Link: https://arxiv.org/abs/2501.09896

**Authors:** Qi Ou, Hongshuai Wang, Minyang Zhuang, Shangqian Chen, Lele Liu, Ning Wang, Zhifeng Gao

arXiv:2501.09896v1 Announce Type: new 
Abstract: The ongoing energy crisis has underscored the urgent need for energy-efficient materials with high energy utilization efficiency, prompting a surge in research into organic compounds due to their environmental compatibility, cost-effective processing, and versatile modifiability. To address the high experimental costs and time-consuming nature of traditional trial-and-error methods in the discovery of highly functional organic compounds, we apply the 3D transformer-based molecular representation learning algorithm to construct a pre-trained model using 60 million semi-empirically optimized structures of small organic molecules, namely, Org-Mol, which is then fine-tuned with public experimental data to obtain prediction models for various physical properties. Despite the pre-training process relying solely on single molecular coordinates, the fine-tuned models achieves high accuracy (with $R^2$ values for the test set exceeding 0.95). These fine-tuned models are applied in a high-throughput screening process to identify novel immersion coolants among millions of automatically constructed ester molecules, resulting in the experimental validation of two promising candidates. This work not only demonstrates the potential of Org-Mol in predicting bulk properties for organic compounds but also paves the way for the rational and efficient development of ideal candidates for energy-saving materials.


---
# ComptoNet: An End-to-End Deep Learning Framework for Scatter Estimation in Multi-Source Stationary CT

## ComptoNet: ä¸€ç§ç”¨äºå¤šæºå¹³ç¨³CTæ•£å°„ä¼°è®¡çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶

Link: https://arxiv.org/abs/2501.09986

**Authors:** Yingxian Xia, Zhiqiang Chen, Li Zhang, Yuxiang Xing, Hewei Gao

arXiv:2501.09986v1 Announce Type: new 
Abstract: Multi-source stationary computed tomography (MSS-CT) offers significant advantages in medical and industrial applications due to its gantry-less scan architecture and/or capability of simultaneous multi-source emission. However, the lack of anti-scatter grid deployment in MSS-CT results in severe forward and/or cross scatter contamination, presenting a critical challenge that necessitates an accurate and efficient scatter correction. In this work, ComptoNet, an innovative end-to-end deep learning framework for scatter estimation in MSS-CT, is proposed, which integrates Compton-scattering physics with deep learning techniques to address the challenges of scatter estimation effectively. Central to ComptoNet is the Compton-map, a novel concept that captures the distribution of scatter signals outside the scan field of view, primarily consisting of large-angle Compton scatter. In ComptoNet, a reference Compton-map and/or spare detector data are used to guide the physics-driven deep estimation of scatter from simultaneous emissions by multiple sources. Additionally, a frequency attention module is employed for enhancing the low-frequency smoothness. Such a multi-source deep scatter estimation framework decouples the cross and forward scatter. It reduces network complexity and ensures a consistent low-frequency signature with different photon numbers of simulations, as evidenced by mean absolute percentage errors (MAPEs) that are less than $1.26\%$. Conducted by using data generated from Monte Carlo simulations with various phantoms, experiments demonstrate the effectiveness of ComptoNet, with significant improvements in scatter estimation accuracy (a MAPE of $0.84\%$). After scatter correction, nearly artifact-free CT images are obtained, further validating the capability of our proposed ComptoNet in mitigating scatter-induced errors.


---
# High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces

## é«˜é˜¶ä¸å¯çº¦ç¬›å¡å°”å¼ é‡åˆ†è§£å’Œç­‰å˜ç©ºé—´çš„åŸº

Link: https://arxiv.org/abs/2412.18263

**Authors:** Shihao Shao, Yikang Li, Zhouchen Lin, Qinghua Cui

arXiv:2412.18263v4 Announce Type: replace-cross 
Abstract: Irreducible Cartesian tensors (ICTs) play a crucial role in the design of equivariant graph neural networks, as well as in theoretical chemistry and chemical physics. Meanwhile, the design space of available linear operations on tensors that preserve symmetry presents a significant challenge. The ICT decomposition and a basis of this equivariant space are difficult to obtain for high-rank tensors. After decades of research, Bonvicini (2024) recently achieves an explicit ICT decomposition for $n=5$ with factorial time/space complexity. In this work we, for the first time, obtains decomposition matrices for ICTs up to rank $n=9$ with reduced and affordable complexity, by constructing what we call path matrices. The path matrices are obtained via performing chain-like contractions with Clebsch-Gordan matrices following the parentage scheme. We prove and leverage that the concatenation of path matrices is an orthonormal change-of-basis matrix between the Cartesian tensor product space and the spherical direct sum spaces. Furthermore, we identify a complete orthogonal basis for the equivariant space, rather than a spanning set (Pearce-Crump, 2023), through this path matrices technique. To the best of our knowledge, this is also the first analytic, rather than numerical, method for theoretically obtaining arbitrary rank orthogonal ICT decomposition matrices and orthogonal equivariant bases. We further extend our result to the arbitrary tensor product and direct sum spaces, enabling free design between different spaces while keeping symmetry. The Python code is available at https://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where the $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and 4m32s on 28-cores Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.


---
# De Novo Design and Bioactivity Prediction of Mitotic Kinesin Eg5 Inhibitors Using MPNN and LSTM-Based Transfer Learning

## åŸºäºMPNNå’ŒLSTMçš„è¿ç§»å­¦ä¹ å¯¹æœ‰ä¸åˆ†è£‚é©±åŠ¨è›‹ç™½Eg5æŠ‘åˆ¶å‰‚çš„ä»å¤´è®¾è®¡å’Œç”Ÿç‰©æ´»æ€§é¢„æµ‹

Link: https://dx.doi.org/10.26434/chemrxiv-2025-7xcq2?rft_dat=source%3Ddrss

**Authors:** Olayinka O., Ajani

Breast cancer, the most commonly diagnosed disease worldwide, has been linked to the overexpression of the kinesin Eg5 protein, a spindle motor protein crucial for the assembly and maintenance of the bipolar spindle during mitosis. This makes Eg5 an attractive therapeutic
target for tumor treatment. To address the urgent need for effective treatments for this lifethreatening illness, we utilized generative AI to design novel and potential inhibitors of this protein. In this study, a generative LSTM model was pretrained on SMILES data from ChEMBL and
subsequently fine-tuned using SMILES of compounds with reported activity against the Eg5 protein. The fine-tuned model generated valid compounds, which were screened using a machine learning model, drug-likeness filters, molecular docking, and molecular dynamics (MD)
simulations conducted over 200 ns. Five novel compounds with better binding affinities to Eg5 compared to the co-crystallized ligand were identified. The top compound, Compound 103 (a bioisostere of the co-crystallized
ligand), demonstrated a significantly improved binding free energy (-82.68 kcal/mol) compared to the co-crystallized ligand (-76.98 kcal/mol), as determined by MM-GBSA calculations. ADMET predictions and MD simulations further confirmed that the top compounds interacted
effectively with the target protein and exhibited drug-like properties. This study shows the potential of generative AI to explore our vast chemical space and find
promising drug candidates. However, further in vitro and in vivo studies are needed to confirm the predicted biological effects of the top compounds.


---
# Integrating Pharmacokinetics and Quantitative Systems Pharmacology Approaches in Generative Drug Design

## åœ¨ç”Ÿæˆæ€§è¯ç‰©è®¾è®¡ä¸­æ•´åˆè¯ä»£åŠ¨åŠ›å­¦å’Œå®šé‡ç³»ç»Ÿè¯ç†å­¦æ–¹æ³•

Link: https://dx.doi.org/10.26434/chemrxiv-2025-77hg5?rft_dat=source%3Ddrss

**Authors:** Gerard J. P., van Westen

Integrated understanding of pharmacokinetics (PK) and pharmacodynamics (PD) is a key aspect of successful drug discovery. Yet in generative computational drug design, the focus often lies on optimizing potency. Here we integrate PK property predictions in DrugEx, a generative drug design framework and we explore the generated compoundsâ€™ PD through simulations with a quantitative systems pharmacology (QSP) model. Quantitative structure-property relationship models were developed to predict molecule PK (clearance, volume of distribution and unbound fraction) and affinity for the Adenosine A2AR receptor (A2AR), a drug target in immuno-oncology. These models were used to score compounds in a reinforcement learning framework to generate molecules with a specific PK profile and high affinity for the A2AR. We predicted the expected tumor growth inhibition profiles using the QSP model for selected candidate molecules with varying PK and affinity profiles. We show that optimizing affinity to the A2AR, while minimizing or maximizing a PK property, shifts the type of molecular scaffolds that are generated. The difference in physicochemical properties of the compounds with different predicted PK parameters was found to correspond with the differences observed in the PK dataset. We demonstrated the use of the QSP model by simulating the effect of a broad range of compound properties on the predicted tumor volume. In conclusion, our proposed integrated workflow incorporating affinity predictions with PKPD may provide a template for the next generation of advanced generative computational drug design.


---
# Bridging the Gap: Using Machine Learning Force Fields to Simulate Gold Break Junctions at Pulling Speeds Closer to Experiments

## å¼¥åˆå·®è·: ä½¿ç”¨æœºå™¨å­¦ä¹ åŠ›åœºä»¥æ¥è¿‘å®éªŒçš„é€Ÿåº¦æ¨¡æ‹Ÿé‡‘æ–­è£‚ç»“

Link: https://dx.doi.org/10.26434/chemrxiv-2025-szt8q?rft_dat=source%3Ddrss

**Authors:** Gemma C., Solomon

The properties and dynamics of gold nanowires have been studied for decades as an important testbed for several physical phenomena. Gold nanowires forming at contacts are an integral part of molecular junctions used to study the electronic and thermal properties of single molecules. However, the huge discrepancy in timescales between experiments and simulations, compounded by the limited accuracy of classical force fields, has posed a challenge in accurately simulating realistic junctions. Here we show that machine-learning force fields reveal new behaviors not captured by classical force fields when modeling Au-Au pulling junctions. Our simulations show a dependency of the average breaking distance on the pulling speed, highlighting a more complex behavior than previously thought. Our results demonstrate that the use of more accurate force fields to simulate metallic nanowires is essential to capture the complexity of their structural evolution in break junction experiments. Our developments advance the modeling accuracy of molecular junctions, bridging the gap between experimental and simulation timescales.


---
# Improving Drug-Induced Liver Injury Prediction Using Graph Neural Networks with Augmented Graph Features from Molecular Optimisation

## ä½¿ç”¨å…·æœ‰åˆ†å­ä¼˜åŒ–å¢å¼ºå›¾å½¢ç‰¹å¾çš„å›¾å½¢ç¥ç»ç½‘ç»œæ”¹å–„è¯ç‰©è¯±å¯¼çš„è‚æŸä¼¤é¢„æµ‹

Link: https://dx.doi.org/10.26434/chemrxiv-2024-d12gk-v2?rft_dat=source%3Ddrss

**Authors:** Taeyeub, Lee

BACKGROUND. Drug-induced liver injury (DILI) is a significant concern in drug development, often leading to the discontinuation of clinical trials and the withdrawal of drugs from the market due to severe hepatotoxicity. This study explores the application of graph neural networks (GNNs) for DILI prediction, using molecular graph representations as the primary input.

METHODS. We evaluated several GNN architectures, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Sample and Aggregation (GraphSAGE), and Graph Isomorphism Networks (GINs), using the latest FDA DILI dataset and other molecular property prediction datasets. We introduce a novel approach that creates a custom graph dataset, driven by molecular optimisation, that incorporates detailed and realistic chemical features such as bond lengths and partial charges as input into the GNN models. We have named our model approach DILIGeNN.

RESULTS. DILIGeNN achieved an AUC of 0.897 on the DILI dataset, surpassing current state-of-the-art model in the DILI prediction task. Furthermore, DILIGeNN outperformed the state-of-the-art in other graph-based molecular prediction tasks, achieving an AUC of 0.918 on the Clintox dataset and 0.993 on the BBBP dataset and 0.953 on the BACE dataset, indicating strong generalisation and performance across different datasets.

CONCLUSION. DILIGeNN, without relying on biological data, outperforms the state-of-the-art methods in DILI prediction that incorporate both chemical and biological data. These findings highlight the effectiveness of our molecular graph generation and the GNN training approach as a powerful tool for early-stage drug development and drug repurposing pipeline.


---
# Scalable Drug Property Prediction via Automated Machine Learning

## é€šè¿‡è‡ªåŠ¨æœºå™¨å­¦ä¹ è¿›è¡Œå¯æ‰©å±•çš„è¯ç‰©ç‰¹æ€§é¢„æµ‹

Link: https://dx.doi.org/10.26434/chemrxiv-2025-2p12l-v2?rft_dat=source%3Ddrss

**Authors:** Matthew, Clark

The integration of artificial intelligence technologies into pharmaceutical research is crucial for gaining an early understanding of molecular properties, thereby facilitating successful drug design. Constructing a machine learning (ML) model however, requires knowledge spanning from data preprocessing and feature engineering to model fine-tuning, posing a challenge for chemists to effectively utilize ML tools for drug property predictions. This paper introduces a model training engine (MTE), which is a scalable automated ML pipeline that supports end-to-end ğ˜ªğ˜¯ ğ˜´ğ˜ªğ˜­ğ˜ªğ˜¤ğ˜° drug property prediction. To accelerate the training process, a paralleled model fine-tuning scheme is developed for model optimization and selection, reducing the time complexity from O(n*k) to O(n+kÂ²), where  k >1 and kÂ² is much smaller than n. The MTE is benchmarked against five state-of-the-art models using twenty-two Therapeutic Data Commons ADMET datasets. The experimental results demonstrate the effectiveness and robustness of the MTE across diverse molecular data prediction tasks.


---
# Implementing Symptom-Based Predictive Models for Early Diagnosis of Pediatric Respiratory Viral Infections

## å®æ–½åŸºäºç—‡çŠ¶çš„é¢„æµ‹æ¨¡å‹ä»¥æ—©æœŸè¯Šæ–­å„¿ç§‘å‘¼å¸é“ç—…æ¯’æ„ŸæŸ“

Link: https://www.researchsquare.com/article/rs-5490724/latest

Introduction: Respiratory viral infections, including SARS-CoV-2, respiratory syncytial virus (RSV), influenza, rhinovirus, and adenovirus, are major causes of acute respiratory illness (ARI) in children. Symptom-based predictive models are valuable tools for expediting diagnoses, particularly in primary care settings. This study assessed the effectiveness of machine learning-based models in estimating infection probabilities for these common pediatric respiratory viruses using symptom data.
Methods: Data were collected from 868 children with ARI symptoms evaluated across 14 primary care centers, members of COPEDICAT (Coronavirus Pediatria Catalunya), from October 2021 to October 2023. Random Forest and Boosting models with 10-fold cross-validation were used, applying SMOTE-NC to address class imbalance. Model performance was evaluated via area under the curve (AUC), sensitivity, specificity, and Shapley Additive exPlanations (SHAP) values for feature importance.
Results: The model performed best for RSV (AUC: 0.81, sensitivity: 0.64, specificity: 0.77) and effectively ruled out SARS-CoV-2 based on symptom absence, such as crackles and wheezing. Predictive performance was lower for non-enveloped viruses like rhinovirus and adenovirus, due to their nonspecific symptom profiles. SHAP analysis identified key symptoms patterns for each virus.
Conclusions: The study demonstrated that symptom-based predictive models effectively identify pediatric respiratory infections, with notable accuracy for RSV, SARS-CoV-2 and influenza.


---
# Career Adaptability and Its Relation to Thriving at Work among Staff Nurses

## æŠ¤å£«èŒä¸šé€‚åº”æ€§åŠå…¶ä¸å·¥ä½œè“¬å‹ƒå‘å±•çš„å…³ç³»

Link: https://www.researchsquare.com/article/rs-5760555/latest

Background
Career adaptability is vital in the nursing profession, especially given the rapidly changing healthcare environment. This adaptability nurtures a workplace where nurses can thrive excel, continuously develop new skills, and stay fully engaged in their roles.
Aim
The present research aimed to assess career adaptability and its relation to thriving at work among staff nurses.
Methods
A descriptive correlational design was included 105 staff nurses.
Results
In this research, the studied subjects reported that more than one fifth (21%) of studied nurses had a low level regarding total career adaptability. Also, more than half (55.2%) of them had moderate level regarding total career adaptability. While, (23.8%) of them had high level regarding total career adaptability. Furthermore, the minority (16.2%) of staff nurses had a low level regarding total thriving at work. Also, (65.7%) of them had moderate level regarding total thriving at work. While, only (18.1%) of them had high level regarding total thriving at work.
Conclusion
This research was concluded that career adaptability was positively correlated and significantly with thriving at work among nurses (r&thinsp;=&thinsp;.194**, p&thinsp;=&thinsp;0.000).&amp;nbsp;
Recommendation: The healthcare organizations should implement targeted interventions such as personalized career development programs, wellness initiatives to boost energy levels, and enhanced access to continuous learning opportunities.
Trial Registration Number [TRN] The study protocol was approved by the Research Ethics Committee of the Faculty of Nursing, Ain Shams University[code number: NUR 24.8.345].


---
# Models for Predicting Tree Diameter at Breast Height from Over and Under Bark Diameter of Stump in Eucalyptus camaldulensis Plantations

## ä»æ¡‰æ ‘äººå·¥æ—æ ‘æ¡©çš„æ ‘çš®ç›´å¾„å’Œæ ‘ä¸‹ç›´å¾„é¢„æµ‹æ ‘å¾„çš„æ¨¡å‹

Link: https://www.researchsquare.com/article/rs-5765573/latest

Allometric functions that predict tree diameter at breast height (D) from stump diameter (DS), referred to as DS-D models, are essential for estimating forest metrics like stand volume and belowground carbon (C), especially when D cannot be measured, such as after inadequately recorded clearcutting or illegal logging of threatened species.Many available DS-D models are generic for diverse species and ecological condition, and arelargely based on DS measured over bark (DSoB). Studies show that bark thickness (BT), a factor of DSoB, varies intra-species and across ecosystemsas a response to fire history and other ecological factors. This raises concerns about the reliance on generic, DSoB-based modelsfor inventoryon regenerating clearcut plantation sites.
We hypothesize that local DS-D models calibrated with DS under bark (DSuB) better account for in-situecological variability inBT. To test this, we gathered data through destructive and non-destructive sampling of clonally propagated (CP), post-fire recovery (FR), and coppice-regenerated (CR) stands of monoculture Eucalyptus camaldulensisplantations (ECPs) in East Africa. Using the data, we employed machine learning and traditional statistical methods to calibrate DS-D models, alternately based on DSoB and DSuB as predictor variables. Through error residuals and effect sizes analyses, we compared (1) the performance of previously published, ex-situgeneric DS-D equations versus the study-derived local models, (2) the effectivenessDSoB versus DSuB for DSoBboth as the predictor and the input variables for DS-D models, and (3) assessed the statistical variation of DS-D models between post-fire recovery and non-fire impacted ECP stands.
The results showed that (1) in-situ models outperformed ex-situ equations (2) substituting DSoB with DSuB as regressors improved model accuracy, (3) DSoB substitution with DSuB as input variable did not reduce the performance of DSoB-based models. and (4) modeling of DS-D allometry post-fire recovery stand was complicated by high heterogeneity in tree diameter classes.
These findings show that recalibrating DSoB-based models with DSuB can better capture DS-D allometry due to the circumvention of local environmental effects on BT. The findings further confirm the utility of DS-D models even when the stump's bark layer is missing.


---
# Enhancing Arecanut Quality Grading: A Comparison of Custom CNNs and Transfer Learning Models

## æé«˜arcanutè´¨é‡åˆ†çº§: è‡ªå®šä¹‰cnnå’Œè¿ç§»å­¦ä¹ æ¨¡å‹çš„æ¯”è¾ƒ

Link: https://www.researchsquare.com/article/rs-5841671/latest

Effective grading of arecanut is essential for ensuring product quality, maximizing market competitiveness, and satisfying consumer preferences. However, traditional methods of arecanut grading are challenging due to variations in arecanut size, shape, and appearance, resulting in subjective and inconsistent evaluations. Deep learning can enhance this process by automating grading and using sophisticated algorithms to assess both visual and non-visual attributes, thereby increasing efficiency, accuracy, and consistency. This study presents two standalone CNN-based methodologies for automated arecanut quality grading, leveraging DenseNet121 and InceptionV3 with custom layers tailored for arecanut classification. A dataset of 2,000 high-resolution images, manually curated from farms and augmented for diversity, was used for training and validation. Eight CNN architectures - DenseNet121, EfficientNetB4, InceptionResNetV2, InceptionV3, MobileNetV2, ResNet50, VGG16, and VGG19 were evaluated. Experimental findings showed DenseNet121 and InceptionV3 achieved the highest accuracy (95.67%) and strong precision/recall scores (96%), making them the most promising models. Meanwhile, MobileNetV2 was identified as the fastest model in terms of classification speed; however, its relatively low accuracy limits its practical application in grading tasks. DenseNet121 and InceptionV3, while marginally slower at 0.015 and 0.011 seconds per image, respectively, offered a good balance between computational cost and elevated accuracy. DenseNet121 excels in feature reuse through its dense connectivity, reducing redundancy and improving performance on smaller datasets, while InceptionV3 utilizes multi-scale feature extraction to capture intricate patterns effectively. Both models demonstrate robustness under varying conditions, ensuring reliability in practical deployment scenarios. This study highlights the potential of CNNs to provide a reliable, and scalable solution for arecanut grading, benefiting farmers by expanding market opportunities.


---
# Exponential-trigonometric Optimization Algorithm with Multi-Strategy Fusion for UAV three-dimensional path planning

## å¤šç­–ç•¥èåˆçš„æŒ‡æ•°ä¸‰è§’ä¼˜åŒ–ç®—æ³•åœ¨æ— äººæœºä¸‰ç»´èˆªè¿¹è§„åˆ’ä¸­çš„åº”ç”¨

Link: https://www.researchsquare.com/article/rs-5825357/latest

With the rapid advancement of Unmanned Aerial Vehicle (UAV) technology, trajectory planning has become a focus research. This paper proposes a three-dimensional path planning method for UAV based on an improved Exponential-triangle Optimization Algorithm (IETO). By constructing a multi-objective optimization function that considers factors such as path length, flight altitude, and turning angle, a comprehensive evaluation of path quality is able to be achieved. The IETO algorithm incorporates interval-constrained logistic chaotic mapping, dynamic reverse learning strategy, and an adaptive artificial bee colony algorithm (ABC) escape mechanism within the ETO algorithm. These enhancements prevent premature convergence to local optima. Through benchmark function tests on the CEC2017 test set and simulations in peak threat environments, the IETO algorithm demonstrated superior robustness. Compared to mainstream algorithms like GWO and GJO, IETO achieves the best performance in 62% of function tests. It also demonstrates exceptional performance in solving complex functions, effectively balances exploration and exploitation capabilities. In mountainous environments, the IETO algorithm generates the smoothest paths with the lowest costs and quickly converges to the optimal solution.


---
# DPCRec-Dual Preferences Learning with Capsule Network for Next POI Recommendation

## DPCRec-ä½¿ç”¨èƒ¶å›Šç½‘ç»œè¿›è¡ŒåŒé‡åå¥½å­¦ä¹ ï¼Œä»¥è·å¾—ä¸‹ä¸€ä¸ªPOIå»ºè®®

Link: https://www.researchsquare.com/article/rs-5841922/latest

The goal of the next Point-of-Interest (POI) recommendation task is to predict a list of POIs that a user might visit next, based on their check-in history, including the locations and times of their check-ins. This list includes the probability of visiting each POI. Clearly, the performance of this task is closely related to how well the user's interests could be extracted. Previous research has made significant progress in this area, but there are still some challenges: 1) Current methods cannot fully extract user interests from different perspectives. 2) They struggle to effectively combine multiple or diverse user interests for prediction. In this paper, a Dual Interest Capsule Recommendation (DPCRec) is proposed to address these two issues. For the first problem, user interests are divided into long-term and short-term interests and introduce Advanced Long-Term Interest Feature Extractor(ALE) and Advanced Short-Term Interest Feature Extractor(ASE) to extract these interests separately. Among them, ALE uses a multi-head attention mechanism with deep attention and residual connections to capture long-term interests, while ASE employs a GRU module enhanced with attention and multi-gating techniques to capture short-term interests. For the second problem, a novel capsule network called Capsule Deep Pointer (CapsDP) is proposed by us, which effectively combines long-term and short-term interests and maps the hierarchical relationship between user interests and the POIs to be predicted. Extensive experiments on three datasets show that our model outperforms ten baseline models, achieving state-of-the-art results.


---
# A Cybersecurity-Centric Model for Predicting Electronic Health Records System Adoption for Sustainable Healthcare: A SEM-ANN Approach

## ä»¥ç½‘ç»œå®‰å…¨ä¸ºä¸­å¿ƒçš„é¢„æµ‹ç”µå­å¥åº·è®°å½•ç³»ç»Ÿé‡‡ç”¨å¯æŒç»­åŒ»ç–—ä¿å¥çš„æ¨¡å‹: sem-annæ–¹æ³•

Link: https://www.researchsquare.com/article/rs-5798963/latest

Electronic Health Records (EHR) systems are critical for achieving healthcare sustainability, offering benefits such as improving care of the patient, enhanced management of data, and operational efficiency. Despite these advantages, the adoption of EHR systems remains a challenge, influenced by various technological, organizational, and individual factors. This study builds upon the UTAUT2 framework by incorporating cybersecurity considerations to offer a more comprehensive understanding of EHR adoption and its role in promoting sustainable healthcare. Data were collected from 374 healthcare professionals through purposive sampling and analyzed using a hybrid approach combining Structural Equation Modeling (SEM) and Artificial Neural Networks (ANN). The findings demonstrate that EHR use plays a key role in advancing healthcare sustainability by improving organizational efficiency and long-term resilience. Key factors influencing EHR adoption include confidentiality and possession/control, underscoring the importance of data privacy, security, and system ownership. Performance expectancy and social influence significantly impact adoption decisions, reflecting the role of usability, peer influence, and organizational dynamics. Additional factors such as integrity and facilitating conditions showed moderate importance, while hedonic motivation and availability were less critical. This study contributes to EHR adoption research by integrating cybersecurity and user experience factors, offering insights for healthcare organizations and policymakers. The findings highlight the need to prioritize data security and usability to enhance adoption. Future research could explore EHR adoption in diverse settings and examine evolving adoption dynamics.


---
# Social media as a supplementary tool to teaching and learning: A case of first year students at a University of Technology

## ç¤¾äº¤åª’ä½“ä½œä¸ºæ•™å­¦å’Œå­¦ä¹ çš„è¡¥å……å·¥å…·: ä»¥ç§‘æŠ€å¤§å­¦ä¸€å¹´çº§å­¦ç”Ÿä¸ºä¾‹

Link: https://www.researchsquare.com/article/rs-5851266/latest

The educational sector has experienced transition from physical classes to online classes owing to COVID-19 that had the world by the scruff of its neck. After COVID-19 restrictions were lifted educational sectors had to maintain a clean transition from online classes back to physical classes hence they adopted what is known as blended learning to accommodate both admires or physical and virtual classes. This transition led to most institutions adopting social media as a supplement tool to ensure that the transition was smooth, and this gave rise to the usage of social media in teaching and learning. Consequently, this quantitative study sought to investigate the most preferred social media platforms by the students for the purpose of teaching and learning. Convenience sampling was used to administer closed ended questionnaires to 37 Engineering Graphics and Design (EGD) first-year pre-service teachers. These questionnaires will follow a 5 Likert type scale. The resulting data was analyzed using the Statistical Package for Social Sciences (SPSS) version 29.00. With the aid of Unified Theory of Acceptance and Use of Technology (UTAUT), the findings show that WhatsApp and YouTube are the most preferred social media platform by students to be used for teaching and learning as they recorded a mean score of 4.54 and 4.30 respectively. The findings also revealed that smartphone is the device that most students access social media on for schooling purposes. Based on the findings, this chapter recommends that universities should adopt social media such as WhatsApp and YouTube as the official tools to be used to supplement learning management systems (LMS) as most students struggle to access such platforms and find more easier to use WhatsApp and YouTube.


---
# EXPLORE: learning interpretable rules for patient-level prediction

## æ¢ç´¢: å­¦ä¹ æ‚£è€…æ°´å¹³é¢„æµ‹çš„å¯è§£é‡Šè§„åˆ™

Link: https://www.researchsquare.com/article/rs-5804837/latest

Objective We investigate whether a trade-off occurs between predictive performance and model interpretability in real-world health care data and illustrate how to develop clinically optimal decision rules by learning under constraints with the Exhaustive Procedure for Logic-Rule Extraction (EXPLORE) algorithm.Methods We enhanced EXPLORE&amp;rsquo;s scalability to enable its use with real-world datasets and developed an R package that generates simple decision rules. We compared EXPLORE&amp;rsquo;s performance to 7 state-of-the-art model algorithms across 5 prediction tasks using data from the Dutch Integrated Primary Care Information (IPCI) database. Additionally, we characterized EXPLORE&amp;rsquo;s space of near-optimal models (i.e. Rashomon set) and conducted experiments on incorporating domain knowledge and improving existing models.Results The prediction models developed using LASSO, RandomForest, and XGBoost consistently performed best in terms of AUROC, followed by DecisionTree and EXPLORE. However, the decision rules generated by EXPLORE are much simpler (at most 5 predictors) than the aforementioned. GOSDT-G, IHT, and RIPPER performed worse. Moreover, we demonstrated that EXPLORE&amp;rsquo;s Rashomon set is very large (1,381&amp;thinsp;&amp;minus;&amp;thinsp;20,320 models) with a large variability in both the generalizability and model diversity. We then showed there is a potential to find more clinically optimal decision rules using EXPLORE by incorporating domain knowledge (age/sex and task-specific features) or improving existing models (the CHADS2 score).Conclusions Our study shows that more complex models generally outperform simpler ones, confirming the expected interpretability-performance trade-off, although it varies in strength across prediction tasks. EXPLORE&amp;rsquo;s ability to learn under constraints is valuable for generating clinically optimal decision rules.


---
# Macular segmentation using an automatic deep learning and graph cut strategy

## ä½¿ç”¨è‡ªåŠ¨æ·±åº¦å­¦ä¹ å’Œgraph cutç­–ç•¥è¿›è¡Œé»„æ–‘åˆ†å‰²

Link: https://www.researchsquare.com/article/rs-5829828/latest

Age-related Macular Degeneration (AMD) is one of the main diseases affectingvisual health in the world, since it causes severe and irreversible vision loss inelderly people. According to the International Agency for the Prevention of Blind-ness (IAPB), by the year 2040, 288 million people are expected to be affectedworldwide, while in Colombia for the year 2020, approximately 234,200 caseswere estimated. With the improvement of computer vision techniques, automaticdiagnosis has become a reliable tool for screening and determining the degree ofthe disease. Many strategies have been proposed in the last decade, from the firstbased on manual characterization of the disease to current ones based on modeltraining using large databases of images annotated by specialists, with very highcomputational costs and data collection time. The present article proposes a novelmethod based on combining the two trends, using the best of each one. The dis-ease is characterized by segmenting its two fundamental features in cascade: theocular vascular network is segmented with a pre-trained deep learning model andtransformed into a graph for extraction of terminal nodes (which are known todelimit the macular zone); and the macula is segmented through a semi-automatic algorithm called graph cut that requires initial background and foreground infor-mation (which corresponds to the terminal nodes already obtained) to become anautomatic method. Finally, we present a comparison between macular segmen-tation using the proposed algorithm with parametric changes in its architectureand a deep learning model for macular segmentation with a reduced set of aug-mented images. It is confirmed that, with a limited database, the proposed graphcut-deep learning strategy is a viable way to obtain a method to extract the mainfeatures of the disease and generate a subsequent diagnosis.


---
# Clinical Nursing Students&rsquo; Perception of Their Mentors' Assessment Literacy: Student Competence, Self-Efficacy, and Gender Difference

## ä¸´åºŠæŠ¤ç†ä¸“ä¸šå­¦ç”Ÿå¯¹å…¶å¯¼å¸ˆè¯„ä¼°ç´ å…»çš„æ„ŸçŸ¥: å­¦ç”Ÿèƒ½åŠ›ï¼Œè‡ªæˆ‘æ•ˆèƒ½æ„Ÿå’Œæ€§åˆ«å·®å¼‚

Link: https://www.researchsquare.com/article/rs-5792871/latest

Background: Mentors play a crucial role in clinical nursing education, particularly in assessing student nurses. However, if students cannot perceive their mentors&amp;rsquo; assessment-literate practices (referred to as mentors&amp;rsquo; assessment-literate practices hereafter), they may not effectively utilize assessment information for learning. Despite its significance, mentors&amp;rsquo; assessment-literate practices and its antecedent factors are not well studied. This study aims to explore the mediation role of nursing students&amp;rsquo; self-efficacy in the relationship between their competence and their perception of mentors&amp;rsquo; assessment-literate practices, while also examining potential gender bias in mentors&amp;rsquo; assessment-literate practices.Methods:  Participants included 854 final-year nursing students (61 males, 793 females) from 10 colleges/universities in southern China. After eight months of clinical training, students reported on mentors&amp;rsquo; assessment-literate practices, self-efficacy, internship grades, and gender. Path analysis was conducted using Mplus 8.10 to test the mediating model, and gender bias was assessed through differential item functioning analysis with Winsteps&amp;reg; (Version 5.6.0.0).Results: The study found a full mediation effect of self-efficacy between competence and students&amp;rsquo; perception of their mentors&amp;rsquo; assessment-literate practices, with a significant indirect association of .10. The path coefficient between competence and self-efficacy is .12, and between self-efficacy and perceived mentors&amp;rsquo; assessment-literate practices is .86. Three items were identified with potential differential item functioning, suggesting mentors should offer male students more practice opportunities and female students more chances to explain.Conclusions: To enhance mentors&amp;rsquo; assessment-literate practices, stakeholders should prioritize developing students&amp;rsquo; self-efficacy. While improving competence is beneficial, the small indirect effect suggests other strategies are also needed. This study introduces assessment-literate practices as a key concept in nursing education, highlighting its antecedent factors and potential gender biases for better assessment practices.


---
# Fostering Supportive Online Communities: Exploring Bystander Intervention in Cyberbullying Prevention

## åŸ¹å…»æ”¯æŒæ€§çš„åœ¨çº¿ç¤¾åŒº: æ¢ç´¢ç½‘ç»œæ¬ºå‡Œé¢„é˜²ä¸­çš„æ—è§‚è€…å¹²é¢„

Link: https://www.researchsquare.com/article/rs-5833561/latest

Cyberbullying can profoundly impact individuals' mental health, leading to increased feelings of anxiety, depression, and social isolation. Psychological research suggests that cyberbullying victims may experience long-term psychological consequences, including diminished self-esteem and academic performance. The widespread use of social media platforms among university students has raised major concerns over cyberbullying, which can have detrimental effects on student mental well-being and academic performance. We designed CBNet, a convolutional neural network (CNN)-based model for detecting cyberbullying among student social media groups. We developed a comprehensive dataset collected from several social media platforms popular among university students. Our results demonstrate that CBNet notably outperforms both the traditional machine learning approaches and the RNN-based model and presents an outstanding value of precision, recall, and F1-score overall, with an Area Under the ROC Curve significantly higher than 0.99. Combined with the fact that the issue of cyberbullying always remains relevant, these results suggest the high feasibility of our suggested approach to the detection of incidents. Given our results, CBNet could be used as a preventative tool for educators, administrators, and community managers to combat cyberbullying behavior and make the online community safer and more welcoming for students. This work suggests the high importance of advanced machine learning approaches to real-world social problems and contributes to the creation of greater digital well-being in university students&amp;rsquo; communities. By employing CBNet, institutions can take proactive measures to mitigate the harmful effects of cyberbullying and cultivate a positive online culture conducive to student success and flourishing.


---
# Deep-learning based Vehicle Trajectory Reconstruction for Arterial intersection Under Connected Vehicle Environment

## è½¦è”ç½‘ç¯å¢ƒä¸‹åŸºäºæ·±åº¦å­¦ä¹ çš„åŠ¨è„‰äº¤å‰å£è½¦è¾†è½¨è¿¹é‡æ„

Link: https://www.researchsquare.com/article/rs-5818910/latest

A complete spatial temporal traffic flow diagram with delicate vehicle trajectories enables traffic managers to totally perceive the fluctuation of traffic status at intersection. Equipped with advanced sensors continuously collecting high-resolution data, Connected Vehicles (CVs) opens up the possibility of reconstructing fully-sampled vehicle trajectories. In this context, this study establishes a novel framework that combines the deep-leaning based method with classic car-following method to reconstruct the trajectories at the micro-perspective level. The cornerstone of framework is the proposed Arrival-GAN model, designed to estimate the distribution of vehicle arrival. This model excels in capturing stochastic arrival patterns even under low-traffic conditions, eliminating the need for the common assumption of uniform arrival between adjacent probe vehicles. Subsequently, an extended car-following model is employed to deduce detailed trajectories based on the driving behavior of CVs. The method evaluation is conducted in the simulated arterial network and compared the results with other classic baselines. Results indicated that the proposed framework successfully reconstructs complete trajectories with significantly improved accuracy, especially in scenarios of low traffic density. This study showcases the potential of utilizing connected vehicles and deep-learning techniques to enhance our understanding of traffic statues, thereby empowering traffic managers with better insights for efficient intersection management.


---
# A New Approach to Automatic Epilepsy Detection from EEG Signals Using Archimedean Spiral and Swin Transformer

## ä½¿ç”¨é˜¿åŸºç±³å¾·èºæ—‹å’ŒSwinå˜å‹å™¨ä»EEGä¿¡å·è‡ªåŠ¨æ£€æµ‹ç™«ç—«çš„æ–°æ–¹æ³•

Link: https://www.researchsquare.com/article/rs-5835848/latest

Epilepsy, a neurological disorder marked by recurrent and unpredictable seizures due to abnormal brain electrical activity, is studied using electroencephalography (EEG) which measures brain activity. The EEG signals are commonly employed to diagnose and monitor conditions like epilepsy, sleep disorders, and brain injuries. This research work introduces an effective hybrid approach based on Archimedean spiral coding (ASC) and a swin transformer-based convolutional neural network (CNN) techniques to detect epilepsy automatically using EEG signals. This proposed ASC method transforms EEG signals into a visually informative 3D matrix and employs swin transformer-based CNN architecture for classification. It yields an accuracy of 97.98% and 88.22% for sample- and subject-based ten-fold cross-validation, respectively using the public epilepsy database of 121 populations. The developed system is ready to be tested with more epilepsy patients from different races to validate the performance. It produced a better accuracy score as compared to the existing results.


---
# HeBoots: A Novel Heuristic Bootstrapping Entity Alignment Model Based on Reasoning

## Hboots: ä¸€ç§åŸºäºæ¨ç†çš„å¯å‘å¼è‡ªä¸¾å®ä½“å¯¹é½æ¨¡å‹

Link: https://www.researchsquare.com/article/rs-5832396/latest

Entity alignment models commonly rely on representation learning, with many also employing bootstrapping techniques to improve performance. In this paper, we present an innovative heuristic bootstrapping model designed to validate and enhance the results produced by conventional bootstrapping methods. Our approach leverages pseudo-anchor relationships between two graphs to strengthen alignment. Moreover, feature selection&amp;mdash;a crucial yet often neglected aspect of graph alignment&amp;mdash;is addressed in our model. We introduce a weighted feature mechanism that assigns greater significance to key features, ensuring more accurate alignment results. Additionally, we propose a novel dual margin-based loss function specifically designed for entity alignment tasks. Experimental results demonstrate that our model consistently surpasses state-of-the-art entity alignment methods on multiple benchmark datasets, delivering performance gains of 2&amp;ndash;4%.


---
# NEOSTI: A Neuromorphic Electronic-Opto Spatial-Temporal Hybrid Image Sensor

## NEOSTI: ä¸€ç§ç¥ç»å½¢æ€ç”µå­-å…‰ç”µæ—¶ç©ºæ··åˆå›¾åƒä¼ æ„Ÿå™¨

Link: https://www.researchsquare.com/article/rs-5770022/latest

Image sensors in machine vision systems face significant challenges related to energy efficiency and processing capability when storing, transferring, and processing massive amounts of data. In humans, over 80% of information processed by the brain is obtained through the eyes, which are capable of detecting and synchronously processing information with extremely low overall power consumption. Inspired by the biomimetics, here we propose a Neuromorphic Electronic-Opto Spatial Temporal Imager (NEOSTI), the smallest all-in-one eye size fully integrated vision system enabling acquisition and operation in typical indoor/outdoor non-coherent environments, under both natural and artificial lighting conditions, without any extra requirement of the light source, such as laser or coherent light source. NEOSTI combines processing-pre-sensor (PPS) in optical domain, processing-in-sensor (PIS) with non-linear acquisition capability while optical to electronic converting, and processing-near-sensor (PNS) in electronic domain, enabling parallel data computing capabilities while sensing. NEOSTI also integrates a low complexity Binary Neural Network (BNN) on the chip to process image semantic information. It attains near-human performance in five static and dynamic visual processing tasks.


---
# Naturally disengaging control to reveal habits

## è‡ªç„¶åœ°è„±ç¦»æ§åˆ¶ä»¥æ­ç¤ºä¹ æƒ¯

Link: https://www.researchsquare.com/article/rs-5773028/latest

Habits are an essential part of everyday decision-making. However, the mechanisms underlying habit formation and expression in humans are difficult to study in the laboratory, owing to a dearth of convenient experimental paradigms that reliably exhibit a key marker of habits &ndash; training-induced inflexibility &ndash; under ecologically valid conditions. This difficulty is often attributed to the fact that habits are identified in contrast to goal-directed (GD) control, which research participants typically engage strongly in laboratory experiments. To address this gap, we develop a new, short habit learning paradigm that incorporates several features we hypothesized would encourage participants to disengage GD control, enabling habits to exert greater influence over behavior: a hierarchical multi-step trial structure, opportunities for self-correction, and frequent switches between extensively and moderately practiced behaviors. Through a series of experiments, we demonstrate that overtraining amplifies habitual control, as evidenced by errors biased toward the overtrained context and away from the moderately-trained context at early response times, while later responses remain dominated by GD control. The reliability of this overtraining effect depended on the inclusion of task features designed to dampen GD control. In addition to providing a practical, robust, and flexible tool for studying the cognitive processes underlying habit formation and habitual control, our paradigm moves us beyond the traditional stimulus-response conception of habits, expanding the definition to include more complex, hierarchical behaviors that better reflect naturalistic human habits.


---
# Assessing Conformation Validity and Rationality of Deep Learning-Generated 3D Molecules

## è¯„ä¼°æ·±åº¦å­¦ä¹ ç”Ÿæˆçš„3Dåˆ†å­çš„æ„è±¡æœ‰æ•ˆæ€§å’Œåˆç†æ€§

Link: https://www.researchsquare.com/article/rs-5479504/latest

Recent advancements in artificial intelligence (AI) have revolutionized the field of 3D molecule generation. However, the lack of effective evaluation methods for 3D conformations limits further improvements. Current techniques, in order to achieve the necessary speed for evaluating large number of AI-generated molecules, often rely on empirical geometric metrics that do not adequately capture various conformational anomalies, or on molecular mechanics (MM) energy metrics that exhibit low accuracy and lack atomic or torsional details. To address this gap, we propose a two-stage approach that achieves both high speed and quantum mechanical (QM) level accuracy. The first stage, termed the validity test, employs an AI-derived force field to identify atoms with elevated energy resulting from implausible neighboring environments. The second stage, known as the rationality test, utilizes a deep learning network trained on data with density functional theory (DFT) accuracy to detect rotatable bonds with high torsional energies. To demonstrate the functionality of our evaluation system, we applied our approach to five recently reported 3D molecule generation AI models across 102 targets in Directory of Useful Decoys-Enhanced (DUD-E) dataset. To facilitate accessibility for the academic community, our method is available as an open-source package.


---
# Leveraging Domain Motif Assembler for Multi-objective, Multi-domain and Explainable Molecular Design

## åˆ©ç”¨åŸŸåŸºåºç»„è£…å™¨è¿›è¡Œå¤šç›®æ ‡ï¼Œå¤šåŸŸå’Œå¯è§£é‡Šçš„åˆ†å­è®¾è®¡

Link: https://www.researchsquare.com/article/rs-5734073/latest

Designing molecules to meet multiple objectives simultaneously is a significant challenge, rooted in the inherent complexity of structure-property relationships and the limited availability of labeled molecular data. Compounding this difficulty, the black-box nature of deep learning models hampers interpretability, undermining confidence in their applications and restricting broader industrial adoption. To address these limitations, we introduce Domain Motif Assembler (DM-Assembler), a novel framework that employs a score-based matching model to guide the selection and assembly of molecular motifs. DM-Assembler excels in generating high-performance molecules that satisfy multi-objective constraints across various domains, drastically reducing the combinatorial complexity of chemical space by leveraging domain motifs and diffusion models on discrete fragment representations. Comprehensive experimental evaluations reveal three distinct advantages of DM-Assembler. First, it delivers exceptional performance in designing molecules with optimized composite metrics, achieving an average improvement of approximately 56\% across four benchmark domains, while extending beyond the property boundaries of its training data. Second, it generates molecular distributions that closely match domain-specific datasets, recording the lowest KL divergence among 149 descriptors encompassing multi-scale topological structures and biochemical properties&mdash;outperforming the second-best method by roughly 19\%. Third, we developed a post-hoc interpretability method based on 149 molecular descriptors, revealing DM-Assembler&rsquo;s superior ability to fit physicochemical properties compared to atom-based models and topological structures compared to non-diffusion models, highlighting its advantages in molecular generation tasks. Furthermore, DM-Assembler demonstrates outstanding conditional sampling capabilities, seamlessly integrating auxiliary scorers or domain motif priors for efficient and accurate conditional generation. This enables deeper qualitative exploration of structure-activity relationships and accelerates pharmacophore discovery. Overall, we anticipate that DM-Assembler will advance trust-worthy and multi-objective molecular design across diverse disciplines, fostering significant progress in related research fields.


---
# Guided Synthesis of the stable sols based on nanosized titanium(IV) oxides with the predictable particle size and antimicrobial properties

## å…·æœ‰å¯é¢„æµ‹çš„ç²’å¾„å’ŒæŠ—èŒæ€§èƒ½çš„åŸºäºçº³ç±³æ°§åŒ–é’› (IV) çš„ç¨³å®šæº¶èƒ¶çš„æŒ‡å¯¼åˆæˆ

Link: https://www.researchsquare.com/article/rs-5843786/latest

The article discusses the targeted synthesis of sols with nanosized titanium(IV) oxides for biological and medical applications, as well as a doping agent precursor in obtaining crystals from solutions. When preparing sols without using surfactants, the synthesis conditions were changed: temperature and duration of hydrolysis, composition and concentration of titanium-containing precursors, stabilizing acid concentration. The resulting sols have different hydrodynamic diameter of titanium(IV) oxide nanoparticles (from ~2 to 2000 nm) and different stability (from 0 to 90 days). A specific set of machine learning tools was developed for well-interpretable analysis of experimental data. These tools were used in three stages of experiments to optimize three functional characteristics of the synthesized sols by varying five synthesis parameters. As a result, a universal minimalistic mechanism for the targeted synthesis of sols with the required characteristics was proposed, allowing for a reduction in the number of experiments and the study of the relationships between synthesis parameters and functional characteristics in various experiments.


---
# Large Language Models Enable Textual Interpretation of Image-Based Astronomical Transient Classifications

## å¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥å¯¹åŸºäºå›¾åƒçš„å¤©æ–‡ç¬æ€åˆ†ç±»è¿›è¡Œæ–‡æœ¬è§£é‡Š

Link: https://www.researchsquare.com/article/rs-5723428/latest

Modern astronomical surveys deliver immense volumes of transient detections, yet distinguishing between real astrophysical signals (e.g., explosive events, variable stars) and bogus imaging artifacts remains challenging. Convolutional neural networks (CNNs) are effective for such real-bogus classification in optical imaging data; however, their reliance on latent representations makes it difficult to discern the underlying physical reasoning behind each classification. Here, we show that large language models (LLMs) achieve accuracy comparable to CNNs on three major optical transient survey datasets (Pan-STARRS, MeerLICHT, and ATLAS) while simultaneously providing direct, human-readable descriptions for every transient. Using only 15 examples and a concise set of instructions, Google's LLM, Gemini, achieves a 93\% average accuracy across these datasets which have quite diverse resolution and pixel scales. This is the first demonstration of a successful application of an LLM to imaging data from optical transient surveys and it eliminates the need for extensive and complex labeled sets. Furthermore, we demonstrate that a second LLM can evaluate the coherence of the first LLM classifications, thus guiding iterative improvements by indicating problematic examples. This opens up new possibilities: rather than laboriously training a network from scratch, one can simply define the desired output characteristics and rely on the LLM to deliver them. Furthermore, by generating textual descriptions of observed features, LLMs enable users to query classifications as if navigating an annotated catalog, rather than deciphering abstract latent spaces. As next-generation telescopes and surveys further increase data streams, LLM-based classification could help bridge the gap between automated detection and transparent, human-level understanding.

