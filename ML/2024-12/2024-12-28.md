# Scientists use machine learning to develop an opener for a molecular can

## 科学家使用机器学习来开发分子罐的开瓶器

Link: https://phys.org/news/2024-12-scientists-machine-molecular.html

In an era of medical care that is increasingly aiming at more targeted medication therapies, more individual therapies and more effective therapies, doctors and scientists want to be able to introduce molecules to the biological system to undertake specific actions.


---
# Numerical simulations show how the classical world might emerge from the many-worlds universes of quantum mechanics

## 数值模拟显示了经典世界如何从量子力学的多世界宇宙中出现

Link: https://phys.org/news/2024-12-numerical-simulations-classical-world-emerge.html

Students learning quantum mechanics are taught the Schrodinger equation and how to solve it to obtain a wave function. But a crucial step is skipped because it has puzzled scientists since the earliest days—how does the real, classical world emerge from, often, a large number of solutions for the wave functions?


---
# Delineating the effective use of self-supervised learning in single-cell genomics

## 描述在单细胞基因组学中有效使用自我监督学习

Link: https://www.nature.com/articles/s42256-024-00934-3

**Authors:** Fabian J. Theis

<p>Nature Machine Intelligence, Published online: 27 December 2024; <a href="https://www.nature.com/articles/s42256-024-00934-3">doi:10.1038/s42256-024-00934-3</a></p>Self-supervised learning techniques are powerful assets for enabling deep insights into complex, unlabelled single-cell genomic data. Richter et al. here benchmark the applicability of self-supervised architectures into key downstream representation learning scenarios.


---
# Training robust and generalizable quantum models

## 训练鲁棒且可推广的量子模型

Link: http://link.aps.org/doi/10.1103/PhysRevResearch.6.043326

**Authors:** Julian Berberich, Daniel Fink, Daniel Pranjić, Christian Tutschku, and Christian Holm

Author(s): Julian Berberich, Daniel Fink, Daniel Pranjić, Christian Tutschku, and Christian Holm<br /><p>Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive parameter-dependent Lipschitz bounds for quantum models with trainable e…</p><br />[Phys. Rev. Research 6, 043326] Published Fri Dec 27, 2024


---
# Machine-learning-assisted dual harmonic generation FROG for enhanced ultrafast pulse recovery

## 机器学习辅助的双谐波生成FROG，用于增强超快脉冲恢复

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad9f21

**Authors:** Wallace Jaffray, Ziheng Guo, Andrea Di Falco and Marcello Ferrera

Ultrafast pulse characterisation is crucial for studying processes that occur at femtosecond timescales and below. Because of this, various methods have been developed to recover a pulse’s electric field profile at these durations, with the frequency-resolved optical gating (FROG) technique being the most common. However, this approach is computationally expensive and suffers from limitations in terms of robustness and reliability. In this regard, recent publications have demonstrated that applying machine learning towards ultrafast pulse recovery can alleviate these issues, providing more accurate retrievals. Inspired by these works, we propose an encoder–decoder scheme for a FROG system which exploits dual harmonic generation in low-index thin films. Specifically, we demonstrate enhanced reliability and accuracy of ultrafast pulse recovery when compared to machine learning approaches using second or third harmonic signals independently. As the amount of information used to train each neural network is kept constant, this study demonstrates and benchmarks the technological advantages of contextual information analysis involving multiple nonlinear processes.


---
# Enhancing Predictive Models for Solubility in Multicomponent Solvent Systems using Semi-Supervised Graph Neural Networks

## 使用半监督图神经网络增强多组分溶剂系统中溶解度的预测模型

Link: https://dx.doi.org/10.26434/chemrxiv-2024-7bz9j?rft_dat=source%3Ddrss

**Authors:** Seonah, Kim

Solubility plays a critical role in guiding molecular design, reaction optimization, and product formulation across diverse chemical applications. Despite its importance, current approaches for measuring solubility face significant challenges, including time- and resource-intensive experiments and limited applicability to novel compounds. Computational prediction strategies, ranging from theoretical models to machine learning (ML) based methods, offer promising pathways to address these challenges. However, such methodologies need further improvement to achieve accurate predictions of solubilities in multicomponent solvent systems, as expanding the modeling approaches to multicomponent mixtures enables broader practical applications in chemistry. This study focuses on modeling solubility in multicomponent solvent systems, where data scarcity and model generalizability remain key hurdles. We curated a comprehensive experimental solubility dataset (MixSolDB) and examined two graph neural network (GNN) architectures – concatenation and subgraph – for improved predictive performance. By further integrating computationally derived COSMO-RS data via a teacher-student semi-supervised distillation (SSD) framework, we significantly expanded the chemical space and corrected previously high error margins. These results illustrate the feasibility of unifying experimental and computational data in a robust, flexible GNN-SSD pipeline, enabling greater coverage, improved accuracy, and enhanced applicability of solubility models for complex multicomponent solvent systems.


---
# Data-Driven Parametrization of All-atom force fields for Organic Semiconductors

## 有机半导体全原子力场的数据驱动参数化

Link: https://dx.doi.org/10.26434/chemrxiv-2024-bl6f9?rft_dat=source%3Ddrss

**Authors:** Xinyan , Wang

Organic semiconductors (OSCs) composed of π conjugated molecules have gained significant interest in the study of bulk properties such as molecular arrangement and electron mobility. However, the types of torsion in the traditional force field (FF) are limited, fail to cover the chemical space of π conjugated molecules, and thus, hinder further molecular dynamics (MD) simulation to deduce these bulk properties through statistical mechanics. In this study, we introduce OSCFF, which supports various types of torsion for conjugated molecules and enables the generation of RESP charges with high accuracy through the neural network (NN). To develop the OSCFF, we construct two expansive and highly diverse molecular datasets: one consists of around 56,000 fragment geometries with torsion profiles, and another consists of around 472,000 optimized molecule geometries with RESP charges. The OSCFF demonstrates high accuracy in predicting torsional energy profiles, RESP charges, and the radial distribution function (RDF) for conjugated molecule systems. Furthermore, our OSCFF is compatible with the GAFF2 and a pipeline is provided for automatically generating the Gromacs supported topology file. We expect OSCFF will reduce the manual effort required for MD simulations of OSCs and serve as a valuable tool for multiple stages of OSCs design.


---
# Automated mechanical ventilator design and analysis using neural network

## 基于神经网络的自动化机械呼吸机设计与分析

Link: https://www.researchsquare.com/article/rs-5030307/latest

Mechanical ventilation is the process through which breathing support is provided to patients who face inconvenience during respiration. During the pandemic, many people were suffering from lung disorders, which elevated the demand for mechanical ventilators. The handling of mechanical ventilators is to be done under the assistance of trained professionals and demands the selection of ideal parameters. In this work, a computer-aided simulation of ventilator design is performed for clinical complications like pneumonia and Chronic Obstructive Pulmonary Disease (COPD) and is validated against normal ventilatory parameters. The parameters such as tidal volume, respiratory rate, and inspiration to expiration ratio (I: E) are considered as control values to check the stability of the mechanical ventilator for stern performance. The check valves 1 and 2 governed by the control parameters provide optimal volume that must be sent inside the tracheal region. The hyperparameters are tuned using a low intricate feed-forward neural network (FFNN). The trained features serve as input to the sensors present in the mimicked lung model. The performance metrics of FFNN during the training and testing phases substantiate the optimal performance of the ventilator. The simulation and validation results indicate that the designed ventilator system is stable and effective for clinical use, providing optimal respiratory support for patients with pneumonia and COPD.


---
# Hyperspectral remote sensing image classification based on enhanced pseudo 3D features and salient band selection

## 基于增强伪三维特征和显著波段选择的高光谱遥感图像分类

Link: https://www.researchsquare.com/article/rs-4820019/latest

Hyperspectral classification is a research hotspot in the field of remote sensing. Recently, 3D convolutional neural networks (CNNs) have achieved better classification performances than traditional machine learning algorithms. However, because of the large kernel size and spectral redundancy, the classification accuracy and efficiency of existing CNN-based methods are still restrained. In this paper, a lightweight model based on the enhanced pseudo 3D features and salient band selection is proposed for HSI classification. Specifically, an enhanced pseudo 3D convolution block is constructed to extract spectral-spatial features with less parameters. Then, a salient band selection block without parameters is designed to relieve the spectral redundancy. To obtain the diverse spectral dependency, a local-connected layer is introduced to explore the interactions between adjacent bands. By integrating these blocks, deep spectral-spatial pseudo 3D features can be well prepared for classification. Experiments on three HSI data sets show that the proposed model outperforms the state-of-the-arts. Source code is available at https://github.com/ningyang-li/EP3FEN.


---
# Identification and liquid-liquid phase separation-Related Genes Prognosis Model in pancreatic cancer by comprehensive analysis

## 胰腺癌中液-液相分离相关基因的综合分析及预后模型

Link: https://www.researchsquare.com/article/rs-5655084/latest

Background Pancreatic cancer is one of the most aggressive and deadly malignancies of the digestive system, with an extremely low five-year survival rate, making treatment highly challenging. Liquid-liquid phase separation (LLPS) is a mechanism that regulates the dynamic aggregation of intracellular proteins and nucleic acids. In cancer, tumor-associated proteins and gene mutations can regulate the formation of LLPS, influencing the quantity and functionality of intracellular condensates, thereby promoting abnormal cellular behavior and contributing to tumorigenesis and cancer progression. Although previous studies have suggested that LLPS may be involved in cancer progression by affecting mechanisms such as stress response and protein aggregation, its specific role in pancreatic cancer remains unclear. Therefore, exploring the molecular mechanisms of LLPS in pancreatic cancer could uncover new biomarkers and potential therapeutic targets, facilitating the development of personalized treatment strategies.Methods LLPS-related signatures were obtained from the TCGA database and Gene Cards. Over 100 machine learning methods were applied to screen for prognostic gene sets closely related to survival, followed by the construction of a risk model. External validation of the model was performed using the GEO database. Single-cell RNA sequencing analysis was conducted on the GSE155698 dataset to assess gene expression profiles and risk scores.Result A total of 55 LLPS-related prognostic genes were identified in pancreatic cancer. Through multiple machine learning methods, 11 key prognostic genes (CKB, PRSS3, KRT6A, DLGAP5, EPHA2, FAM83B, FOXM1, IGF2BP3, KRT16, CASP14, and TOP2A.) were selected, demonstrating high sensitivity and specificity as biomarkers for the diagnosis and prognosis of PAAD patients. The risk score signature constructed based on machine learning was found to be an independent factor associated with high mortality, advanced clinicopathological features, and chemotherapy resistance. Furthermore, this signature was closely related to lipid biosynthesis pathways, cell cycle-related pathways, and KRAS/TP53 mutation profiles, suggesting its potential role in enhancing the number and functionality of abnormal lipid-based "droplets" and accelerating cell cycle progression, thereby driving pancreatic cancer development. Additionally, the signature was strongly associated with immune-suppressive cell infiltration and immune checkpoint expression, indicating its role as a key immunosuppressive factor in the tumor microenvironment. Single-cell RNA sequencing revealed that PKP3, EPHA2, and KRT16 were specifically expressed in pancreatic ductal epithelial cells.Conclusions This study provides insights into the potential links between LLPS-related molecular characteristics and clinical features, the tumor microenvironment, and clinical drug response. It highlights the crucial role of LLPS in pancreatic cancer progression and treatment resistance, offering valuable new perspectives for the prognosis and treatment response prediction in PAAD.


---
# Design of an Integrated Model for Gait Identification Using DDPG, Sparse Group Lasso, and Stacked Generalization

## 使用DDPG，稀疏组套索和堆叠泛化的步态识别集成模型的设计

Link: https://www.researchsquare.com/article/rs-5705969/latest

Applications in security, healthcare, and human-computer interaction critically require accurate gait identification under complex environmental conditions such as varying lighting and background noise. Current approaches are usually unable to adapt to dynamic, highdimensional environments, with reduced accuracy of feature extraction and classification. This paper bridges the gap by offering an overview of a multi-stage framework that merges the advanced techniques of machine learning with those of reinforcement learning for preemptive optimization. It begins by using Deep Deterministic Policy Gradient for a preprocessing module: environmental parameters are dynamically adjusted so that their real-time data quality is optimized. The module is then followed by a phase in multi-domain feature extraction using Sparse Group Lasso along with KMeans clustering, thereby improving representativeness while reducing dimensionality by 50&amp;ndash;60%. We have used a hybrid of stacked generalization, in this case of XGBoost and LightGBM, because this provides a better overall classification accuracy. Refined temporal post-processing at the hidden Markov model and Auto-Regressive Integrated Moving Average (ARIMA) results in enhanced phase transitions that may be gait-based, thus improving the identification accuracy. As the final step, we use Proximal Policy Optimization to implement feedback-driven reinforcement learning, where improvements are incrementally made by updating the model with iterative feedback. This new method enhances the correctness of feature extraction by 12% in complex environments. Overall classification accuracy increases by 5&amp;ndash;6% and reaches 95%. False positives in gait phase transitions decrease as well, further increasing the system robustness and reliability in real-world applications.


---
# Empirical Evaluation for Cricket CommentaryDecoder

## 板球评论解码器的经验评估

Link: https://www.researchsquare.com/article/rs-5712957/latest

Cricket is not just a sport but a global phenomenon, attracting billions of fans and generating immense revenue through broadcasting rights, streaming platforms, and fantasy sports applications. With the advent of professional leagues like the Indian Premier League (IPL) and Big Bash League (BBL), cricket has become a data-rich and analytics-driven game. Real- time event classification from live commentary is crucial for powering these ecosystems, from enhancing viewer experiences to enabling fantasy leagues and predictive analytics. This project aims to develop a real-time cricket commentary decoder to classify events accurately from unstructured and informal textual commentary. Cricket commentary often includes colloquial lan- guage, ambiguous phrases, and context-dependent expressions, which traditional rule-based Natural Language Processing (NLP) techniques struggle to handle effectively. The solution incorpo- rates innovative strategies to address sense disambiguation by intentionally removing clear event-indicative keywords, thereby simulating real-world complexity. By tackling the limitations of rule-based systems such as their over reliance on explicit keywords and inability to handle ambiguous contexts, the system achieves robust event classification for runs, outs, extras, and dots game actions. Designed to seamlessly integrate with real- time sports tracking applications, the decoder enables dynamic updates and API calls. By balancing computational efficiency with classification accuracy, this project not only addresses the technical challenges of decoding live commentary but also supports the growing role of data and analysis in the modern cricket ecosystem. To overcome these challenges, the proposed system employs advanced machine learning methods, including LSTM, GRU, SVM, Logistic classifiers, and boosting techniques like LightGBM.


---
# Financial Technology (FinTech), Artificial Intelligence (AI), ICT, Institutional Quality, and Financial Sector Development: International Evidence

## 金融技术 (FinTech) 、人工智能 (AI) 、ICT、制度质量和金融部门发展: 国际证据

Link: https://www.researchsquare.com/article/rs-5712330/latest

In this digital era, the rapid advancement of financial technology, artificial intelligence, and information and communication technology is significantly transforming the financial ecosystem. Given this paradigm shift, understanding how these factors and strong institutional quality influence financial sector development is crucial. Therefore, the ultimate objective of this study is to explore the relationship between financial technology, artificial intelligence, information and communication technology, institutional quality, and financial sector development across 30 countries from 2016 to 2023. The study applied the system generalized method of moments estimation technique, and the regression results show that financial technology, artificial intelligence, information and communication technology, and institutional quality positively and significantly influence financial sector development, with each variable contributing to an improved financial sector in terms of access, depth, efficiency, and stability. Furthermore, the interaction between financial technology and artificial intelligence, information and communication technology, and institutional quality demonstrate a significant positive impact on financial sector development, highlighting the role of their combined contributions. Additionally, the interaction of artificial intelligence with information and communication technology and institutional quality reveals a strong positive relationship, underscoring the critical role of advanced technological infrastructure and governance quality in fostering financial sector development. Based on the findings, the researcher suggested that stakeholders invest significantly in fintech startups and machine learning model developers by establishing innovation hubs. Expanding ICT infrastructure and strengthening the regulatory framework are equally essential to further improving the financial sector's development.


---
# Anomaly Detection in Quadcopter Systems Using AI and Vibration Signal Processing

## 使用AI和振动信号处理在四轴飞行器系统中进行异常检测

Link: https://www.researchsquare.com/article/rs-5695145/latest

This study examines the implementation of artificial intelligence (AI) techniques for anomaly identification in quadcopters, concentrating on vibration data obtained from the ADXL345 accelerometer. The ESP32 Wi-Fi module analyses and transmits these signals, delivering high-resolution data appropriate for real-time monitoring. Diverse AI methodologies, encompassing supervised learning algorithms, are utilised to analyse the data and identify anomalies. Feature extraction techniques, including standard deviation (std), variance, and mean absolute deviation (MAD), are employed to augment the predictive capability of the data. Classifiers such as Random Forest and Support Vector Machine(SVM) are utilised on the retrieved features, with a maximum accuracy of 97.78%. The amalgamation of AI and IoT technologies facilitates an efficient and effective approach to enhance defect identification and problem diagnostics in unmanned aerial vehicles (UAVs), presenting substantial promise for augmenting the dependability and safety of these systems.


---
# Prediction for typical respiratory diseases development under main meteorological factors based on lag effect and neural network modeling

## 基于滞后效应和神经网络建模的主要气象因素下典型呼吸系统疾病发展预测

Link: https://www.researchsquare.com/article/rs-5643142/latest

Respiratory diseases affect human health significantly, and understanding their impact factors and future development is conducive to helping improve effective prevention and treatment. Especially with global climate change, the impact of meteorological factors on respiratory diseases is non-negligible. This paper used 2023&amp;ndash;2024 data of the number of respiratory disease visits and incidence in Haidian District of Beijing, combined with meteorological data for the same period, to conduct correlation analysis using Origin 2021, to develop a BP neural network time series prediction model using MATLAB R2022a. The results showed that the meteorological factors had a significant effect on the occurrence of respiratory diseases. Temperature had the greatest effect on the number of respiratory disease visits, the number of A and B flu-positive individuals and the number of COVID-19 positive individuals, with the high-risk temperature ranges of: -4&amp;thinsp;~&amp;thinsp;16&amp;deg;C and &amp;gt;&amp;thinsp;23&amp;deg;C, -3&amp;thinsp;~&amp;thinsp;16&amp;deg;C, 2&amp;thinsp;~&amp;thinsp;16&amp;deg;C, and the peaks of the risks of 6&amp;deg;C, 5&amp;deg;C, and 8&amp;deg;C, respectively. The lag effect of temperature on the number of visits and COVID-19 positives was not significant, but had a significant effect on the number of A and B positives, with high temperatures being the most significant. The lag effect of low air pressure had a significant effect on the number of A&amp;amp;B positives and persisted for 7 days, since low air pressure affects the supply of oxygen in the body and increases the susceptibility to respiratory illnesses. Lower air humidity had a significant lag effect on the number of visits and COVID-19 positives, but not on the number of A and B flu-positives. The daily average relative humidity ranges with the lowest risk for the number of visits, A and B flu positives and COVID-19 positives were 40&amp;ndash;80%, 40&amp;ndash;72% and 36&amp;ndash;79%, respectively. The modeling determination coefficients of the BP neural network-based time-series prediction for the total number of visits, A and B flu-positive, and COVID-19 positive were 0.94, 0.98, and 0.92, respectively, and the validation determination coefficients were 0.88, 0.69, and 0.59, respectively, with the modeling root mean square error RMSEs of 15.34, 3.34, and 2.07, respectively, and the validation root mean square error RMSEs of 13.37, 6.21 and 2.88, respectively. The proposed model achieves accurate estimation of future visits and positive rate, especially effective in predicting the total visits. This study can provide technical support for the scientific prevention and control of respiratory diseases and scientific evidence for the development of measures related to meteorological-based medical forecasting.


---
# Machine tool model correction assisted by dynamic evolution sequence

## 动态演化序列辅助的机床模型修正

Link: https://www.researchsquare.com/article/rs-5614276/latest

In the simulation analysis of large-scale industrial instruments such as machine tools, in order to ensure simulation accuracy, model parameter correction is necessary. This research presents a machine tool model correction method assisted by dynamic evolution sequence (DES). The method first introduces a dynamic evolution method to generate a uniformly distributed sequence, replacing the traditional sequence used in Kriging surrogate models, and constructing a more accurate Kriging surrogate model for machine tools. Additionally, incorporating a dynamic evolution sequence instead of a random sequence improves the search space coverage of the Heterogeneous Comprehensive Learning Particle Swarm Optimization (HCLPSO) algorithm. The results of numerical examples demonstrate that the finite element model, corrected using the proposed method, accurately predicts the true displacement responses of the machine tool. This method offers a new solution for addressing large-scale machine tool static model correction problems.


---
# Revolutionizing Disease Diagnosis with Large Language Models: A Systematic Review

## 使用大语言模型革新疾病诊断: 系统综述

Link: https://www.researchsquare.com/article/rs-5704278/latest

Purpose: The underlining success of large language models (LLMs) in general language understanding has revolutionized many domains, including healthcare. This systematic review aims to explore the application of LLM in disease diagnosis, acknowledging its success in reducing diagnosis delays in areas with limited health resources or when health costs are not affordable.
Methods: We systematically reviewed the literature on LLMs used for disease diagnosis tasks, such as differential diagnosis, question-answering, and report generation, from January 2014 to September 2024. The included studies are categorized based on input data types (text, images, others), learning approaches (zero-shot, few-shot, retrieval-augmented generation, fine-tuning, etc.), and diagnostic contexts.
Results: We observe that LLMs used for disease diagnosis primarily employ zero-shot learning, prompting, and retrieval-augmented generation techniques. While some LLMs are explicitly fine-tuned for this purpose, only a few have been trained from scratch. Most LLMs are trained using data from the Internet and research publications. Despite this, LLM models have successfully diagnosed many common chronic diseases and addressed some rare and uncommon diseases with reasonable accuracy. Despite these promising trends and successes, concerns about the potential for misdiagnosis persist, particularly with less common and rare diseases.
Conclusion: The use of LLMs in disease diagnosis has a promising future in reducing diagnostic delay and complementing the work of health professionals in resource-constrained environments. The success of LLM in disease diagnosis calls for proper analysis of data from health domains and for encouraging the inclusion of information on otherwise uncommon diseases.


---
# A Federated Weighted Learning Algorithm against Poisoning Attacks

## 一种抗中毒攻击的联合加权学习算法

Link: https://www.researchsquare.com/article/rs-5680571/latest

The emergence of Federated Learning (FL) has provided a promising framework for distributed machine learning, where the probability of privacy leakage is minimized. However, the existing FL protocol is vulnerable to malicious poisoning attacks, thus affecting data privacy. To address this issue, Federated Weighted Learning Algorithm (FWLA) is introduced. In FWLA, the weight of each client is self-adjusted and optimized using asynchronous method and residual testing method during updating process. Each client uploads parameters independently in designed asynchronous training. Experiments show that the proposed framework can achieve at least 97.8% accuracy and at most 3.6% false acceptance rate for the CICIDS2017, UNSW-NB15 and NSL-KDD datasets, which reflects its state-of-the-art performance. Furthermore, when noise data exist in the training dataset, FWLA can also reduce the decline of accuracy, which ensures the robustness of federated learning.


---
# Uncovering Niche Insights in Long-Tail Markets: A Unified LNRE Framework

## 揭示长尾市场中的利基洞察力: 一个统一的LNRE框架

Link: https://www.researchsquare.com/article/rs-5707015/latest

In long-tail markets, analysis predominantly is skewed towards the "head," while the "tail," rich with niche insights, often goes uninvestigated. The tail, however, stores valuable information that can expose the emergent trends while sometimes contradictory to general findings derived from the head. This research highlights that while conventional machine learning algorithms struggle to model rare events due to token sparsity, our model successfully captures these elusive insights. By leveraging the mathematical properties of G-functions and Q-functions, this study integrates their behavior into traditional fabric of machine learning frameworks, which improves rare event modelling. We show that uniform partitioning of data into subintervals facilitates granular analysis, enabling the detection of rare events. The findings highlight how long-tail contributions not only dominate but also grow with specific thresholds, uncovering emergent trends. Additionally, our approach analyzes temporal trends, dynamically tracking their evolution over time. This research highlights the need of integrating LNRE models with partitioning and convergence techniques, offering a robust tool for decoding the hidden value in long-tail markets and empowering businesses to access previously invisible opportunities.


---
# Variational Quantum Kolmogorov-Arnold Network

## 变分量子kolmogorov-arnold网络

Link: https://www.researchsquare.com/article/rs-4504342/latest

We implemented a quantum version of the Kolmogorov-Arnold Network (KAN) on a quantum circuit. It optimizes the weight of each synaptic connection to enhance the overall performance of the neurons. This approach offers a significant boost in efficiency over traditional neural networks, as it can be optimized more accurately and requires only a few neurons to solve complex problems. The KAN is a multi-layer network, similar to a traditional neural network, with each layer represented as a matrix containing parameters and feedback. This structure is linear and mirrors the form of Variational Quantum Algorithms. Thus, we propose the Variational Quantum Kolmogorov-Arnold Network (VQKAN) as a quantum version of the Kolmogorov-Arnold Network. We demonstrated the optimization of VQKAN for fitting the given function in various ways, such as by using ansatzes and comparisons.

