# Spatiotemporal characterization of water diffusion anomalies in saline solutions using machine learning force field

## 使用机器学习力场对盐溶液中的水扩散异常进行时空表征

Link: https://www.science.org/doi/abs/10.1126/sciadv.adp9662?af=R

**Authors:** Ji Woong Yu, Sebin Kim, Jae Hyun Ryu, Won Bo Lee, Tae Jun Yoon

Science Advances, Volume 10, Issue 50, December 2024. <br />


---
# Publisher Correction: Single neuromorphic memristor closely emulates multiple synaptic mechanisms for energy efficient neural networks

## 出版商更正: 单个神经形态忆阻器紧密模拟节能神经网络的多个突触机制

Link: https://www.nature.com/articles/s41467-024-54823-9

**Authors:** Alexandros Emboras

<p>Nature Communications, Published online: 11 December 2024; <a href="https://www.nature.com/articles/s41467-024-54823-9">doi:10.1038/s41467-024-54823-9</a></p>Publisher Correction: Single neuromorphic memristor closely emulates multiple synaptic mechanisms for energy efficient neural networks


---
# [ASAP] A Preliminary Neural Network-Based Composite Method for Accurate Prediction of Enthalpies of Formation

## [ASAP] 一种基于神经网络的精确预测生成焓的初步复合方法

Link: http://dx.doi.org/10.1021/acs.jctc.4c01351

**Authors:** Gabriel César Pereira and Rogério Custodio

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acs.jctc.4c01351/asset/images/medium/ct4c01351_0004.gif" /></p><div><cite>Journal of Chemical Theory and Computation</cite></div><div>DOI: 10.1021/acs.jctc.4c01351</div>


---
# Digital-analog quantum convolutional neural networks for image classification

## 用于图像分类的数模量子卷积神经网络

Link: http://link.aps.org/doi/10.1103/PhysRevResearch.6.L042060

**Authors:** Anton Simen, Carlos Flores-Garrigos, Narendra N. Hegade, Iraitz Montalban, Yolanda Vives-Gilabert, Eric Michon, Qi Zhang, Enrique Solano, and José D. Martín-Guerrero

Author(s): Anton Simen, Carlos Flores-Garrigos, Narendra N. Hegade, Iraitz Montalban, Yolanda Vives-Gilabert, Eric Michon, Qi Zhang, Enrique Solano, and José D. Martín-Guerrero<br /><p>An approach to image classification by combining digital-analog quantum kernels with convolutional neural networks is presented. This hybrid model leverages quantum entanglement dynamics to enhance feature detection in medical images, achieving comparable or superior performance to classical counterparts with significantly fewer parameters. Applications include breast cancer and pneumonia diagnosis using realistic medical datasets.</p><img height="" src="http://cdn.journals.aps.org/journals/PRRESEARCH/key_images/10.1103/PhysRevResearch.6.L042060.png" width="200" /><br />[Phys. Rev. Research 6, L042060] Published Wed Dec 11, 2024


---
# Long‐Term Used Continuous Blood Pressure Monitoring via Personalized Object Transfer Learning Architecture Enhanced Triboelectric Pulse Sensors

## 通过个性化对象转移学习架构增强型摩擦电脉冲传感器进行长期连续血压监测

Link: https://onlinelibrary.wiley.com/doi/10.1002/adfm.202418318?af=R

**Authors:** Chuanjie Yao, 
Suhang Liu, 
Xingyuan Xu, 
Peng Yun, 
Tao Zhang, 
Tiancheng Sun, 
Mengyi He, 
Baoming Liang, 
Minghao Li, 
Shuang Huang, 
Yan Li, 
Yunuo Wang, 
Hui‐jiuan Chen, 
Xi Xie

Advanced Functional Materials, EarlyView.


---
# A Cluster‐Based Deep Learning Model Perceiving Series Correlation for Accurate Prediction of Phonon Spectrum

## 基于聚类的感知序列相关性的深度学习模型，用于精确预测声子谱

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202406183?af=R

**Authors:** Chao Liang, 
Yilimiranmu Rouzhahong, 
Shunwei Yao, 
Junhao Liang, 
Chunlin Yu, 
Biao Wang, 
Huashan Li

Advanced Science, Volume 11, Issue 46, December 11, 2024.


---
# A Sliding‐Kernel Computation‐In‐Memory Architecture for Convolutional Neural Network

## 卷积神经网络的滑动内核计算内存架构

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202407440?af=R

**Authors:** Yushen Hu, 
Xinying Xie, 
Tengteng Lei, 
Runxiao Shi, 
Man Wong

Advanced Science, Volume 11, Issue 46, December 11, 2024.


---
# Reconstructing Molecular Networks by Causal Diffusion Do‐Calculus Analysis with Deep Learning

## 基于深度学习的因果扩散微积分分析重建分子网络

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202409170?af=R

**Authors:** Jiachen Wang, 
Yuelei Zhang, 
Luonan Chen, 
Xiaoping Liu

Advanced Science, Volume 11, Issue 46, December 11, 2024.


---
# Electrochemical Dissolution: Paths in High-Entropy Alloy Composition Space

## 电化学溶解: 高熵合金成分空间中的路径

Link: https://dx.doi.org/10.26434/chemrxiv-2024-4vt27?rft_dat=source%3Ddrss

**Authors:** Jan, Rossmeisl

The stability of a nanoparticle catalyst during electrochemical reaction is crucial for its application. Despite increasing interest in multi-metallic alloy nanoparticles, such as high-entropy alloys (HEAs), for electrocatalysis and emerging models for their catalytic activity, there is limited work on frameworks that can predict the metastability of these alloys under reaction conditions, including stability against electrochemical surface dissolution. Incorporating electrochemical stability in multi-objective optimization would advance HEAs as a catalyst discovery platform. To address the knowledge gap on electrochemical stability, we propose a methodology for simulating the dissolution of n-element alloy nanoparticles comprised of density functional theory and machine learning regression to calculate the dissolution potentials of the surface atoms. We demonstrate the methodology for the Ag-Au-Cu-Ir-Pd-Pt-Rh-Ru HEA system with the conditions of the oxygen reduction reaction. We investigated trends in stability against dissolution through a compositional grid search for the octo-metallic composition space, uncovering two alloying strategies to increase stability against electrochemical surface dissolution: Alloying with a noble metal or a metal with high relative surface energy. In the simulations, stabilization ensues from forming a protective surface layer, and consequently, the dissolution of persistent alloyed nanoparticles results in core-shell structures. The model enables tracing the evolution of the surface and dissolved composition during electrochemical dissolution, forming paths of dissolution and revealing unretainable surface compositions.


---
# Effectiveness of M-learning and Gamification in Undergraduate Medical Education in Southern Coastal Karnataka

## 卡纳塔克邦南部沿海地区的M学习和游戏化在本科医学教育中的有效性

Link: https://www.researchsquare.com/article/rs-5265361/latest

Mobile(M)- Learning and Gamification have been shown to be effective in teaching. Quizizz is a platform which enables the use of these techniques. This study was done to assess the effectiveness and feasibility of the M-learning application Quizizz in undergraduate medical education. A quasi-experimental study was done among the medical students at a private medical college. Pre-test was conducted in the quiz mode of Quizizz, and integrated class and post-test was conducted in the lesson mode of Quizizz. Feedback was taken in the 5-point Likert scale regarding the Quizizz platform using a self-administered Google Form. The anonymised scored from the test and the feedback were analysed to meet the study objectives. Of the 91 students who answered both the pre-test and post-test, the mean score increased in the post-test compared to the pre-test and the mean time taken also reduced. The feedback received from the students also suggested that the platform was easy to use and increased the attentiveness of the students. The friendly competition made the learning fun and increased participation of the students. Hence, M-learning and Gamification are viable and beneficial ways to improve information acquisition in medical education


---
# Uncovering XSS Polyglot Payload Detection with Machine Learning: Advancing Web Security Against Complex Threats&nbsp;

## 使用机器学习揭示XSS多语言有效负载检测: 针对复杂威胁提高Web安全性

Link: https://www.researchsquare.com/article/rs-5564100/latest

The XSS Polyglot (Cross-Site Scripting) payload remains a serious threat to application security, hence the need for innovative ways for detection and mitigation. XSS polyglot payloads are snippets of code with the ability to span many web contexts at the same time. They are hard to identify due to their intelligent syntax and encoding technique, which they can easily use to spoof conventional scanners with traditional pattern matching formats. Despite their notable threat, research on XSS polyglot payloads remains notably limited, highlighting the need for further investigation and the development of more advanced detection methods. This research paper delves into techniques for detecting XSS polyglot payloads through the lens of machine learning. Using an overarching database, which constitutes three types of datasets &amp;mdash; XSS Polyglot payloads, Conventional XSS payloads, and benign data appended with textual content &amp;mdash; to study the effectiveness of diverse machine learning models in determining malicious and non-malicious content. This study seeks to gather the results of different ML algorithms on malicious and non-malicious data detection. This paper addresses the challenges such as data imbalance and ethical considerations and follows responsible disclosure practices. Experimental results provide the significance of the proposed techniques and enhance the application security against evolving XSS threats. This research contributes to the web security community by providing knowledge and advanced strategies for XSS polyglot payload detection with the support of machine learning methodologies.


---
# Explainable AI in brain tumor diagnosis: A critical review of ML and DL techniques

## 脑肿瘤诊断中的可解释AI: ML和DL技术的批判性回顾

Link: https://www.researchsquare.com/article/rs-5580195/latest

Brain tumors, caused by abnormal tissue growth within the brain, can severely disrupt brain functions and pose significant health risks. As the tumor progresses to higher stages, the patient's prognosis and survival decrease, resulting in a high mortality rate. With the advancements in medical imaging, especially the use of MRI, AI approaches have emerged as strong tools for detecting, segmenting, and classifying brain cancers. CNN and hybrid models, such as Vision Transformers (ViTs), have produced promising findings in this area. Although AI models exhibit high accuracy, they suffer from a lack of transparency and interpretability, paving the way for the development of eXplainable AI (XAI) methods in brain disease diagnosis. This paper investigates the utilization of machine learning, deep learning, and explainable AI (XAI) in brain tumor detection, segmentation, and classification. In this study, we have utilized the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist and diagram. Peer-reviewed articles from PubMed, IEEE Explore, ScienceDirect, Google Scholar, Springer, and Wilay online libraries were searched, and only those papers were selected that were published in Scopus, SCIE, and ESCI-indexed journals. We have identified the 20 research papers published between 2020 and 2024 that used machine learning, deep learning and explainable AI to detect, segment, and classify the brain tumor. This review provides a comprehensive survey the of explainable artificial intelligence (XAI) in biomedical imaging, focusing on its role in the detection, segmentation and classification of brain tumors. It examines various machine learning, deep learning and XAI techniques, addresses current challenges, and suggests future directions. The objective is to provide clinicians, regulators and AI developers with valuable insights to improve the transparency and reliability of these methods in medical diagnostics.


---
# L-type calcium channels regulate decision-making process during fear learning in the zebrafish

## L型钙通道调节斑马鱼恐惧学习中的决策过程

Link: https://www.researchsquare.com/article/rs-5614626/latest

L-type calcium channels (LTCCs), is a family of the high-voltage activated family of voltage-dependent calcium channel. In the central nervous system, LTCCs play variety of roles including dendritic development, neuronal survival, synaptic plasticity, cognition, and behaviour. However, the role of LTCCs in cognitive function such as learning and memory are controversial. LTCCs and their encoding genes (CACNA1s) are evolutionarily conserved, but the role of LTCCs in cognitive function in non-mammalian species remains obscure. Hence, in this study, we examined the effect of a LTCC agonist, (&amp;plusmn;)-Bay K8644 on fear-associated learning using the conditioned place avoidance paradigm in adult zebrafish. Intraperitoneal administration of Bay K8644 did not diminish conditioned avoidance learning, while the fish treated with Bay K8644 spend a longer duration in the non-conditioned compartment as compared to control. This suggests that LTCCs could a crucial role in the decision-making process, rather than fear consolidation or fear retrieval in zebrafish.


---
# Prediction model of intradialytic hypertension in hemodialysis patients based on machine learning

## 基于机器学习的血液透析患者透析中高血压预测模型

Link: https://www.researchsquare.com/article/rs-5355171/latest

Objective: The global prevalence of chronic kidney disease (CKD) is escalating, particularly for end-stage renal disease (ESRD), which has led to greater dependence on hemodialysis. This upswing exerts substantial strains on patient families and healthcare systems. A critical concern during hemodialysis is the emergence of Intradialytic Hypertension (IDH), which carries significant health risks. Delayed management of IDH can lead to severe cardiovascular and cerebrovascular complications. The aim of our study was to harness machine learning methodologies to develop a predictive algorithm for IDH, utilizing patient demographic data and dialysis records. Our model equips medical professionals with a robust predictive tool that enhances the detection of patients more susceptible to hypertension during dialysis, thereby advancing the pre-screening for individuals considered at increased risk.
Methods: This study developed two predictive models for IDH, named IDH-1 and IDH-2, by employing a suite of machine learning algorithms, namely the Light Gradient Boosting Machine (LGBM), Support Vector Machine (SVM), and TabNet. IDH-1 is specifically engineered to provide immediate predictions of IDH risk prior to a hemodialysis session, utilizing records from the imminent pre-dialysis period combined with historical average dialysis data, whereas IDH-2 employs records from the current dialysis session along with historical average data to forecast the risk of IDH for the next hemodialysis session. The performance evaluation of the models utilized key metrics, including Area Under the Curve (AUC), recall, accuracy, and F1 score, which are crucial in determining the models' precision and reliability.
Results: This research analyzed data from 1,405 patients at Shenzhen People's Hospital over 185,125 dialysis sessions and 416 patients at Fuding City Hospital across 71,427 sessions. Data from Shenzhen served as the training set, while Fuding data comprised the test set, supporting the model development and validation process. In the IDH-1 models, the LGBM outperformed SVM and TabNet with an AUC of 0.87. LGBM achieved a recall of 0.73, an accuracy of 0.243, and an F1 score of 0.36. For IDH-2 models, LGBM maintained superior performance, with an AUC of 0.75, a recall of 0.56, an accuracy of 0.17, and an F1 score of 0.26. Predictor importance analysis for the LGBM algorithm identified pre-dialysis diastolic pressures, historical mean arterial pressure, and historical average IDH episodes as significant for the IDH-1 model. For the IDH-2 model, historical average IDH episodes and post-dialysis systolic pressures were most predictive.
Conclusions: This study's results highlight the significant potential of machine learning techniques in leveraging demographic and dialysis data to predict IDH in patients undergoing hemodialysis.


---
# Unexpectedly Benign Pulmonary Nodules Using Machine Learning

## 使用机器学习意外良性肺结节

Link: https://www.researchsquare.com/article/rs-5361749/latest

Background: The widespread application of computed tomography (CT) for pulmonary disease screening has led to an increased detection of pulmonary nodules. However, this has also resulted in a high false-positive rate for suspected malignancies that ultimately prove to be benign. It is crucial to explore the clinical and imaging characteristics of these patients to avoid unnecessary major pulmonary resections. This study aims to evaluate the characteristics of surgically resected benign nodules that were initially presumed to be lung cancers based on lung CT scans.
Materials and Methods: This retrospective study analyzed 203 cases of benign lung nodules at the First Medical Centre of the Chinese People&rsquo;s Liberation Army (PLA) General Hospital from January 2017 to June 2023. Pathological examination following surgical resection confirmed pulmonary granulomatous inflammation in these cases. The study cohort was divided into two groups: 86 patients with benign nodules and 117 with malignant nodules, all diagnosed based on imaging features. Given the overlapping imaging features of benign and malignant nodules, the clinical and imaging characteristics of both groups were compared to reduce the incidence of unnecessary surgeries. Various machine learning models, including Random Forest, SVM linear, SVM nonlinear, Logistic Regression, XGBoost, and k-Nearest Neighbor, were constructed. With the optimal model selected based on performance on a validation set, A framework was developed to identify personalized risk factors using a feature importance ranking algorithm.
Results: Analysis of data from 203 patients revealed significant differences in maximum lesion size (pathological diagnosis), nodule density, boundary, calcification, satellite nodules, vascular aggregation sign, vacuole sign, spiculation sign, lobulation sign, pleural indentation sign, and nodule location (p&amp;lt;0.05). The SVMlinear model, which achieved the highest AUC (0.867), was selected for the final predictive model.Using recursive feature elimination method and manual feature selection, the feature of lesion size, lobulation sign, vacuole sing and enlarged lymph nodes have been screened in predicting and distinguishing the nature of nodules through imaging.
Conclusion:Benign pulmonary nodules that are unexpectedly resected often present with features typically associated with malignancy, such as larger volumes, lobulation, vacuole signs, and enlarged lymph nodes. This study highlights the importance of accurately distinguishing between benign and malignant nodules to minimize unnecessary surgical interventions.


---
# A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics

## 用于学习蛋白质-配体结合动力学的多粒度对称微分方程模型

Link: https://www.researchsquare.com/article/rs-5538361/latest

In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by utilizing machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations in protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) the BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory under Newtonian mechanics. For the experiment, we design ten single-trajectory and three multi-trajectory binding simulation tasks. We demonstrate the efficiency and effectiveness of NeuralMD, achieving over 1K$\times$ speedup compared to standard numerical MD simulations. NeuralMD also outperforms all other ML approaches, achieving up to 15$\times$ reduction in reconstruction error and 70% increase in validity. Additionally, we qualitatively illustrate that the oscillations in the predicted trajectories align more closely with ground-truth dynamics than those of other machine-learning methods. We believe NeuralMD paves the foundation for a new research paradigm in simulating protein-ligand dynamics.


---
# Contrastive Learning of Categories Features Representations for the Recognition of Underwater Target with Shot-few Annotations Samples

## 类别特征表示的对比学习，用于识别带有少量注释样本的水下目标

Link: https://www.researchsquare.com/article/rs-5412897/latest

Underwater acoustic target recognition based on deep learning is complex owing to the shot-few annotation samples, moreover, the imbalance between classes of annotation samples. In this study, a contrast-based semi-supervised network (CBSN) is proposed for accurately recognizing the underwater targets at near-sea areas where a limited number of annotations samples with imbalance are obtained. This algorithm first designs an unsupervised contrast learning network, which uses the features distinction between positive and negative unannotated samples to contrast learning. The significant recognition features of the unannotated samples are extracted adaptively. Secondly, the feature extraction network is chosen in unsupervised networks representing high-dimensional annotations samples' features. Thus, the practical features for recognition in the annotated samples are obtained. Thirdly, contrast learning loss for underwater acoustic signals is designed to improve recognition accuracy. Extensive experiments on multiple supervised networks and semi-supervised networks demonstrate the superiority of the proposed framework showing that it can extract helpful recognition features for shot-few samples using the mutual guidance between annotated and unannotated samples. Further validation of the feature extraction performance shows that the network has excellent recognition of unbalanced shot-few samples.


---
# An Efficient Prediction Based Dynamic Resource Allocation Framework in Quantum Cloud Using Knowledge Based Offline Reinforcement Learning

## 基于知识的离线强化学习的量子云中高效预测动态资源分配框架

Link: https://www.researchsquare.com/article/rs-5125318/latest

Quantum Cloud Computing (QCC) is a practice of setting up the cloud platform for delivering computing assets over the internet via a pay-as-you-go model with the help of Quantum Computing (QC) paradigm. Real-time applications have scrupulous compliance regarding performance requirements due to the low-speed of traditional computers. Estimating cloud data center asset usage is a challenging task due to its dynamic nature. It employs a contemporary model to precisely estimate data center CPU utilization and applies an effective resource controller for optimized resource allocation using quantum computers. The proposed design ensures efficient resource estimation, scaling up or down based on predictions. An efficient dynamic resource controller is crucial to solving the scaling process with quantum computing support. Existing systems use a Reinforcement-Based resource controller with a Markov decision process that decides based on the current state of the environment, leading to long scaling and processing times. Our proposed model, the Prediction-Based Offline Reinforcement Learning (PB-ORL) Model, enhances this by considering historical information for prediction-based decisions. This approach achieves accurate and high-performance prediction, optimizing resource allocation proactively and dynamically. The model is analyzed using a real cloud data set with quantum cloud and machine learning approaches, which reduces latency and bandwidth traffic. Empirical results show that the proposed quantum computer-based machine learning approach outperforms previous methods, achieving 30&amp;ndash;50% improved accuracy in CPU resource utilization and reducing time complexity by 33&amp;ndash;42% in resource allocation.


---
# Ensemble Runoff Forecasting Based on Multiple Machine Learning Methods

## 基于多机器学习方法的集成径流预测

Link: https://www.researchsquare.com/article/rs-5414792/latest

The accuracy of runoff forecasting is influenced by factors, such as the type of prediction model and parameter settings. To account for these uncertainties and leverage the strengths of different runoff forecasting models, in this study, we developed an ensemble forecasting model. It assigned combination weights to each model based on its prediction accuracy, improving the accuracy of short-term runoff forecasts. Using daily runoff data from the Dongqiaoyuan Hydrological Station in the Rongjiang River Basin, China, six runoff forecasting models were established by coupling ensemble empirical mode decomposition (EEMD) and empirical mode decomposition (EMD) with a Backpropagation Neural Network, convolutional neural network, and support vector machine. Two ensemble methods, namely, the optimal weighting method and stacking algorithm, were applied to the EMD- and EEMD-based coupled models, respectively, and their predictive performances were comparatively analyzed. Different data preprocessing methods significantly affected the performances of both the individual and ensemble models. The ensemble models had a considerable reduction in the root mean square error and mean absolute percentage error. The random forest stacking ensemble model showed the highest improvement and prediction accuracy. The model greatly enhances the prediction accuracy of large flows in the Rongjiang River Basin, meeting the needs for short-term forecasting. It can effectively support runoff prediction during extreme environmental changes in the river basin. Additionally, it serves as a valuable reference for enhancing ensemble prediction outcomes in runoff forecasting.


---
# Classically studied coherent structures only paint a partial picture of wall-bounded turbulence

## 经典研究的相干结构仅描绘了壁界湍流的部分图片

Link: https://www.researchsquare.com/article/rs-5587182/latest

For the last 140 years, the mechanisms of transport and dissipation of energy
in a turbulent flow have not been completely understood due to the complexity
of this phenomenon. The dissipation of energy due to turbulence is significative,
and understanding turbulence physics is crucial for fighting the present climate
emergency. Previous research has focused on analyzing the so-called coherent
structures of the flow (Q events, streaks, and vortices), which are regions of high
turbulence transport, high/low streamwise fluctuation, and rotation, respectively.
However, the connection between these classically studied structures and the
flow development is still uncertain. In a previous analysis, the importance of the
different Q events was quantified through a data-driven methodology, showing
that the calculated importance did not perfectly agree with the definition of the
structures. To fill this gap, here we show a data-driven methodology for objectively
identifying high-importance regions in a turbulent flow. A deep-learning
model is trained to predict a future state of a turbulent channel flow and the
gradient-SHAP explainability algorithm is used to calculate the importance of
each grid point for such a prediction. Finally, high-importance regions are computed
using the SHAP data, analyzing and comparing their characteristics with
those of the other coherent structures. The SHAP analysis provides an objective
way to identify the regions of highest importance in the turbulent flow, which
exhibit different levels of agreement with the classically studied structures.


---
# General intelligent imaging and uncertainty quantification by deterministic diffusion model

## 确定性扩散模型的通用智能成像和不确定性量化

Link: https://www.researchsquare.com/article/rs-5337841/latest

Computational imaging is crucial in many disciplines from autonomous driving to life sciences. However, traditional model-driven and iterative methods consume large computational power and lack scalability for imaging. Deep learning (DL) is effective in processing local-to-local patterns, but it struggles with handling universal global-to-local (nonlocal) patterns under current frameworks. To bridge this gap, we propose a novel DL framework that employs a progressive denoising strategy, named the deterministic diffusion model (DDM), to facilitate general computational imaging at a low cost. We experimentally demonstrate the efficient and faithful image reconstruction capabilities of DDM from nonlocal patterns, such as speckles from multimode fiber and intensity patterns of second harmonic generation, surpassing the capability of previous state-of-the-art DL algorithms. By embedding Bayesian inference into DDM, we establish a theoretical framework and provide experimental proof of its uncertainty quantification. This advancement ensures the predictive reliability of DDM, avoiding misjudgment in high-stakes scenarios. This versatile and integrable DDM framework can readily extend and improve the efficacy of existing DL-based imaging applications.


---
# Cross-Domain Tuple and Random Collision GuidedApproach for Creative Requirement GenerationUsing LLM

## 使用LLM进行创意需求生成的跨域元组和随机碰撞指南方法

Link: https://www.researchsquare.com/article/rs-5438398/latest

In software engineering, creative requirements are unique features detailed in software specifications. Generating these requirements is both crucial and challenging within the field of software requirements engineering. Manual methods, which rely on limited human experience, are often time-consuming and unpredictable. Current machine learning solutions typically offer only combinatorial creation mechanisms and lack objective standards for evaluating creativity. This paper presents a novel approach for automatically generating creative software requirements using large language models (LLM). Our method utilizes cross-domain tuple random collision, where innovative requirements are produced by inputting randomly recombined and preprocessed subject-verb-object (SVO) tuples into a fine-tuned GPT-2 model. We provide a detailed discussion of strategies for recombining SVO tuples from various domains and introduce techniques to enhance creativity. To evaluate the creativity of the generated requirements, we establish the GRUEN Integrated Creativity (GIC) evaluation standard by incorporating the GRUEN model. Experimental studies across three software domains show that this fully automated approach consistently generates creative requirements. Additionally, comparisons with state-of-the-art methods and ChatGPT 4.0 highlight the unique advantages of our approach.


---
# Predictive Modeling of Biodegradation Pathways Using Transformer Architectures

## 使用变压器架构对生物降解途径进行预测建模

Link: https://www.researchsquare.com/article/rs-5200860/latest

In recent years, the integration of machine learning techniques into chemical reaction product prediction has opened new avenues for understanding and predicting the behaviour of chemical substances. The necessity for such predictive methods stems from the growing regulatory and social awareness of the environmental consequences associated with the persistence and accumulation of chemical residues. Traditional biodegradation prediction methods rely on expert knowledge to perform predictions. However, creating this expert knowledge is becoming increasingly prohibitive due to the complexity and diversity of newer datasets, leaving existing methods unable to perform predictions on these datasets. We formulate the product prediction problem as a sequence-to-sequence generation task and take inspiration from natural language processing and other reaction prediction tasks. In doing so, we reduce the need for the expensive manual creation of expert-based rules.

Scientific Contribution We contribute the first study of the transformer's ability to predict biodegradation reactions. Our proposed method can more accurately and efficiently predict biodegradation reactions on more compounds than existing methods. We also contribute a framework for evaluating transformer product prediction methods that can better illustrate the method's performance and is more suitable for comparison to other methods.

