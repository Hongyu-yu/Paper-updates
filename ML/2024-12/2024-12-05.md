# Particle research gets closer to answering why we're here: Physicists outline next 10 years of neutrino research

## 粒子研究更接近回答我们为什么在这里: 物理学家概述下一个10年的中微子研究

Link: https://phys.org/news/2024-12-particle-closer-physicists-outline-years.html

Physicists soon will be closer than ever to answering fundamental questions about the origins of the universe by learning more about its tiniest particles.


---
# Towards a personalized AI assistant to learn machine learning

## 走向学习机器学习的个性化AI助手

Link: https://www.nature.com/articles/s42256-024-00953-0

<p>Nature Machine Intelligence, Published online: 05 December 2024; <a href="https://www.nature.com/articles/s42256-024-00953-0">doi:10.1038/s42256-024-00953-0</a></p>Towards a personalized AI assistant to learn machine learning


---
# Memetic robots

## 模因机器人

Link: https://www.nature.com/articles/s42256-024-00959-8

<p>Nature Machine Intelligence, Published online: 05 December 2024; <a href="https://www.nature.com/articles/s42256-024-00959-8">doi:10.1038/s42256-024-00959-8</a></p>Social learning is a powerful strategy of adaptation in nature. An interactive rat-like robot that engages in imitation learning with a freely behaving rat opens a way to study social behaviours.


---
# Modulating emotional states of rats through a rat-like robot with learned interaction patterns

## 通过具有学习的交互模式的类似大鼠的机器人来调节大鼠的情绪状态

Link: https://www.nature.com/articles/s42256-024-00939-y

<p>Nature Machine Intelligence, Published online: 05 December 2024; <a href="https://www.nature.com/articles/s42256-024-00939-y">doi:10.1038/s42256-024-00939-y</a></p>Interactive robots can be used to study animal social behaviour. Imitation learning can be used to enable a rat-like robot to learn subtle templates of social behaviour, demonstrating that it can modulate the emotional states of rats through varied interaction patterns.


---
# Nanobody–antigen interaction prediction with ensemble deep learning and prompt-based protein language models

## 基于集成深度学习和基于提示的蛋白质语言模型的纳米抗体-抗原相互作用预测

Link: https://www.nature.com/articles/s42256-024-00940-5

<p>Nature Machine Intelligence, Published online: 05 December 2024; <a href="https://www.nature.com/articles/s42256-024-00940-5">doi:10.1038/s42256-024-00940-5</a></p>Predicting nanobody–antigen interactions is crucial for advancing nanobody development in drug discovery, but it remains a challenging task. Deng et al. propose DeepNano to enhance the prediction of nanobody–antigen interactions, facilitating virtual screening of target nanobodies.


---
# <i>Tbx1</i> haploinsufficiency leads to local skull deformity, paraflocculus and flocculus dysplasia, and motor-learning deficit in 22q11.2 deletion syndrome

## &lt;i&gt;Tbx1&lt;/i&gt; 单倍体不足导致22 q11.2缺失综合征的局部颅骨畸形，旁小叶和小叶发育不良以及运动学习缺陷

Link: https://www.nature.com/articles/s41467-024-54837-3

<p>Nature Communications, Published online: 05 December 2024; <a href="https://www.nature.com/articles/s41467-024-54837-3">doi:10.1038/s41467-024-54837-3</a></p>Neurodevelopmental disorders normally arise from intrinsic brain abnormality. Here the authors show that a motor-learning deficit in 22q11 deletion syndrome may arise from improper development of the skull structure housing a part of the cerebellum.


---
# Hybrid data-driven and physics-informed regularized learning of cyclic plasticity with neural networks

## 使用神经网络对循环可塑性进行混合数据驱动和物理通知的正则化学习

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad95da

An extendable, efficient and explainable Machine Learning approach is proposed to represent cyclic plasticity and replace conventional material models based on the Radial Return Mapping algorithm. High accuracy and stability by means of a limited amount of training data is achieved by implementing physics-informed regularizations and the back stress information. The off-loading of the neural network (NN) is applied to the maximal extent. The proposed model architecture is simpler and more efficient compared to existing solutions from the literature using approximately only half the amount of NN parameters, while representing a complete three-dimensional material model. The validation of the approach is carried out by means of results obtained with the Armstrong–Frederick kinematic hardening model. The mean squared error is assumed as the loss function which stipulates several restrictions: deviatoric character of internal variables, compliance with the flow rule, the differentiation of elastic and plastic steps and the associativity of the flow rule. The latter, however, has a minor impact on the accuracy, which implies the generalizability of the model for a broad spectrum of evolution laws for internal variables. Numerical tests simulating several load cases are presented in detail. The validation shows cyclic stability and deviations in normal directions of less than 2% at peak values which is comparable to the order of measurement inaccuracies.


---
# Exploring spatial reasoning performances of CNN on linear layout dataset

## 线性布局数据集上CNN的空间推理性能研究

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad9706

Spatial reasoning, a fundamental aspect of human intelligence, is essential for machine learning models to understand and interpret object relationships. It is crucial for numerous real-world applications, ranging from autonomous navigation to urban planning. The lack of comprehensive datasets limits the development and evaluation of models that can effectively handle spatial reasoning tasks. Existing datasets often contain complex spatial reasoning problems with overlapping spatial relationships, making it challenging to diagnose specific aspects that a model struggles with. We address this gap by introducing a new dataset of linear layouts. This dataset is systematically designed to exhibit a range of spatial relations and complexity levels. Analyzing spatial reasoning through linear layout generation offers a more structured and manageable approach to understanding how models learn and interpret spatial relationships. Linear layout generation has broad applicability and is of fundamental importance in design and optimization. To benchmark dataset, we develop LinLayCNN, a generic data-driven method that applies shallow, one-dimensional convolutional neural network (CNN), to generate linear layouts in an iterative process. Experimental results reveal that LinLayCNN can effectively solve fundamental spatial challenges even with the relatively small size of the training set. It is capable of precise object placement, making it a robust tool for linear layout generation. Current layout generation methods focus on domain-specific solutions and often fail to maintain the precision needed for technical domains, such as accurate sizing, and object counting. They also require a substantial amount of data to function effectively. LinLayCNN overcame these issues. This study further clarifies CNNs’ capabilities in spatial reasoning, highlight their potential to advance the field of layout generation. As a result, our approach establishes a clear benchmark for evaluating spatial reasoning and aids in development of models that can more effectively understand and reason about space.


---
# Learning constitutive relations from experiments: 1. PDE constrained optimization

## 从实验中学习本构关系: 1.PDE约束优化

Link: https://arxiv.org/abs/2412.02864

arXiv:2412.02864v1 Announce Type: new 
Abstract: We propose a method to accurately and efficiently identify the constitutive behavior of complex materials through full-field observations. We formulate the problem of inferring constitutive relations from experiments as an indirect inverse problem that is constrained by the balance laws. Specifically, we seek to find a constitutive behavior that minimizes the difference between the experimental observation and the corresponding quantities computed with the model, while enforcing the balance laws. We formulate the forward problem as a boundary value problem corresponding to the experiment, and compute the sensitivity of the objective with respect to model using the adjoint method. The resulting method is robust and can be applied to constitutive models with arbitrary complexity. We focus on elasto-viscoplasticity, but the approach can be extended to other settings. In this part one, we formulate the method and demonstrate it using synthetic data on two problems, one quasistatic and the other dynamic.


---
# Machine Learned Potential for High-Throughput Phonon Calculations of Metal-Organic Frameworks

## 用于金属有机框架的高通量声子计算的机器学习潜力

Link: https://arxiv.org/abs/2412.02877

arXiv:2412.02877v1 Announce Type: new 
Abstract: Metal-organic frameworks (MOFs) are highly porous and versatile materials studied extensively for applications such as carbon capture and water harvesting. However, computing phonon-mediated properties in MOFs, like thermal expansion and mechanical stability, remains challenging due to the large number of atoms per unit cell, making traditional Density Functional Theory (DFT) methods impractical for high-throughput screening. Recent advances in machine learning potentials have led to foundation atomistic models, such as MACE-MP-0, that accurately predict equilibrium structures but struggle with phonon properties of MOFs. In this work, we developed a workflow for computing phonons in MOFs within the quasi-harmonic approximation with a fine-tuned MACE model, MACE-MP-MOF0. The model was trained on a curated dataset of 127 representative and diverse MOFs. The fine-tuned MACE-MP-MOF0 improves the accuracy of phonon density of states and corrects the imaginary phonon modes of MACE-MP-0, enabling high-throughput phonon calculations with state-of-the-art precision. The model successfully predicts thermal expansion and bulk moduli in agreement with DFT and experimental data for several well-known MOFs. These results highlight the potential of MACE-MP-MOF0 in guiding MOF design for applications in energy storage and thermoelectrics.


---
# CuXASNet: Rapid and Accurate Prediction of Copper L-edge X-Ray Absorption Spectra Using Machine Learning

## CuXASNet: 使用机器学习快速准确地预测铜L边缘x射线吸收谱

Link: https://arxiv.org/abs/2412.02916

arXiv:2412.02916v1 Announce Type: new 
Abstract: In this work, we have developed CuXASNet, a dense neural network that predicts simulated Cu L-edge X-ray absorption spectra (XAS) from atomic structures. Featurization of the Cu local environment is performed using a component of M3GNet, a graph neural network developed for predicting the potential energy surface. CuXASNet is trained on simulated spectra from FEFF9 at the multiple scattering level of theory, and can predict the L3 and L2 edges for Cu sites to quantitative accuracy. To validate our approach, we compare 14 experimental spectra extracted from the literature with the predictions of CuXASNet. The agreement of CuXASNet with experiments is shown by an average MAE of 0.125 and an average Spearman's correlation coefficient of 0.891, which is comparable to FEFF9's values of 0.131 and 0.898 for the same metrics. As such, CuXASNet can rapidly generate a large number of L-edge XAS spectra at the same accuracy as FEFF9 simulations. This can be used as a drop-in replacement for multiple scattering codes for fast screening of candidate atomic structure models of a measured system. This model establishes a general framework for Cu XAS prediction, and can be extended to more computationally expensive levels of theory and to other transition metal L-edges.


---
# The bcc coating of Lennard-Jones crystal nuclei vanishes with a change of local structure detection algorithm

## Lennard-jones晶核的bcc涂层随着局部结构检测算法的变化而消失

Link: https://arxiv.org/abs/2412.03276

arXiv:2412.03276v1 Announce Type: new 
Abstract: Since the influential work of ten Wolde, Ruiz-Montero, and Frenkel [Phys. Rev. Lett. 75, 2714 (1995)], crystal nucleation from a Lennard-Jones fluid has been regarded as a paradigmatic example of metastable crystal ordering at the surface of a critical nucleus. We apply seven commonly used local structure detection algorithms to characterize crystal nuclei obtained from transition path sampling simulations. The polymorph composition of these nuclei varies significantly depending on the algorithm used. Our results indicate that one should be very careful when characterizing the local structure near solid-solid and solid-fluid interfaces. Particles near such interfaces exhibit a local structure distinct from that of bulk fluid or bulk crystal phases. We argue that incorporating outlier detection into the local structure detection method is beneficial, leading to greater confidence in the classification results. Interestingly, the bcc coating nearly disappears when adopting a machine learning method with outlier detection.


---
# Dielectric tensor of perovskite oxides at finite temperature using equivariant graph neural network potentials

## 使用等变图神经网络电势在有限温度下钙钛矿氧化物的介电张量

Link: https://arxiv.org/abs/2412.03541

arXiv:2412.03541v1 Announce Type: new 
Abstract: Atomistic simulations of properties of materials at finite temperatures are computationally demanding and require models that are more efficient than the ab initio approaches. Machine learning (ML) and artificial intelligence (AI) address this issue by enabling accurate models with close to ab initio accuracy. Here, we demonstrate the utility of ML models in capturing properties of realistic materials by performing finite temperature molecular dynamics simulations of perovskite oxides using a force field based on equivariant graph neural networks. The models demonstrate efficient learning from a small training dataset of energies, forces, stresses, and tensors of Born effective charges. We qualitatively capture the temperature dependence of the dielectric tensor and structural phase transitions in calcium titanate.


---
# A deep neural network approach to solve the Dirac equation

## 求解Dirac方程的深度神经网络方法

Link: https://arxiv.org/abs/2412.03090

arXiv:2412.03090v1 Announce Type: cross 
Abstract: We extend the method from [Naito, Naito, and Hashimoto, Phys. Rev. Research 5, 033189 (2023)] to solve the Dirac equation not only for the ground state but also for low-lying excited states using a deep neural network and the unsupervised machine learning technique. The variational method fails because of the Dirac sea, which is avoided by introducing the inverse Hamiltonian method. For low-lying excited states, two methods are proposed, which have different performances and advantages. The validity of this method is verified by the calculations with the Coulomb and Woods-Saxon potentials.


---
# Theoretical Studies on Sodium Storage Mechanism in Hard Carbon Anodes of Sodium-Ion Batteries: Molecular Simulations Based on Machine Learning Force Fields

## 钠离子电池硬碳阳极储钠机理的理论研究 -- 基于机器学习力场的分子模拟

Link: https://arxiv.org/abs/2412.00340

arXiv:2412.00340v3 Announce Type: replace 
Abstract: Sodium-ion batteries (SIBs) have garnered significant attention in recent years as a promising alternative to lithium-ion batteries (LIBs) due to their low cost, abundant sodium resources, and excellent cycling performance. Hard carbon materials, characterized by their high specific capacity, outstanding cycling stability, and low cost, have emerged as potential candidates for SIB anodes. However, the sodium storage mechanism in hard carbon anodes remains highly complex, especially in disordered structures, and is yet to be fully understood. To address this, we employed relative machine learning force fields (MLFFs) in conjunction with multiscale simulation techniques to systematically investigate the sodium storage behavior in hard carbon. By integrating simulations, this study provides a detailed exploration of sodium adsorption, intercalation, and filling mechanisms. High-precision, large-scale simulations reveal the dynamic behavior and distribution patterns of sodium ions in hard carbon. The findings not only deepen our understanding of sodium storage mechanisms in hard carbon anodes, but also offer a theoretical foundation for optimizing future SIB designs, while introducing novel simulation methodologies and technical frameworks to enhance battery performance.


---
# Quantum Delocalization Enables Water Dissociation on Ru(0001)

## 量子离域使Ru(0001) 上的水解离

Link: https://arxiv.org/abs/2412.00484

arXiv:2412.00484v2 Announce Type: replace 
Abstract: We revisit the long-standing question of whether water molecules dissociate on the Ru(0001) surface through nanosecond-scale path-integral molecular dynamics simulations on a sizable supercell. This is made possible through the development of an efficient and reliable machine-learning potential with near first-principles accuracy, overcoming the limitations of previous ab initio studies. We show that the quantum delocalization associated with nuclear quantum effects enables rapid and frequent proton transfers between water molecules, thereby facilitating the water dissociation on Ru(0001). This work provides the direct theoretical evidence of water dissociation on Ru(0001), resolving the enduring issue in surface sciences and offering crucial atomistic insights into water-metal interfaces.


---
# Simplified derivations for high-dimensional convex learning problems

## 高维凸学习问题的简化推导

Link: https://arxiv.org/abs/2412.01110

arXiv:2412.01110v2 Announce Type: replace 
Abstract: Statistical physics provides tools for analyzing high-dimensional problems in machine learning and theoretical neuroscience. These calculations, particularly those using the replica method, often involve lengthy derivations that can obscure physical interpretation. We give concise, non-replica derivations of several key results and highlight their underlying similarities. Specifically, we introduce a cavity approach to analyzing high-dimensional learning problems and apply it to three cases: perceptron classification of points, perceptron classification of manifolds, and kernel ridge regression. These problems share a common structure -- a bipartite system of interacting feature and datum variables -- enabling a unified analysis. For perceptron-capacity problems, we identify a symmetry that allows derivation of correct capacities through a na\"ive method. These results match those obtained through the replica method.


---
# Exploring the energy landscape of aluminas through machine learning interatomic potential

## 通过机器学习原子间潜力探索氧化铝的能源格局

Link: https://arxiv.org/abs/2412.02191

arXiv:2412.02191v2 Announce Type: replace 
Abstract: Aluminum oxide (alumina, Al$_2$O$_3$) exists in various structures and has broad industrial applications. While the crystal structure of $\alpha$-Al$_2$O$_3$ is well-established, those of transitional aluminas remain highly debated. In this study, we propose a universal machine learning interatomic potential (MLIP) for aluminas, trained using the neuroevolution potential (NEP) approach. The dataset is constructed through iterative training and farthest point sampling, ensuring the generation of the most representative configurations for an exhaustive sampling of the potential energy surface. The accuracy and generality of the potential are validated through simulations under a wide range of conditions, including high temperatures and pressures. A phase diagram is presented that includes both transitional aluminas and $\alpha$-Al$_2$O$_3$ based on the NEP. We also successfully extrapolate the phase diagram of aluminas under extreme conditions ([0, 4000] K and [0, 200] GPa ranges of temperature and pressure, respectively), while maintaining high accuracy in describing their properties under more moderate conditions. Furthermore, combined with our developed structure search workflow, the NEP provides an evaluation of existing $\gamma$-Al$_2$O$_3$ structure models. The NEP developed in this work enables highly accurate dynamic simulations of various aluminas on larger scales and longer timescales, while also offering new insights into the study of transitional aluminas structures.


---
# Efficiency of neural quantum states in light of the quantum geometric tensor

## 根据量子几何张量的神经量子态的效率

Link: https://arxiv.org/abs/2402.01565

arXiv:2402.01565v4 Announce Type: replace-cross 
Abstract: Neural quantum state (NQS) ans\"atze have shown promise in variational Monte Carlo algorithms by their theoretical capability of representing any quantum state. However, the reason behind the practical improvement in their performance with an increase in the number of parameters is not fully understood. In this work, we systematically study the efficiency of a shallow neural network to represent the ground states in different phases of the spin-1 bilinear-biquadratic chain, as the number of parameters increases. We train our ansatz by a supervised learning procedure, minimizing the infidelity w.r.t. the exact ground state. We observe that the accuracy of our ansatz improves with the network width in most cases, and eventually saturates. We demonstrate that this can be explained by looking at the spectrum of the quantum geometric tensor (QGT), particularly its rank. By introducing an appropriate indicator, we establish that the QGT rank provides a useful diagnostic for the practical representation power of an NQS ansatz.


---
# A Physics Preserving Neural Network Based Approach for Constitutive Modeling of Isotropic Fibrous Materials

## 基于物理保持神经网络的各向同性纤维材料本构建模方法

Link: https://arxiv.org/abs/2403.13357

arXiv:2403.13357v5 Announce Type: replace-cross 
Abstract: We develop a new neural network architecture that strictly enforces constitutive constraints such as polyconvexity, frame-indifference, and the symmetry of the stress and material stiffness. Additionally, we show that the accuracy of the stress and material stiffness predictions is significantly improved for this neural network by using a Sobolev minimization strategy that includes derivative terms. Using our neural network, we model the constitutive behavior of fibrous-type discrete network material. With Sobolev minimization, we obtain a normalized mean square error of 0.15% for the strain energy density, 0.815% averaged across the components of the stress, and 5.4% averaged across the components of the stiffness tensor. This machine-learned constitutive model was deployed in a finite element simulation of a facet capsular ligament. The displacement fields and stress-strain curves were compared to a multiscale simulation that required running on a GPU-based supercomputer. The new approach maintained upward of 85% accuracy in stress up to 70% strain while reducing the computation cost by orders of magnitude.


---
# A Graph Neural Network Approach to Dispersed Systems

## 离散系统的图神经网络方法

Link: https://arxiv.org/abs/2412.02967

arXiv:2412.02967v1 Announce Type: new 
Abstract: We present a Graph Neural Network (GNN) that accurately simulates a multidisperse suspension of interacting spherical particles. Our machine learning framework is build upon the recent work of Sanchez-Gonzalez et al. ICML, PMLR, 119, 8459-8468 (2020) on graph network simulators, and efficiently learns the intricate dynamics of the interacting particles. Nodes and edges of the GNN correspond to, respectively, the particles with their individual properties/data (e.g., radius, position, velocity) and the pair interactions between the particles (e.g., electrostatics, hydrodynamics). A key contribution of our work is to account for the finite dimensions of the particles and their impact on the system dynamics. We test our GNN against an exemplary case study of a multidisperse mixture of two-dimensional spheres sedimenting under gravity in a liquid and interacting with each other by a Lennard-Jones potential. The present GNN framework offers a fast and accurate method for the theoretical study of complex physical systems such as field-induced behavior of colloidal suspensions and ionic liquids. Our implementation of the GNN is available on GitHub at github.com/rfjd/GNS-DispersedSystems.


---
# Hamiltonian-based neural networks for systems under nonholonomic constraints

## 非完整约束下系统的基于哈密顿量的神经网络

Link: https://arxiv.org/abs/2412.03018

arXiv:2412.03018v1 Announce Type: new 
Abstract: There has been increasing interest in methodologies that incorporate physics priors into neural network architectures to enhance their modeling capabilities. A family of these methodologies that has gained traction are Hamiltonian neural networks (HNN) and their variations. These architectures explicitly encode Hamiltonian mechanics both in their structure and loss function. Although Hamiltonian systems under nonholonomic constraints are in general not Hamiltonian, it is possible to formulate them in pseudo-Hamiltonian form, equipped with a Lie bracket which is almost Poisson. This opens the possibility of using some principles of HNNs in systems under nonholonomic constraints. The goal of the present work is to develop a modified Hamiltonian neural network architecture capable of modeling Hamiltonian systems under holonomic and nonholonomic constraints. A three-network parallel architecture is proposed to simultaneously learn the Hamiltonian of the system, the constraints, and their associated multipliers. A rolling disk and a ball on a spinning table are considered as canonical examples to assess the performance of the proposed Hamiltonian architecture. The experiments are then repeated with a noisy training set to study modeling performance under more realistic conditions.


---
# Optical tweezers with optical vortex based on deep learning

## 基于深度学习的光学涡旋光镊

Link: https://arxiv.org/abs/2412.03137

arXiv:2412.03137v1 Announce Type: new 
Abstract: Optical tweezers (OTs) with structured light expand degrees of freedom of particle manipulation. However, the studies of structured optical tweezers are usually accompanied by complex theoretical models, strict simulation conditions, and uncertain experimental factors, which may bring about high time costs and insufficiently precise results. In this work, we proposed a bidirectional neural network model for the analysis and design of OTs with optical vortices (OVs) as a typical structured light beam. In analyzing optical forces, the network can achieve over 98% accuracy and improve computational efficiency by more than 20 times. In further analyzing particle trajectories, the network can also achieve over 95.5% accuracy. Meanwhile, in OTs with OV-like beams, our network can still predict particle motion behavior with a high accuracy of up to 96.2%. Our network can inversely design optical vortex tweezers on demand with 95.4% accuracy. In addition, the experimental results in OTs with plasmonic vortex can be analyzed by the proposed model, which can be used to achieve arbitrary optical manipulation. Our work demonstrates that the proposed deep learning network can provide an effective algorithmic platform for the analysis and design of OTs, and is expected to promote the application of OTs in biomedicine.


---
# Fast and flexible range-separated models for atomistic machine learning

## 用于原子机器学习的快速灵活的范围分离模型

Link: https://arxiv.org/abs/2412.03281

arXiv:2412.03281v1 Announce Type: new 
Abstract: Most atomistic machine learning (ML) models rely on a locality ansatz, and decompose the energy into a sum of short-ranged, atom-centered contributions. This leads to clear limitations when trying to describe problems that are dominated by long-range physical effects - most notably electrostatics. Many approaches have been proposed to overcome these limitations, but efforts to make them efficient and widely available are hampered by the need to incorporate an ad hoc implementation of methods to treat long-range interactions. We develop a framework aiming to bring some of the established algorithms to evaluate non-bonded interactions - including Ewald summation, classical particle-mesh Ewald (PME), and particle-particle/particle-mesh (P3M) Ewald - into atomistic ML. We provide a reference implementation for PyTorch as well as an experimental one for JAX. Beyond Coulomb and more general long-range potentials, we introduce purified descriptors which disregard the immediate neighborhood of each atom, and are more suitable for general long-ranged ML applications. Our implementations are fast, feature-rich, and modular: They provide an accurate evaluation of physical long-range forces that can be used in the construction of (semi)empirical baseline potentials; they exploit the availability of automatic differentiation to seamlessly combine long-range models with conventional, local ML schemes; and they are sufficiently flexible to implement more complex architectures that use physical interactions as building blocks. We benchmark and demonstrate our torch-pme and jax-pme libraries to perform molecular dynamics simulations, to train range-separated ML potentials, and to evaluate long-range equivariant descriptors of atomic structures.


---
# Learning constitutive relations from experiments: 1. PDE constrained optimization

## 从实验中学习本构关系: 1.PDE约束优化

Link: https://arxiv.org/abs/2412.02864

arXiv:2412.02864v1 Announce Type: cross 
Abstract: We propose a method to accurately and efficiently identify the constitutive behavior of complex materials through full-field observations. We formulate the problem of inferring constitutive relations from experiments as an indirect inverse problem that is constrained by the balance laws. Specifically, we seek to find a constitutive behavior that minimizes the difference between the experimental observation and the corresponding quantities computed with the model, while enforcing the balance laws. We formulate the forward problem as a boundary value problem corresponding to the experiment, and compute the sensitivity of the objective with respect to model using the adjoint method. The resulting method is robust and can be applied to constitutive models with arbitrary complexity. We focus on elasto-viscoplasticity, but the approach can be extended to other settings. In this part one, we formulate the method and demonstrate it using synthetic data on two problems, one quasistatic and the other dynamic.


---
# Machine Learned Potential for High-Throughput Phonon Calculations of Metal-Organic Frameworks

## 用于金属有机框架的高通量声子计算的机器学习潜力

Link: https://arxiv.org/abs/2412.02877

arXiv:2412.02877v1 Announce Type: cross 
Abstract: Metal-organic frameworks (MOFs) are highly porous and versatile materials studied extensively for applications such as carbon capture and water harvesting. However, computing phonon-mediated properties in MOFs, like thermal expansion and mechanical stability, remains challenging due to the large number of atoms per unit cell, making traditional Density Functional Theory (DFT) methods impractical for high-throughput screening. Recent advances in machine learning potentials have led to foundation atomistic models, such as MACE-MP-0, that accurately predict equilibrium structures but struggle with phonon properties of MOFs. In this work, we developed a workflow for computing phonons in MOFs within the quasi-harmonic approximation with a fine-tuned MACE model, MACE-MP-MOF0. The model was trained on a curated dataset of 127 representative and diverse MOFs. The fine-tuned MACE-MP-MOF0 improves the accuracy of phonon density of states and corrects the imaginary phonon modes of MACE-MP-0, enabling high-throughput phonon calculations with state-of-the-art precision. The model successfully predicts thermal expansion and bulk moduli in agreement with DFT and experimental data for several well-known MOFs. These results highlight the potential of MACE-MP-MOF0 in guiding MOF design for applications in energy storage and thermoelectrics.


---
# Assessing the performance of CT image denoisers using Laguerre-Gauss Channelized Hotelling Observer for lesion detection

## 使用laguerre-gauss信道化Hotelling观测器进行病变检测来评估CT图像去噪器的性能

Link: https://arxiv.org/abs/2412.02920

arXiv:2412.02920v1 Announce Type: cross 
Abstract: The remarkable success of deep learning methods in solving computer vision problems, such as image classification, object detection, scene understanding, image segmentation, etc., has paved the way for their application in biomedical imaging. One such application is in the field of CT image denoising, whereby deep learning methods are proposed to recover denoised images from noisy images acquired at low radiation. Outputs derived from applying deep learning denoising algorithms may appear clean and visually pleasing; however, the underlying diagnostic image quality may not be on par with their normal-dose CT counterparts. In this work, we assessed the image quality of deep learning denoising algorithms by making use of visual perception- and data fidelity-based task-agnostic metrics (like the PSNR and the SSIM) - commonly used in the computer vision - and a task-based detectability assessment (the LCD) - extensively used in the CT imaging. When compared against normal-dose CT images, the deep learning denoisers outperformed low-dose CT based on metrics like the PSNR (by 2.4 to 3.8 dB) and SSIM (by 0.05 to 0.11). However, based on the LCD performance, the detectability using quarter-dose denoised outputs was inferior to that obtained using normal-dose CT scans.


---
# A deep neural network approach to solve the Dirac equation

## 求解Dirac方程的深度神经网络方法

Link: https://arxiv.org/abs/2412.03090

arXiv:2412.03090v1 Announce Type: cross 
Abstract: We extend the method from [Naito, Naito, and Hashimoto, Phys. Rev. Research 5, 033189 (2023)] to solve the Dirac equation not only for the ground state but also for low-lying excited states using a deep neural network and the unsupervised machine learning technique. The variational method fails because of the Dirac sea, which is avoided by introducing the inverse Hamiltonian method. For low-lying excited states, two methods are proposed, which have different performances and advantages. The validity of this method is verified by the calculations with the Coulomb and Woods-Saxon potentials.


---
# Comparison between tensor methods and neural networks in electronic structure calculations

## 电子结构计算中张量方法与神经网络的比较

Link: https://arxiv.org/abs/2412.03319

arXiv:2412.03319v1 Announce Type: cross 
Abstract: This article compares the tensor method density matrix renormalization group (DMRG) with two neural network based methods -namely FermiNet and PauliNet) for determining the ground state wavefunction of the  many-body electronic Schr{\"o}dinger problem. We provide numerical simulations illustrating the main features of the methods and showing convergence with respect to some parameter, such as the rank for DMRG, and number of pretraining iterations for neural networks. We then compare the obtained energy with the methods for a few atoms and molecules, for some of which the exact value of the energy is known for the sake of comparison. In the last part of the article, we propose a new kind of neural network to solve the Schr{\"o}dinger problem based on the training of the wavefunction on a simplex, and an explicit permutation for evaluating the wavefunction on the whole space. We provide numerical results on a toy problem for the sake of illustration.


---
# A Novel and Simple Invariant-Domain-Preserving Framework for PAMPA Scheme: 1D Case

## 用于PAMPA方案的新颖且简单的不变域保留框架: 一维情况

Link: https://arxiv.org/abs/2412.03423

arXiv:2412.03423v1 Announce Type: cross 
Abstract: The PAMPA (Point-Average-Moment PolynomiAl-interpreted) method, proposed in [R. Abgrall, Commun. Appl. Math. Comput., 5: 370-402, 2023], combines conservative and non-conservative formulations of hyperbolic conservation laws to evolve cell averages and point values. Solutions to hyperbolic conservation laws typically have an invariant domain, and ensuring numerical solutions stay within this domain is essential yet nontrivial. This paper presents a novel framework for designing efficient Invariant-Domain-Preserving (IDP) PAMPA schemes. We first analyze the IDP property for updated cell averages in the original PAMPA scheme, revealing the role of cell average decomposition and midpoint values in maintaining the invariant domain. This analysis highlights the difficulty of relying on continuous fluxes alone to preserve the invariant domain. Building on these insights, we introduce a simple IDP limiter for cell midpoint values, and propose a provably IDP PAMPA scheme that guarantees the preservation of the invariant domain for updated cell averages without requiring post-processing limiters. This approach contrasts with existing bound-preserving PAMPA schemes, which often require additional convex limiting to blend high-order and low-order solutions. Most notably, inspired by the Softplus and Clipped ReLU functions from machine learning, we propose an automatic IDP reformulation of the governing equations, resulting in an unconditionally limiter-free IDP scheme for evolving point values. We also introduce techniques to suppress spurious oscillations, enabling the scheme to capture strong shocks effectively. Numerical experiments on 1D problems, including the linear convection equation, Burgers equation, the compressible Euler equations, and MHD equations, demonstrate the accuracy and robustness of the proposed IDP PAMPA scheme.


---
# Soft Checksums to Flag Untrustworthy Machine Learning Surrogate Predictions and Application to Atomic Physics Simulations

## 用于标记不可信机器学习代理预测的软校验和及其在原子物理模拟中的应用

Link: https://arxiv.org/abs/2412.03497

arXiv:2412.03497v1 Announce Type: cross 
Abstract: Trained neural networks (NN) are attractive as surrogate models to replace costly calculations in physical simulations, but are often unknowingly applied to states not adequately represented in the training dataset. We present the novel technique of soft checksums for scientific machine learning, a general-purpose method to differentiate between trustworthy predictions with small errors on in-distribution (ID) data points, and untrustworthy predictions with large errors on out-of-distribution (OOD) data points. By adding a check node to the existing output layer, we train the model to learn the chosen checksum function encoded within the NN predictions and show that violations of this function correlate with high prediction errors. As the checksum function depends only on the NN predictions, we can calculate the checksum error for any prediction with a single forward pass, incurring negligible time and memory costs. Additionally, we find that incorporating the checksum function into the loss function and exposing the NN to OOD data points during the training process improves separation between ID and OOD predictions. By applying soft checksums to a physically complex and high-dimensional non-local thermodynamic equilibrium atomic physics dataset, we show that a well-chosen threshold checksum error can effectively separate ID and OOD predictions.


---
# Dielectric tensor of perovskite oxides at finite temperature using equivariant graph neural network potentials

## 使用等变图神经网络电势在有限温度下钙钛矿氧化物的介电张量

Link: https://arxiv.org/abs/2412.03541

arXiv:2412.03541v1 Announce Type: cross 
Abstract: Atomistic simulations of properties of materials at finite temperatures are computationally demanding and require models that are more efficient than the ab initio approaches. Machine learning (ML) and artificial intelligence (AI) address this issue by enabling accurate models with close to ab initio accuracy. Here, we demonstrate the utility of ML models in capturing properties of realistic materials by performing finite temperature molecular dynamics simulations of perovskite oxides using a force field based on equivariant graph neural networks. The models demonstrate efficient learning from a small training dataset of energies, forces, stresses, and tensors of Born effective charges. We qualitatively capture the temperature dependence of the dielectric tensor and structural phase transitions in calcium titanate.


---
# Edge Dynamics in Iron-Cluster Catalyzed Growth of Single-Walled Carbon Nanotubes Revealed by Molecular Dynamics Simulations based on a Neural Network Potential

## 基于神经网络势的分子动力学模拟揭示铁簇催化单壁碳纳米管生长的边缘动力学

Link: https://arxiv.org/abs/2302.09264

arXiv:2302.09264v5 Announce Type: replace 
Abstract: Given the high potential for applications utilizing the unique properties of single-walled carbon nanotubes (SWCNTs), there is considerable enthusiasm for addressing the challenges associated with synthesizing SWCNTs with specific chirality. To elucidate the mechanisms that determine the chirality of SWCNTs during growth, intensive efforts have been devoted to classical molecular dynamics (MD) simulations. However, the mechanism of chirality determination has not been fully clarified, which can partly be attributed to the limited accuracy of empirical interatomic potentials in reproducing the behavior of carbon and metal atoms. In this work, we develop a neural network potential (NNP) for carbon-metal system to accurately describe the SWCNT growth, and perform MD simulations of SWCNT growth using the NNP. The MD simulations illustrate the defect-free, chirality-definable growth of SWCNTs, highlighting the dynamic rearrangement of edge configurations and the consistency between the probability of edge configuration appearance and the entropy-driven edge stability model proposed here. It is also shown that the edge defect formation is induced by vacancy and suppressed by vacancy healing through adatom diffusion on the SWCNT edges. These results provide insights into the edge formation thermodynamics and kinetics of SWCNTs, an important clue to the chirality-controlled synthesis of SWCNTs.


---
# A Physics Preserving Neural Network Based Approach for Constitutive Modeling of Isotropic Fibrous Materials

## 基于物理保持神经网络的各向同性纤维材料本构建模方法

Link: https://arxiv.org/abs/2403.13357

arXiv:2403.13357v5 Announce Type: replace 
Abstract: We develop a new neural network architecture that strictly enforces constitutive constraints such as polyconvexity, frame-indifference, and the symmetry of the stress and material stiffness. Additionally, we show that the accuracy of the stress and material stiffness predictions is significantly improved for this neural network by using a Sobolev minimization strategy that includes derivative terms. Using our neural network, we model the constitutive behavior of fibrous-type discrete network material. With Sobolev minimization, we obtain a normalized mean square error of 0.15% for the strain energy density, 0.815% averaged across the components of the stress, and 5.4% averaged across the components of the stiffness tensor. This machine-learned constitutive model was deployed in a finite element simulation of a facet capsular ligament. The displacement fields and stress-strain curves were compared to a multiscale simulation that required running on a GPU-based supercomputer. The new approach maintained upward of 85% accuracy in stress up to 70% strain while reducing the computation cost by orders of magnitude.


---
# Segmentation-Free Outcome Prediction from Head and Neck Cancer PET/CT Images: Deep Learning-Based Feature Extraction from Multi-Angle Maximum Intensity Projections (MA-MIPs)

## 基于头颈部肿瘤PET/CT图像的无分割结果预测: 基于深度学习的多角度最大强度投影特征提取 (ma-mips)

Link: https://arxiv.org/abs/2405.01756

arXiv:2405.01756v3 Announce Type: replace 
Abstract: We introduce an innovative, simple, effective segmentation-free approach for outcome prediction in head \& neck cancer (HNC) patients. By harnessing deep learning-based feature extraction techniques and multi-angle maximum intensity projections (MA-MIPs) applied to Fluorodeoxyglucose Positron Emission Tomography (FDG-PET) volumes, our proposed method eliminates the need for manual segmentations of regions-of-interest (ROIs) such as primary tumors and involved lymph nodes. Instead, a state-of-the-art object detection model is trained to perform automatic cropping of the head and neck region on the PET volumes. A pre-trained deep convolutional neural network backbone is then utilized to extract deep features from MA-MIPs obtained from 72 multi-angel axial rotations of the cropped PET volumes. These deep features extracted from multiple projection views of the PET volumes are then aggregated and fused, and employed to perform recurrence-free survival analysis on a cohort of 489 HNC patients. The proposed approach outperforms the best performing method on the target dataset for the task of recurrence-free survival analysis. By circumventing the manual delineation of the malignancies on the FDG PET-CT images, our approach eliminates the dependency on subjective interpretations and highly enhances the reproducibility of the proposed survival analysis method.


---
# Validation of the static forward Grad-Shafranov equilibrium solvers in FreeGSNKE and Fiesta using EFIT++ reconstructions from MAST-U

## 使用MAST-U的EFIT重建验证FreeGSNKE和Fiesta中的静态正向grad-shafranov平衡求解器

Link: https://arxiv.org/abs/2407.12432

arXiv:2407.12432v4 Announce Type: replace 
Abstract: A key aspect in the modelling of magnetohydrodynamic (MHD) equilibria in tokamak devices is having access to fast, accurate, and stable numerical simulation methods. There is an increasing demand for reliable methods that can be used to develop traditional or machine learning-based shape control feedback systems, optimise scenario designs, and integrate with other plasma edge or transport modelling codes. To handle such applications, these codes need to be flexible and, more importantly, they need to have been validated against both analytically known and real-world tokamak equilibria to ensure they are consistent and credible. In this paper, we are interested in solving the static forward Grad-Shafranov (GS) problem for free-boundary MHD equilibria. Our focus is on the validation of the static forward solver in the Python-based equilibrium code FreeGSNKE by solving equilibria from magnetics-only EFIT++ reconstructions of MAST-U shots. In addition, we also validate FreeGSNKE against equilibria simulated using the well-established MATLAB-based equilibrium code Fiesta. To do this, we develop a computational pipeline that allows one to load the same (a)symmetric MAST-U machine description into each solver, specify the required inputs (active/passive conductor currents, plasma profiles and coefficients, etc.) from EFIT++, and solve the GS equation for all available time slices across a shot. For a number of different MAST-U shots, we demonstrate that both FreeGSNKE and Fiesta can successfully reproduce various poloidal flux quantities and shape targets (e.g. midplane radii, magnetic axes, separatrices, X-points, and strikepoints) in agreement with EFIT++ calculations to a very high degree of accuracy. We also provide public access to the code/data required to load the MAST-U machine description in FreeGSNKE/Fiesta and reproduce the equilibria in the shots shown.


---
# Scalable learning of potentials to predict time-dependent Hartree-Fock dynamics

## 预测时间相关的hartree-fock动力学的潜力的可扩展学习

Link: https://arxiv.org/abs/2408.04765

arXiv:2408.04765v2 Announce Type: replace 
Abstract: We propose a framework to learn the time-dependent Hartree-Fock (TDHF) inter-electronic potential of a molecule from its electron density dynamics. Though the entire TDHF Hamiltonian, including the inter-electronic potential, can be computed from first principles, we use this problem as a testbed to develop strategies that can be applied to learn a priori unknown terms that arise in other methods/approaches to quantum dynamics, e.g., emerging problems such as learning exchange-correlation potentials for time-dependent density functional theory. We develop, train, and test three models of the TDHF inter-electronic potential, each parameterized by a four-index tensor of size up to $60 \times 60 \times 60 \times 60$. Two of the models preserve Hermitian symmetry, while one model preserves an eight-fold permutation symmetry that implies Hermitian symmetry. Across seven different molecular systems, we find that accounting for the deeper eight-fold symmetry leads to the best-performing model across three metrics: training efficiency, test set predictive power, and direct comparison of true and learned inter-electronic potentials. All three models, when trained on ensembles of field-free trajectories, generate accurate electron dynamics predictions even in a field-on regime that lies outside the training set. To enable our models to scale to large molecular systems, we derive expressions for Jacobian-vector products that enable iterative, matrix-free training.


---
# AI Meets Antimatter: Unveiling Antihydrogen Annihilations

## AI遇到反物质: 揭示反氢an灭

Link: https://arxiv.org/abs/2412.00961

arXiv:2412.00961v2 Announce Type: replace 
Abstract: The ALPHA-g experiment at CERN aims to perform the first-ever direct measurement of the effect of gravity on antimatter, determining its weight to within 1% precision. This measurement requires an accurate prediction of the vertical position of annihilations within the detector. In this work, we present a novel approach to annihilation position reconstruction using an ensemble of models based on the PointNet deep learning architecture. The newly developed model, PointNet Ensemble for Annihilation Reconstruction (PEAR) outperforms the standard approach to annihilation position reconstruction, providing more than twice the resolution while maintaining a similarly low bias. This work may also offer insights for similar efforts applying deep learning to experiments that require high resolution and low bias.


---
# Explainable Data-driven Modeling of Adsorption Energy in Heterogeneous Catalysis

## 非均相催化中吸附能的可解释数据驱动模型

Link: https://arxiv.org/abs/2405.20397

arXiv:2405.20397v2 Announce Type: replace-cross 
Abstract: The increasing popularity of machine learning (ML) in catalysis has spurred interest in leveraging these techniques to enhance catalyst design. Our study aims to bridge the gap between physics-based studies and data-driven methodologies by integrating ML techniques with eXplainable AI (XAI). Specifically, we employ two XAI techniques: Post-hoc XAI analysis and Symbolic Regression. These techniques help us unravel the correlation between adsorption energy and the properties of the adsorbate-catalyst system. Leveraging a large dataset such as the Open Catalyst Dataset (OC20), we employ a combination of shallow ML techniques and XAI methodologies. Our investigation involves utilizing multiple shallow machine learning techniques to predict adsorption energy, followed by post-hoc analysis for feature importance, inter-feature correlations, and the influence of various feature values on the prediction of adsorption energy. The post-hoc analysis reveals that adsorbate properties exert a greater influence than catalyst properties in our dataset. The top five features based on higher Shapley values are adsorbate electronegativity, the number of adsorbate atoms, catalyst electronegativity, effective coordination number, and the sum of atomic numbers of the adsorbate molecule. There is a positive correlation between catalyst and adsorbate electronegativity with the prediction of adsorption energy. Additionally, symbolic regression yields results consistent with SHAP analysis. It deduces a mathematical relationship indicating that the square of the catalyst electronegativity is directly proportional to the adsorption energy. These consistent correlations resemble those derived from physics-based equations in previous research. Our work establishes a robust framework that integrates ML techniques with XAI, leveraging large datasets like OC20 to enhance catalyst design through model explainability.


---
# Big Data-Driven Deep Learning for Natural Language Processing

## 大数据驱动的自然语言处理深度学习

Link: https://www.researchsquare.com/article/rs-5413571/latest

Sentiment analysis, a crucial task in natural language processing (NLP), aims to extract and classify sentiments expressed in textual data. This research delves into the application of deep learning techniques, powered by Big Data, to enhance sentiment analysis accuracy. By leveraging a substantial Amazon review dataset, we train a simple feedforward neural network to classify sentiments as positive or negative. The model employs embedding layers to represent words as dense vectors, followed by a global average pooling layer to capture semantic information. A final dense layer with a sigmoid activation function predicts the sentiment probability. The results demonstrate the effectiveness of deep learning in capturing complex linguistic nuances and achieving high accuracy. With an accuracy of 88.47%, the model outperforms traditional methods, showcasing the potential of Big Data and deep learning in sentiment analysis. Future research directions include exploring more sophisticated architectures, addressing class imbalance issues, improving model interpretability, and incorporating domain-specific knowledge to further enhance sentiment analysis performance.


---
# Preparing physiotherapists for the future: the development and evaluation of an innovative curriculum

## 为未来准备物理治疗师: 创新课程的开发和评估

Link: https://www.researchsquare.com/article/rs-5014136/latest

Background Educational innovation in health professional education is needed to keep up with rapidly changing healthcare systems and societal needs. This study evaluates the implementation of PACE, an innovative curriculum designed by the physiotherapy department of the HAN University of Applied Sciences in The Netherlands. The PACE concept features an integrated approach to learning and assessment based on pre-set learning outcomes, personalized learning goals, flexible learning routes, and programmatic assessment. PACE distinguishes itself from traditional education because of the flexible learning routes, vertical organization in learning communities, absence of pre-defined learning activities and class schedules, and a culture of continuous learning and development. PACE is based on three guiding principles: 1) flexible and varied, 2) self-directed and collaborative, 3) future-oriented. PACE was implemented in 2021 for first-year students. This study evaluates the implementation to inform future curriculum development.Methods A sequential explanatory mixed methods design was used to evaluate the implementation of PACE using a questionnaire, focus groups, in-depth interviews, and a national progress test allowing for benchmarking results. Participants were undergraduate physiotherapy students of cohort 2021&amp;ndash;2022, the first group who experienced PACE and teachers involved with this cohort. Questionnaire data were analyzed using descriptive statistics. To compare mean total scores of the national progress test between four different universities a one-way ANOVA was conducted including a post-hoc analysis.  Reflexive thematic analysis guidelines were applied to analyze the interview data.Results In total 82 first year students (44,6%) of cohort 2021&amp;ndash;2022 and 36 teachers (60%) completed the questionnaire. Results show that the guiding principles were implemented as intended. Results of the national progress test on knowledge and clinical reasoning showed that students of the HAN University performed well compared to other universities. Thematic analysis of interviews and focus groups resulted in three themes and nine subthemes: 1) navigating a personalized curriculum, 2) caring and sharing, and 3) shaping professional identity. PACE contributed positively to students' intrinsic motivation, learning joy, identity development, and life-long learning skills. Areas for improvement were self-directed learning support, and teaching strategies to prompt deep learning.Conclusion The evaluation showed that the guiding principles of PACE were implemented as intended and that the innovation positively contributed to student learning,


---
# Assessing the Impact of Digital Literacy Competency on Academic Outcomes: A Theoretical Model Validation Study

## 评估数字素养能力对学术成果的影响: 理论模型验证研究

Link: https://www.researchsquare.com/article/rs-5566588/latest

As technology becomes integral to education, especially with the emergence of advanced artificial intelligence applications, students require advanced digital literacy (DL) skills to succeed both academically and professionally. DL, defined as the ability to use digital technologies with a positive attitude toward digital learning, is explored in this study. The literature review for this study identified gaps in understanding the relationship between DL and academic performance. Current studies lack comprehensive data across university levels and majors, have limited representation of diverse student populations, and do not offer a unified understanding of the collective impact of DL skills on performance. This study aims to explore digital competence among higher education students using a tailored theoretical model, focusing on the impact of these competencies on academic performance. Employing a customized DL theoretical model that incorporates 22 competencies across three domains&amp;mdash;computer and information skills, advanced production, and digital security&amp;mdash;this research also considers demographic influences, such as sex and year of study. This study used partial least squares structural equation modeling and other statistical methods to investigate the relationships among these 22 competencies and their impact on students&amp;rsquo; academic performance. The findings revealed a significant correlation between computer and information skills and student performance with variations according to demographic factors. This study enhances academic understanding of DL and offers practical insights into educational strategies and policy development in higher education. This streamlined approach to developing a DL framework addresses the changing educational needs of undergraduate students.


---
# Non-coding genetic variants underlying higher prostate cancer risk in men of African ancestry

## 非洲血统男性前列腺癌风险较高的非编码遗传变异

Link: https://www.researchsquare.com/article/rs-5485172/latest

Incidence and severity of prostate cancer (PrCa) substantially varies across ancestries. American men of African ancestry (AA) are more likely to be diagnosed with and die from PrCa than the those of European ancestry (EA). Published polygenic risk scores for developing prostate cancer, even those based on multi-ancestry genome-wide association studies, do not address population-specific genetic mechanisms underlying PrCa risk in men of African ancestry. Specifically, the role of non-coding regulatory polymorphisms in driving inter-ancestry variation in PrCa has not been sufficiently explored. Here, by employing a sequence-based deep learning model of prostate regulatory enhancers, we identified&amp;thinsp;~&amp;thinsp;2,000 SNPs with higher alternate allele frequency in AA men that potentially affect enhancer function associated with PrCa susceptibility, as supported by our experimental validation. The identified enhancer SNPs (eSNPs) may influence PrCa development through two complementary mechanisms: 1) the alternate allele that increase enhancer activity result in immune suppression and telomere elongation, and 2) the alternate alleles that decrease enhancer activity, lead to de-differentiation and inhibition of apoptosis. Notably, the eSNPs tend to disrupt the binding of known prostate transcription factors including FOX, AR and HOX families. Lastly, the identified eSNPs can be combined into a polygenic risk score that adds value to current GWAS-based risk variants in assessing PrCa risk in independent cohorts.


---
# Revealing the Oxidative Stress-Related Molecular Characteristics and Potential Therapeutic Targets of Schizophrenia through Integrated Gene Expression Data Analysis

## 整合基因表达数据分析揭示精神分裂症氧化应激相关分子特征及潜在治疗靶点

Link: https://www.researchsquare.com/article/rs-5381302/latest

Background Schizophrenia is a severe mental disorder characterized by oxidative stress imbalances. The underlying mechanisms of oxidative stress-related gene expression in schizophrenia require further investigation. Additionally, the diagnosis of schizophrenia lacks sensitive and specific biomarkers as well as predictive models for assessing susceptibility.Methods We analyzed genome-wide mRNA expression profiles from GSE38484 (schizophrenia&amp;thinsp;=&amp;thinsp;106, control&amp;thinsp;=&amp;thinsp;96) and GSE54913 (schizophrenia&amp;thinsp;=&amp;thinsp;18, control&amp;thinsp;=&amp;thinsp;12) using Weighted Gene Co-expression Network Analysis and machine learning to identify oxidative stress-related hub genes in schizophrenia. Subsequent analyses included Gene Set Enrichment Analysis, protein-protein interaction networks, immune cell infiltration, and molecular docking. A diagnostic model was also constructed.Results We identified five hub genes associated with oxidative stress in schizophrenia: CTSB, RNH1, REC8, ITIH4, and TNFAIP8L1, and constructed a diagnostic model (AUC&amp;thinsp;=&amp;thinsp;0.954). Five hub genes and twenty co-expressed genes were enriched in pathways related to endopeptidase and endoribonuclease activities. Significant differences in the abundance of seven immune cell types were noted in schizophrenia samples. Drug prediction and molecular docking suggested UREA and COUMARIN as potential therapeutic agents targeting CTSB.Conclusions We identified five hub genes associated with oxidative stress in schizophrenia: CTSB, RNH1, REC8, ITIH4, and TNFAIP8L1. We carried out downstream analyses and constructed a diagnostic model for schizophrenia.


---
# Predictive Modeling and Optimization of TBM Operations: Advanced Techniques Applied to the Jakarta MRT Project

## TBM操作的预测建模和优化: 应用于雅加达地铁项目的先进技术

Link: https://www.researchsquare.com/article/rs-5576307/latest

The effectiveness of Earth Pressure Balance (EPB) Tunnel Boring Machines (TBMs) in urban underground construction relies on understanding and optimizing their performance under variable geotechnical conditions. This study investigates the key parameters impacting TBM efficiency during the construction of the Jakarta Mass Rapid Transit (MRT) Underground Section CP106. Data from TBM operation were analyzed using statistical and machine learning techniques, including Mutual Information (MI), Partial Dependence Plots (PDP), and Analysis of Variance (ANOVA), to identify influential parameters such as Tensile Strength, Uniaxial Strength, Spacing, and Penetration. Predictive models, including Gradient Boosting Regressor, Random Forest Regressor, and Linear Regression, were evaluated based on error metrics and R-squared values, with Gradient Boosting Regressor showing the highest predictive accuracy. Clustering analyses using K-Means and Principal Component Analysis (PCA) further classified operational states, identifying conditions that optimize energy efficiency and reduce mechanical wear. The findings suggest that TBM configurations with lower Specific Energy, Normal Force, and Rolling Force contribute to more efficient, less force-intensive tunneling. These insights provide a basis for refining TBM operations and predictive modeling in urban tunneling projects.


---
# Intern insights: Career decisions, aspirations and perspectives from interns in a regional hospital setting

## 实习生见解: 区域医院环境中实习生的职业决策，抱负和观点

Link: https://www.researchsquare.com/article/rs-5134499/latest

Objective To identify the factors influencing the decision of interns to pursue prevocational training at a regional hospital, and gain insights into their career aspirations, expectations and concerns as they commence their internship.Methods The study involved retrospective analysis of welcome interviews with Postgraduate Year 1 (PGY1) interns during their first rotation at a regional hospital in Queensland, Australia in 2024. The main outcome measures included factors influencing the decision to complete internship at a regional hospital, career aspirations, expectations and concerns for internship.Results Interns primarily chose the regional hospital for its positive reputation of being a supportive environment, opportunities for broad generalist clinical experience, and comprised a smooth transition from local regionally based university sites. Career aspirations varied, with popular interests in rural generalism, general practice, emergency medicine, anaesthetics and paediatrics. Interns expected and received hands-on learning experiences, regular patient interaction and broad exposure to various clinical specialties, while concerns included managing workload and adapting to new hospital systems.Conclusion Addressing the workforce nurturing and pastoral care needs of interns is crucial for a supportive and fulfilling internship experience. Promoting pastoral care and learning opportunities, are potential points of difference that may imbue reputational growth and ultimately attract interns to regional hospitals and enhance retention, optimising the medical workforce in these areas.


---
# UIEAnything: Zero-Shot Underwater Image Enhancement via Advanced Depth Estimation, White Balance Models, and Improved Sea-thru

## Uie任何东西: 通过先进的深度估计，白平衡模型和改进的海透零拍摄水下图像增强

Link: https://www.researchsquare.com/article/rs-5429465/latest

Underwater image enhancement is fundamental for marine applications yet remains challenging due to complex light&amp;ndash;water interactions that degrade image quality through wavelength-dependent absorption and scattering effects. Existing methods often require extensive paired training data and struggle to generalize across diverse underwater conditions. We propose UIEAnything, a novel zero-shot underwater image enhancement framework that integrates automatic white balance preprocessing, physics-guided depth estimation, and an improved restoration algorithm based on underwater light transport theory. Our approach introduces three key innovations: (1) a domain adaptation strategy that bridges the gap between underwater and natural images via physically motivated white balance correction, enabling effective utilization of pre-trained models; (2) an improved Sea-thru algorithm incorporating nonlinear backscatter modeling and adaptive attenuation estimation, accurately capturing the depth-dependent nature of underwater light propagation; and (3) a unified framework that eliminates the need for task-specific training while maintaining physical consistency. Extensive experiments on seven benchmark datasets demonstrate that UIEAnything consistently outperforms state-of-the-art methods, achieving average improvements of 15.3% in PSNR and 12.8% in SSIM. Furthermore, without additional training, our framework demonstrates remarkable generalization capability by successfully addressing other challenging vision tasks involving scattering media, such as image dehazing and sandstorm removal. These results establish UIEAnything as a significant advancement in physics-guided zero-shot learning for image enhancement in complex optical environments.


---
# Developing the Predictive Model for the Level of Food Insecurity Status of Households Using Ensemble Machine Learning Techniques with XAI

## 使用集成机器学习技术与XAI开发家庭粮食不安全状况水平的预测模型

Link: https://www.researchsquare.com/article/rs-5561434/latest

Among the world&amp;rsquo;s undernourished people, more than 282&amp;nbsp;million people in Africa and 418&amp;nbsp;million people in Asia were found. Moderate or severe food insecurity at the global level has risen from 22.6% in 2014 to 26.6% in 2019, with Sub-Saharan Africa experiencing high levels, particularly in Ethiopia. In 2018, 239&amp;nbsp;million undernourished people were registered in Sub-Saharan Africa particularly high in Kenya, Somalia, Ethiopia, and South Sudan. This study, hence, aimed to develop a predictive model using ensemble machine learning algorithms to assess and classify the levels of food insecurity based on socioeconomic, environmental, and demographic factors in North Western Ethiopia. The dataset, collected from the Dabat Health and Demographic Surveillance from 2014 to 2020, was preprocessed using data cleaning, transformation, and class balancing with SMOTE-ENN. The dataset is split into training, validation, and testing sets with a 90/10 ratio. Relevant features were selected via recursive feature elimination, and class decomposition methods were evaluated. Experiments with ensemble models, including Random Forest, Gradient Boosting, XGBoost, CatBoost, and LightGBM, identified XGBoost as the best-performing algorithm, achieving 91.53% accuracy, 89.39% recall, and a 94.00% micro-average ROC score. SHAP was employed for explainable AI, offering insights into critical factors influencing food insecurity. Key factors that enhance food security include receiving assistance in the form of food or money, the size of cultivated land, altitude, monthly income, and household assets. In contrast, factors that increase the likelihood of food insecurity include the education level of the household head, age, marital status, limited access to irrigation, and reductions in portion sizes and meal frequency for the household head. This study demonstrates the utility of machine learning in identifying key drivers of food insecurity and offers a robust framework for targeted interventions. By bridging predictive analytics with explainable AI, actionable insights are provided to policymakers and stakeholders to alleviate food insecurity in Ethiopia and beyond.


---
# Predicting the Neonatal Mortality Using Ensemble Machine Learning Algorithms in Case of Ethiopian Rural Areas

## 在埃塞俄比亚农村地区使用集成机器学习算法预测新生儿死亡率

Link: https://www.researchsquare.com/article/rs-5552789/latest

Each year, approximately 2.5 million newborns die globally, with developing countries behavior the impact of this crisis. Sub-Saharan Africa experiences the highest neonatal mortality rate at 27 deaths per 1,000 live births. In Ethiopia, neonatal mortality remains alarmingly high at 29 deaths per 1,000 live births, with early neonatal mortality reaching 41.8 deaths per 1,000 live births. Rural areas face even more severe disparities, with a prevalence of 45.6 deaths per 1,000 live births compared to 25.5 in urban settings, basically due to inadequate healthcare access, poor maternal and neonatal services, and socioeconomic challenges.
This study aimed to develop a robust predictive model for neonatal mortality in rural Ethiopia, using secondary data from the Ethiopian Demographic and Health Surveys (2000&ndash;2019). The dataset, consisting of 29,048 instances and 22 relevant features, was preprocessed to handle missing values and balance the class distribution using SMOTE. Several advanced ensemble machine learning algorithms were applied to build the predictive model, including Random Forest, Gradient Boosting, Extreme Gradient Boosting, Light Gradient Boosting, and CatBoost. The performance of these models was evaluated based on key metrics, including accuracy, precision, recall, F1 score, and ROC-AUC.
Among the ensemble algorithms tested, CatBoost demonstrated the highest performance, achieving 97.5% accuracy, 97.52% precision, 97.5% recall, 97.5% F1 score, and an outstanding ROC-AUC value of 99.57%. The key risk factors for neonatal mortality identified in the study included BCG vaccination status, the number of under-five children in the household, recent episodes of diarrhea, and iron tablet intake during pregnancy. These factors were found to significantly contribute to predicting neonatal mortality, underscoring the importance of targeted healthcare interventions for high-risk neonates.
This study developed a predictive model for neonatal mortality in rural Ethiopia using ensemble machine learning, identifying key risk factors like BCG vaccination and maternal health. It offers actionable insights for targeted interventions, supports healthcare prioritization, and highlights the need for improved access and policy reforms. Mobile health apps and policymaker collaboration can further reduce neonatal mortality.


---
# Immunotherapy drug target identification using machine learning and patient-derived tumour explant validation

## 使用机器学习和患者来源的肿瘤外植体验证进行免疫治疗药物靶标鉴定

Link: https://www.researchsquare.com/article/rs-5499857/latest

Immunotherapy has revolutionised cancer treatment, yet few patients respond clinically, necessitating alternative strategies that can benefit these patients. Novel immune-oncology targets can achieve this through bypassing resistance mechanisms to standard therapies. To address this, we introduce MIDAS, a multimodal graph neural network system for immune-oncology target discovery that leverages gene interactions, multi-omic patient profiles, immune cell biology, antigen processing, disease associations, and phenotypic consequences of genetic perturbations. MIDAS generalises to time-sliced data, outcompetes existing methods, including OpenTargets, and distinguishes approved from prospective targets. Moreover, MIDAS recovers immunotherapy response-associated genes in unseen trials, thus capturing tumour-immune dynamics within human tumours. Interpretability analyses reveal a reliance on autoimmunity, regulatory networks, and relevant biological pathways. Functionally perturbing the OSM-OSMR axis, a proposed target, in TRACERx melanoma patient-derived explants yielded reduced dysfunctional CD8+ T cells, which associate with immunotherapy response. Our results present a machine learning framework for analysing multimodal data for immune-oncology discovery.


---
# A Compact Deep Learning Approach Integrating Depthwise Convolutions and Spatial Attention for Plant Disease Classification

## 一种融合深度卷积和空间注意力的紧凑型深度学习方法，用于植物病害分类

Link: https://www.researchsquare.com/article/rs-5392998/latest

Agriculture is a major sector that provides food to the growing worldpopulation, so improving crop yields from the disease is essential. Bac-terial, fungi and viral plant diseases significantly challenge high cropproductivity. Traditional methods of plant disease detection are time-consuming and require expert knowledge. Therefore, to ensure optimalcrop health and yield, advanced, efficient, and accurate methods areneeded to detect and classify plant diseases early and accurately. Thisreview article explores the recent advancements in vision-based machinelearning (ML) and deep learning (DL) techniques for detecting plantleaf diseases. Specifically, the objective is to provide a detailed overviewof the current state-of-the-art methodologies, assess their effectiveness,and identify the role of critical datasets in facilitating these advance-ments. Additionally, the article highlights the potential of integratingemerging technologies, such as vision based models, to enhance diseasedetection systems&rsquo; capabilities. The review systematically examines var-ious ML and DL techniques for plant leaf disease detection, focusingon their application and performance. Techniques such as Convolu-tional Neural Networks (CNNs), which have shown high accuracy in disease identification, are discussed in depth. The importance of open-source databases, particularly PlantVillage, in training and validatingthese models is emphasized. The methodology also discusses integrat-ing advanced technologies and developing hybrid models that combinevision-based and language-based approaches to improve detection accu-racy and robustness. The analysis highlights the significant progressin applying ML and DL to plant leaf disease detection, showcasingseveral successful implementations and their outcomes. The reviewidentifies emerging trends that promise to enhance disease detectionsystems. It also critically assesses the strengths and limitations ofcurrent techniques, offering insights into potential improvements andfuture research directions. This comprehensive analysis highlights thecritical role of ML and DL in advancing plant disease detection, aim-ing to provide sustainable and scalable solutions for the agriculturalsector. The findings have significant implications for improving cropyields and ensuring food security for the growing global population.


---
# eFCMG - An Evolving Fuzzy Classifier with Participatory Learning and Multivariable Gaussian for Data Stream

## eFCMG-一种具有参与式学习和多变量高斯的数据流演化模糊分类器

Link: https://www.researchsquare.com/article/rs-5566310/latest

This paper introduces a novel evolving fuzzy classifier that begins with no initial structure and develops incrementally through a participatory learning-based clustering algorithm. It employs multivariable Gaussian membership functions for rule antecedents and class outputs for consequents. The classifier's learning algorithm is designed to adjust dynamically by creating, merging, deleting, and updating clusters and rules. Uniquely, it features a 'procrastination' approach where clusters are initially formed in a disabled state to robustly manage outliers and ensure only representative data influence the model. Clusters are refined based on compatibility measures using the Mahalanobis distance, with adjustments to learning rates influenced by the nature of incoming data&mdash;slowing for anomalies and accelerating for typical inputs. This mechanism enhances adaptability and model accuracy, distinguishing it from existing fuzzy classifiers. Comparative analyses on binary and multiclass tasks demonstrate its superior or competitive performance, underscoring the classifier's innovative approach to evolving fuzzy classification.


---
# Machine Learning-Aided Spatial Adaptation for Improved Digital Image Correlation Analysis of Complex Geometries

## 机器学习辅助的空间自适应，用于改进复杂几何形状的数字图像相关分析

Link: https://www.researchsquare.com/article/rs-5566473/latest

Digital Image Correlation (DIC) is a widely used experimental technique for measuring full-field deformations. However, its applicability to samples with irregular geometries, particularly for measuring deformations near sample edges, has been limited. This is because DIC subset windows must be split when their centroids approach the sample edge, and portions of the subset outside the sample region need to be discarded, which often requires significant manual intervention. In this paper, we present a novel machine learning-aided approach that significantly improves the efficiency and speed of DIC post-processing. Our approach begins by utilizing the recently developed Segment Anything Model 2 (SAM 2) to rapidly generate initial masks that delineate regions of interest within the sample. Compared to conventional image segmentation methods, this approach reduces computation time by one to two orders of magnitude. These masks then undergo spatial and temporal refinement to improve accuracy and consistency. The refined masks serve as input for our recently developed SpatioTemporally Adaptive Quadtree mesh DIC (STAQ-DIC) method, which automatically selects regions of interest and generates adaptively refined meshes, particularly around areas with complex geometries. DIC subsets near sample edges or internal voids are automatically split, further improving the accuracy of the resolved displacement fields. Through multiple case studies, we demonstrate the effectiveness of this approach in accelerating and improving DIC analysis for complex geometries. It provides a more efficient and accurate means of measuring deformations in challenging experimental scenarios, while minimizing manual intervention and processing time. Additionally, we provide an open-source code that is freely available to use our approach.


---
# A Universal Defense Strategy Against Adversarial Attacks Based on Attention-Guided

## 基于注意力引导的对抗攻击的通用防御策略

Link: https://www.researchsquare.com/article/rs-5165408/latest

Deep Neural Networks (DNNs) have been shown to be vulnerable to adversarial examples. The existence of adversarial examples significantly hinders the development of deep learning technologies in domains with high-security requirements. However, current defense methods often lack universality, being effective only against specific adversarial attacks. This study focuses on analyzing adversarial examples through changes in model attention, classifying attack algorithms into attention-shifting and attention-attenuation categories. To counter attention-shifting attacks, a defense module named Feature Pyramid-based Attention Space-guided (FPAS) is proposed, which spatially retracts the shifting attention in adversarial examples, thereby enhancing the model's overall defense capability. Attention-based Non-Local (ANL) is a proposed defense module to counter attention-attenuation attacks. This module enhances the model's focus on critical features, efficiently constructing a robust defense model with low implementation cost and minimal intrusion into the original model. By integrating FPAS and ANL into the Wide-ResNet model within a boosting framework, the study demonstrates their synergistic defense capability. Even with eight adversarial samples embedded with adversarial patches, our FPAS_at and ANL_at models demonstrated significant improvements over the baseline, enhancing the average defense rate by 5.47% and 7.74%, respectively. Extensive experiments confirm that this universal defense strategy offers comprehensive protection against adversarial attacks at a lower implementation cost compared to current mainstream defense methods, while also being adaptable for integration with existing defense strategies to further enhance adversarial robustness.


---
# Evaluating and Accelerating Vision Transformers on GPU-based Embedded Edge AI Systems

## 在基于GPU的嵌入式边缘AI系统上评估和加速视觉转换器

Link: https://www.researchsquare.com/article/rs-5083258/latest

Many current embedded systems comprise heterogeneous computing components including quite powerful GPUs, which enables their application across diverse sectors. This study demonstrates the efficient execution of a medium-sized Self-Supervised Audio Spectrogram Transformer (SSAST) model on a low-power System-on-Chip (SoC). Through comprehensive evaluation, including real-time inference scenarios, we show that GPUs outperform multi-core CPUs in inference processes. Optimization techniques such as adjusting batch size, model compilation with TensorRT, and reducing data precision significantly enhance inference time, energy consumption, and memory usage. In particular, negligible accuracy degradation is observed, with post-training quantization to 8-bit integers showing less than 1% loss. This research underscores the feasibility of deploying transformer neural networks on low-power embedded devices, ensuring efficiency in time, energy, and memory while maintaining the accuracy of the results.


---
# Surrogate model and machine learning approaches for thermal field reconstruction from weld pool contour: application to GTA welding

## 从熔池轮廓重建热场的代理模型和机器学习方法: 在GTA焊接中的应用

Link: https://www.researchsquare.com/article/rs-5422383/latest

Thermal cycles in arc welding are crucial as they determine the metallurgy, residual stresses and distortions of welded parts. Experimentally measuring the temperature everywhere in the welded parts is not possible. This can be achieved with a thermal simulation but finite element analysis requires long computational times especially for large parts. This study aimed to predict the thermal field using a data-driven approach using numerical and experimental data. First, thermal modeling is defined and arc heating is described with an equivalent heat source. The numerical design of experiments was conducted by varying the heat source parameters. Weld pool contour is extracted from each simulations for building a numerical dataset. The numerical dataset is used for training a surrogate model. The surrogate model is used for estimating the heat source parameters from the weld pool contour using an optimization technique. Then a K-Nearest Neighbors algorithm is used to predict the thermal field from the estimated heat source parameters. A significant reduction in computational time is obtained for predicting the thermal field from experimental weld pool contour. Numerical analysis showed that the predicted thermal field is fairly good in the solid than in the weld pool.


---
# Intermediates of Forming Transition Metal Dichalcogenides Heterostructures Revealed by Machine Learning Simulations

## 通过机器学习模拟揭示了形成过渡金属二硫属化合物异质结构的中间体

Link: https://www.researchsquare.com/article/rs-5424715/latest

The primary restrictions on 2D transition metal dichalcogenide (TMD) van der Waals heterostructures (vdWHs) are size limitation and alloying. Recently, a two-step vapor deposition method was reported to grow wafer-scale TMD vdWHs with little contamination [Nature 621, 499 (2023)]. In this study, we developed a machine learning potential (MLP) which can accurately simulate the growth processes of bilayer MoS2/WS2 vdWHs under various conditions. Importantly, a SMMS (where M is Mo or W) structure is revealed as a highly stable intermediate easily introduces metal atom exchange and alloying. Eliminating the alloying contamination in TMD vdWHs is avoiding SMMS structure by preventing the landing of bare metal atoms. However, SMMS is revealed as an ideal electrode for MoS2 FETs with low Schottky barrier.


---
# An Advanced Neural Network Framework for Intrusion Detection

## 一种用于入侵检测的高级神经网络框架

Link: https://www.researchsquare.com/article/rs-4043594/latest

Cloud computing is rapidly expanding, and virtualized data centers are gaining favor as a practical infrastructure for the telecommunications sector. End customers, including numerous private and public organizations, have widely adopted and used Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Security remains the primary issue in cloud computing systems despite its widespread acceptance. Customers of cloud services live in constant worry of availability problems, information theft, security breaches, and data loss. With the development of machine learning (ML) tools, security applications are currently becoming more and more prominent in the literature. In this study, we investigate the applicability of enhanced Artificial Neural Networks, a well-known ML method, to identify intrusions or unusual behavior in the cloud environment. We have designed machine learning (ML) models using an enhanced ANN approach and compared the results. The UNSW-NB-15 dataset was used to train and test the models. To reduce the complexity and training time of the ML model, we have also conducted feature engineering and parameter tuning to identify the best set of features with the highest level of accuracy. We see that the accuracy of anomaly detection achieved by an enhanced ANN approach with the right features set is 99.91%. This accuracy is greater than that seen in the literature and requires fewer features to train the model.


---
# Continuous Visual Navigation with Ant-Inspired Memories

## 具有蚂蚁启发记忆的连续视觉导航

Link: https://www.researchsquare.com/article/rs-5505975/latest

Solitary foraging ants excel in following long visual routes in complex environments with limited sensory and neural resources&mdash;an ability that remains challenging for robots with minimal computational power. Here, we introduce a self-supervised, insect-inspired neural network that enables robust route-following on the compact, low-cost Antcar robot. The robot leverages key aspects of ant brain and behavior: (i) continuous, one-shot visual route learning using panoramic encoding in a mushroom body-inspired network, (ii) categorization of low-resolution egocentric panoramas via oscillatory movements, (iii) opponent-process control of angular and forward velocities based on visual familiarity, (iv) recognition of places of interest along routes, and (v) motivation-based memory modulation. Antcar autonomously followed routes between indoor or outdoor destinations, forward or backward, while remaining stable in both theoretical analysis and real-world testing despite occlusions and visual changes. Across 1.3 km of autonomous travel, Antcar achieved challenging route-following with sub-20 cm lateral error at speeds up to 150 cm/s, requiring only 148 kilobits of memory and processing panoramas every 62 ms. This efficient, brain-inspired architecture stands out from more sensor-intensive and computationally demanding methods, presenting a neuromorphic approach with valuable insights into insect navigation and practical robotic applications.


---
# Novel Machine Learning Approaches for Predicting Soil Moisture Content Using Hydrological and Soil Characteristics: A Comparative Analysis of ANN, SVM, and ANFIS Models

## 利用水文和土壤特征预测土壤水分含量的新型机器学习方法: ANN，SVM和ANFIS模型的比较分析

Link: https://www.researchsquare.com/article/rs-5404605/latest

The agricultural system's ability to make decisions on water management and irrigation scheduling depends on knowledge of the soil moisture content. However, when used with large datasets, standard techniques for estimating soil moisture content, like time-domain reflectometry and gravimetric analysis, need a significant amount of time and manual labor. The moisture content of soil is significantly influenced by numerous critical hydrological and soil parameters. As a result, these characteristics can be used to calculate and predict the soil moisture content. This work offers an alternative machine learning (ML) method for modeling and predicting moisture content of soil based on hydrological and soil characteristics. To predict the moisture content of soil from various hydrological and soil properties, such as average water depth (feet), average soil bulk density (g/cm3), average organic matter (%), Cation-Exchange capacity (meq/100g), percentages of clay and sand content (%), and tonnage of residuals (ton/acre), three machine learning techniques were employed: artificial neural network (ANN), and support vector machine (SVM) and adaptive neuro-fuzzy inference system (ANFIS) were employed for the prediction of the soil moisture content. The findings demonstrated that all three methods (ANN, SVM, and ANFIS) could accurately predict moisture content, with different prediction error rates. The average prediction error (APE) of ANN, SVM, and ANFIS is 9.057%, 10.834%, and 5.753%, respectively, of which the lowest root mean square error (RMSE) was observed for ANFIS of the testing (0.9979) and training (1.0049) datasets. In nutshell, the created models may be used to forecast the moisture in the soil of any farms with given hydrological and soil characteristics to control the water management system, saving money, effort and scarce water resources in the process of figuring out the soil moisture content.

