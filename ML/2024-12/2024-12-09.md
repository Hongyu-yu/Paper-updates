# Not so simple machines: Cracking the code for materials that can learn

## 不是那么简单的机器: 破解可以学习的材料的代码

Link: https://phys.org/news/2024-12-simple-machines-code-materials.html

It's easy to think that machine learning is a completely digital phenomenon, made possible by computers and algorithms that can mimic brain-like behaviors. But the first machines were analog and now, a small but growing body of research is showing that mechanical systems are capable of learning, too. Physicists at the University of Michigan have provided the latest entry into that field of work.


---
# A scalable framework for learning the geometry-dependent solution operators of partial differential equations

## 用于学习偏微分方程的几何相关解算子的可扩展框架

Link: https://www.nature.com/articles/s43588-024-00732-2

<p>Nature Computational Science, Published online: 09 December 2024; <a href="https://www.nature.com/articles/s43588-024-00732-2">doi:10.1038/s43588-024-00732-2</a></p>This work presents an artificial intelligence framework to learn geometry-dependent solution operators of partial differential equations (PDEs). The framework enables scalable and fast approximations of PDE solutions on a variety of 3D geometries.


---
# Training all-mechanical neural networks for task learning through in situ backpropagation

## 通过原位反向传播训练用于任务学习的全机械神经网络

Link: https://www.nature.com/articles/s41467-024-54849-z

<p>Nature Communications, Published online: 09 December 2024; <a href="https://www.nature.com/articles/s41467-024-54849-z">doi:10.1038/s41467-024-54849-z</a></p>Here, authors introduce an in situ backpropagation analogue to train mechanical neural networks locally and physically, enabling efficient and exact gradient-based training. The network achieves high accuracy in behavior learning and various machine learning tasks.


---
# Unsupervised machine learning for the detection of exotic phases in skyrmion phase diagrams

## 用于检测skyrmion相图中的奇异相的无监督机器学习

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.214415

Author(s): F. A. Gómez Albarracín<br /><p>Undoubtedly, machine learning (ML) techniques are being increasingly applied to a wide range of situations in the field of condensed matter. Amongst these techniques, unsupervised techniques are especially attractive, since they imply the possibility of extracting information from the data without p…</p><br />[Phys. Rev. B 110, 214415] Published Mon Dec 09, 2024


---
# Deep Learning‐Assisted Design of Novel Donor–Acceptor Combinations for Organic Photovoltaic Materials with Enhanced Efficiency

## 具有增强效率的有机光伏材料的新型供体-受体组合的深度学习辅助设计

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202407613?af=R

Advanced Materials, EarlyView.


---
# Metaplasticity‐Enabled Graphene Quantum Dot Devices for Mitigating Catastrophic Forgetting in Artificial Neural Networks

## 用于减轻人工神经网络中灾难性遗忘的介塑性石墨烯量子点器件

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202411237?af=R

Advanced Materials, EarlyView.


---
# Machine‐Learning Enabled Biocompatible Capacitive‐Electromyographic Bimodal Flexible Sensor for Facial Expression Recognition

## 用于面部表情识别的机器学习支持生物相容性电容肌电双模柔性传感器

Link: https://onlinelibrary.wiley.com/doi/10.1002/adfm.202418463?af=R

Advanced Functional Materials, EarlyView.


---
# Lattice Lingo: Effect of Textual Detail on Multimodal Learning for Property Prediction of Crystals

## Lattice Lingo: 文本细节对晶体性能预测的多模式学习的影响

Link: https://arxiv.org/abs/2412.04670

arXiv:2412.04670v1 Announce Type: new 
Abstract: Most prediction models for crystal properties employ a unimodal perspective, with graph-based representations, overlooking important non-local information that affects crystal properties. Some recent studies explore the impact of integrating graph and textual information on crystal property predictions to provide the model with this "missing" information by concatenation of embeddings. However, such studies do not evaluate which type of textual information is actually beneficial. We concatenate graph representations with text representations derived from textual descriptions with varying levels of detail. These descriptions, generated using the Robocrystallographer package, encompass global (e.g., space group, crystal type), local (e.g., bond lengths, coordination environment), and semiglobal (e.g., connectivity, arrangements) information about the structures. Our approach investigates how augmenting graph-based information with various levels of textual detail influences the performance for predictions for shear modulus and bulk modulus. We demonstrate that while graph representations can capture local structural information, incorporating semiglobal textual information enhances model performance the most. Global information can support performance further in the presence of semiglobal information. Our findings suggest that the strategic inclusion of textual information can enhance property prediction, thereby advancing the design and discovery of advanced novel materials for battery electrodes, catalysts, etc.


---
# Driving Thermoelectric Optimization in AgSbTe2 via Design of Experiments and Machine Learning

## 通过实验设计和机器学习在AgSbTe2中驱动热电优化

Link: https://arxiv.org/abs/2412.04699

arXiv:2412.04699v1 Announce Type: new 
Abstract: Systemic optimization of thermoelectric materials is arduous due to their conflicting electrical and thermal properties. A strategy based on Design of Experiments and machine learning is developed to optimize the thermoelectric efficiency of AgSb1+xTe2+y, an established thermoelectric. From eight experiments, high thermoelectric performance in AgSb1.021Te2.04 is revealed with a peak and average thermoelectric figure of merit of 1.61 +/- 0.24 at 600 K and 1.18 +/- 0.18 (300 - 623 K), respectively, which is over 30% higher than the best literature values for AgSb1+xTe2+y. Ag-deficiency and suppression of secondary phases in AgSb1.021Te2.04 improves the electrical properties and reduces the thermal conductivity (~0.4 W m-1 K-1). Our strategy is implemented into an open-source graphical user interface, and it can be used to optimize the methodologies, properties, and processes across different scientific fields.


---
# Unveiling hole-facilitated amorphisation in pressure-induced phase transformation of silicon

## 在硅的压力诱导相变中揭示孔促进的非晶化

Link: https://arxiv.org/abs/2412.04732

arXiv:2412.04732v1 Announce Type: new 
Abstract: Pressure-induced phase transformation occurs during silicon (Si) wafering processes. \b{eta}-tin (Si-II) phase is formed at high pressures, followed by the transformation to Si-XII, Si-III or/and amorphous Si ({\alpha}-Si) phases during the subsequent decompression. While the imposed pressure and its release rate are known to dictate the phase transformation of Si, the effect of charge carriers are ignored. Here, we experimentally unveil that the increased hole concentration facilitates the amorphization in the pressure-induced phase transformation of Si. The underlying mechanism is elucidated by the theoretical calculations based on machine-learning interatomic potentials. The hole-facilitated amorphization is also experimentally confirmed to occur in the indented Ge, GaAs or SiC. We discover that hole concentration is another determining factor for the pressure-induced phase transformations of the industrially important semiconductors.


---
# Dirac-Equation Signal Processing: Physics Boosts Topological Machine Learning

## 狄拉克方程信号处理: 物理促进拓扑机器学习

Link: https://arxiv.org/abs/2412.05132

arXiv:2412.05132v1 Announce Type: new 
Abstract: Topological signals are variables or features associated with both nodes and edges of a network. Recently, in the context of Topological Machine Learning, great attention has been devoted to signal processing of such topological signals. Most of the previous topological signal processing algorithms treat node and edge signals separately and work under the hypothesis that the true signal is smooth and/or well approximated by a harmonic eigenvector of the Hodge-Laplacian, which may be violated in practice. Here we propose Dirac-equation signal processing, a framework for efficiently reconstructing true signals on nodes and edges, also if they are not smooth or harmonic, by processing them jointly. The proposed physics-inspired algorithm is based on the spectral properties of the topological Dirac operator. It leverages the mathematical structure of the topological Dirac equation to boost the performance of the signal processing algorithm. We discuss how the relativistic dispersion relation obeyed by the topological Dirac equation can be used to assess the quality of the signal reconstruction. Finally, we demonstrate the improved performance of the algorithm with respect to previous algorithms. Specifically, we show that Dirac-equation signal processing can also be used efficiently if the true signal is a non-trivial linear combination of more than one eigenstate of the Dirac equation, as it generally occurs for real signals.


---
# Comparing the effects of Boltzmann machines as associative memory in Generative Adversarial Networks between classical and quantum sampling

## 比较玻尔兹曼机在经典和量子采样之间的生成对抗网络中作为联想记忆的效果

Link: https://arxiv.org/abs/2203.15220

arXiv:2203.15220v2 Announce Type: replace 
Abstract: We investigate the quantum effect on machine learning (ML) models exemplified by the Generative Adversarial Network (GAN), which is a promising deep learning framework. In the general GAN framework the generator maps uniform noise to a fake image. In this study, we utilize the Associative Adversarial Network (AAN), which consists of a standard GAN and an associative memory. Further, we set a Boltzmann Machine (BM), which is an undirected graphical model that learns low-dimensional features extracted from a discriminator, as the memory. Owing to difficulty calculating the BM's log-likelihood gradient, it is necessary to approximate it by using the sample mean obtained from the BM, which has tentative parameters. To calculate the sample mean, a Markov Chain Monte Carlo (MCMC) is often used. In a previous study, this was performed using a quantum annealer device, and the performance of the "Quantum" AAN was compared to that of the standard GAN. However, its better performance than the standard GAN is not well understood. In this study, we introduce two methods to draw samples: classical sampling via MCMC and quantum sampling via quantum Monte Carlo (QMC) simulation, which is quantum simulation on the classical computer. Then, we compare these methods to investigate whether quantum sampling is advantageous. Specifically, calculating the discriminator loss, the generator loss, inception score and Fr\'echet inception distance, we discuss the possibility of AAN. We show that the AANs trained by both MCMC and QMC are more stable during training and produce more varied images than the standard GANs. However, the results indicate no difference in sampling by QMC simulation compared to that by MCMC.


---
# What can we learn from quantum convolutional neural networks?

## 我们可以从量子卷积神经网络中学到什么？

Link: https://arxiv.org/abs/2308.16664

arXiv:2308.16664v3 Announce Type: replace-cross 
Abstract: Quantum machine learning (QML) shows promise for analyzing quantum data. A notable example is the use of quantum convolutional neural networks (QCNNs), implemented as specific types of quantum circuits, to recognize phases of matter. In this approach, ground states of many-body Hamiltonians are prepared to form a quantum dataset and classified in a supervised manner using only a few labeled examples. However, this type of dataset and model differs fundamentally from typical QML paradigms based on feature maps and parameterized circuits. In this study, we demonstrate how models utilizing quantum data can be interpreted through hidden feature maps, where physical features are implicitly embedded via ground-state feature maps. By analyzing selected examples previously explored with QCNNs, we show that high performance in quantum phase recognition comes from generating a highly effective basis set with sharp features at critical points. The learning process adapts the measurement to create sharp decision boundaries. Our analysis highlights improved generalization when working with quantum data, particularly in the limited-shots regime. Furthermore, translating these insights into the domain of quantum scientific machine learning, we demonstrate that ground-state feature maps can be applied to fluid dynamics problems, expressing shock wave solutions with good generalization and proven trainability.


---
# Ground state-based quantum feature maps

## 基于基态的量子特征图

Link: https://arxiv.org/abs/2404.07174

arXiv:2404.07174v2 Announce Type: replace-cross 
Abstract: We introduce a quantum data embedding protocol based on the preparation of a ground state of a parameterized Hamiltonian. We analyze the corresponding quantum feature map, recasting it as an adiabatic state preparation procedure with Trotterized evolution. We compare the properties of underlying quantum models with ubiquitous Fourier-type quantum models, and show that ground state embeddings can be described effectively by a spectrum with degree that grows rapidly with the number of qubits, corresponding to a large model capacity. We observe that the spectrum contains massive frequency degeneracies, and the weighting coefficients for the modes are highly structured, thus limiting model expressivity. Our results provide a step towards understanding models based on quantum data, and contribute to fundamental knowledge needed for building efficient quantum machine learning (QML) protocols. As non-trivial embeddings are crucial for designing QML protocols that cannot be simulated classically, our findings guide the search for high-capacity quantum models that can largely outperform classical models.


---
# How polarization fields can be beneficial in nitride emitters

## 极化场如何在氮化物发射器中受益

Link: https://arxiv.org/abs/2410.23591

arXiv:2410.23591v2 Announce Type: replace-cross 
Abstract: We revisit the prevailing notion that spontaneous and piezoelectric polarization fields are inherently detrimental to light emission in polar semiconductor heterostructures. Here, we demonstrate that polarization can actually enhance the overlap of electron and hole wave functions in III-nitride quantum wells, which are being considered for polychromatic micron-scale pixels in extended-reality and biomedical applications. By systematically exploring the design space of AlInGaN heterostructures with machine learning, we uncover that larger electric fields globally correlate with higher wave-function overlaps for red emitters. The key is the quantum-confined Stark effect, which enables a reduction in well width while avoiding the associated increase in In composition. Our work demonstrates the use of machine learning to reveal unexpected trends for informing the design of semiconductor heterostructures.


---
# Advancing Marine Heatwave Forecasts: An Integrated Deep Learning Approach

## 推进海洋热浪预报: 一种集成的深度学习方法

Link: https://arxiv.org/abs/2412.04475

arXiv:2412.04475v1 Announce Type: new 
Abstract: Marine heatwaves (MHWs), an extreme climate phenomenon, pose significant challenges to marine ecosystems and industries, with their frequency and intensity increasing due to climate change. This study introduces an integrated deep learning approach to forecast short-to-long-term MHWs on a global scale. The approach combines graph representation for modeling spatial properties in climate data, imbalanced regression to handle skewed data distributions, and temporal diffusion to enhance forecast accuracy across various lead times. To the best of our knowledge, this is the first study that synthesizes three spatiotemporal anomaly methodologies to predict MHWs. Additionally, we introduce a method for constructing graphs that avoids isolated nodes and provide a new publicly available sea surface temperature anomaly graph dataset. We examine the trade-offs in the selection of loss functions and evaluation metrics for MHWs. We analyze spatial patterns in global MHW predictability by focusing on historical hotspots, and our approach demonstrates better performance compared to traditional numerical models in regions such as the middle south Pacific, equatorial Atlantic near Africa, south Atlantic, and high-latitude Indian Ocean. We highlight the potential of temporal diffusion to replace the conventional sliding window approach for long-term forecasts, achieving improved prediction up to six months in advance. These insights not only establish benchmarks for machine learning applications in MHW forecasting but also enhance understanding of general climate forecasting methodologies.


---
# Learning Generalized Diffusions using an Energetic Variational Approach

## 使用能量变分方法学习广义扩散

Link: https://arxiv.org/abs/2412.04480

arXiv:2412.04480v1 Announce Type: new 
Abstract: Extracting governing physical laws from computational or experimental data is crucial across various fields such as fluid dynamics and plasma physics. Many of those physical laws are dissipative due to fluid viscosity or plasma collisions. For such a dissipative physical system, we propose two distinct methods to learn the corresponding laws of the systems based on their energy-dissipation laws, assuming either continuous data (probability density) or discrete data (particles) are available. Our methods offer several key advantages, including their robustness to corrupted observations, their easy extension to more complex physical systems, and the potential to address higher-dimensional systems. We validate our approach through representative numerical examples and carefully investigate the impacts of data quantity and data property on the model discovery.


---
# Raspberry Pi multispectral imaging camera system (PiMICS): a low-cost, skills-based physics educational tool

## Raspberry Pi多光谱成像相机系统 (PiMICS): 一种低成本，基于技能的物理教育工具

Link: https://arxiv.org/abs/2412.04679

arXiv:2412.04679v1 Announce Type: new 
Abstract: We report on an educational pilot program for low-cost physics experimentation run in Ecuador, South Africa, and the United States. The program was developed after having needs-based discussions with African educators, researchers, and leaders. It was determined that the need and desire for low-cost, skills-building, and active-learning tools is very high. From this, we developed a 3D-printable, Raspberry Pi-based multispectral camera (15 to 25 spectral channels in the visible and near-IR) for as little as $100. The program allows students to learn 3D modeling, 3D printing, feedback, control, image analysis, Python programming, systems integration and artificial intelligence as well as spectroscopy. After completing their cameras, the students in the program studied plant health, plant stress, post-harvest fruit ripeness, and polarization and spectral analysis of nanostructured insect wings, the latter of which won the ``best-applied research" award at a conference poster session and will be highlighted in this paper. Importantly, these cameras can be an integral part of any developing country's agricultural, recycling, medical, and pharmaceutical infrastructure. Thus, we believe this experiment can play an important role at the intersection of student training and developing countries' capacity building.


---
# Comparison of Deep Learning and Particle Smoother Expectation Maximization Methods for Estimation of Myocardial Perfusion PET Kinetic Parameters

## 深度学习和粒子平滑器期望最大化方法估计心肌灌注PET动力学参数的比较

Link: https://arxiv.org/abs/2412.04706

arXiv:2412.04706v1 Announce Type: new 
Abstract: Background: Positron emission tomography (PET) is widely used for studying dynamic processes, such as myocardial perfusion, by acquiring data over time frames. Kinetic modeling in PET allows for the estimation of physiological parameters, offering insights into disease characterization. Conventional approaches have notable limitations; for example, graphical methods may reduce accuracy due to linearization, while non-linear least squares (NLLS) methods may converge to local minima. Purpose: This study aims to develop and validate two novel methods for PET kinetic analysis of 82Rb: a particle smoother-based algorithm within an Expectation-Maximization (EM) framework and a convolutional neural network (CNN) approach. Methods: The proposed methods were applied to simulated 82Rb dynamic PET myocardial perfusion studies. Their performance was compared to conventional NLLS methods and a Kalman filter-based Expectation-Maximization (KEM) algorithm. Results: The success rates for parameters F, k3, and k4 were 46.0%, 67.5%, and 54.0% for the particle smoother with EM (PSEM) and 86.5%, 83.0%, and 79.5% for the CNN model, respectively, outperforming the NLLS method. Conclusions: The CNN and PSEM methods showed promising improvements over traditional methods in estimating kinetic parameters in dynamic PET studies, suggesting their potential for enhanced accuracy in disease characterization.


---
# Machine-Learning Electron Dynamics with Moment Propagation Theory: Application to Optical Absorption Spectrum Computation using Real-Time TDDFT

## 具有矩传播理论的机器学习电子动力学: 使用实时TDDFT在光学吸收光谱计算中的应用

Link: https://arxiv.org/abs/2412.05260

arXiv:2412.05260v1 Announce Type: new 
Abstract: We present an application of our new theoretical formulation of quantum dynamics, moment propagation theory (MPT) (Boyer et al., J. Chem. Phys. 160, 064113 (2024)), for employing machine-learning techniques to simulate the quantum dynamics of electrons. In particular, we use real-time time-dependent density functional theory (RT-TDDFT) simulation in the gauge of the maximally localized Wannier functions (MLWFs) for training the MPT equation of motion. Spatially-localized time-dependent MLWFs provide a concise representation that is particularly convenient for the MPT expressed in terms of increasing orders of moments. The equation of motion for these moments can be integrated in time while the analytical expressions are quite involved. In this work, machine-learning techniques were used to train the the second-order time derivatives of the moments using first-principles data from the RT-TDDFT simulation, and this MPT enabled us to perform electron dynamics efficiently. The application to computing optical absorption spectrum for various systems was demonstrated as a proof-of-principles example of this approach. In addition to isolated molecules (water, benzene, and ethene), condensed matter systems (liquid water and crystalline silicon) were studied, and we also explored how the principle of the nearsightedness of electrons can be employed in this context.


---
# Machine learning approach for mapping the stable orbits around planets

## 绘制行星稳定轨道的机器学习方法

Link: https://arxiv.org/abs/2412.04568

arXiv:2412.04568v1 Announce Type: cross 
Abstract: Numerical N-body simulations are commonly used to explore stability regions around exoplanets, offering insights into the possible existence of satellites and ring systems. This study aims to utilize Machine Learning (ML) techniques to generate predictive maps of stable regions surrounding a hypothetical planet. The approach can also be extended to planet-satellite systems, planetary ring systems, and other similar configurations. A dataset was generated using 10^5 numerical simulations, each incorporating nine orbital features for the planet and a test particle in a star-planet-test particle system. The simulations were classified as stable or unstable based on stability criteria, requiring particles to remain stable over a timespan equivalent to 10,000 orbital periods of the planet. Various ML algorithms were tested and fine-tuned through hyperparameter optimization to determine the most effective predictive model. Tree-based algorithms showed comparable accuracy in performance. The best-performing model, using the Extreme Gradient Boosting (XGBoost) algorithm, achieved an accuracy of 98.48%, with 94% recall and precision for stable particles and 99% for unstable particles. ML algorithms significantly reduce the computational time required for three-body simulations, operating approximately 100,000 times faster than traditional numerical methods. Predictive models can generate entire stability maps in less than a second, compared to the days required by numerical simulations. The results from the trained ML models will be made accessible through a public web interface, enabling broader scientific applications.


---
# Loss Terms and Operator Forms of Koopman Autoencoders

## Koopman自动编码器的损失项和算子形式

Link: https://arxiv.org/abs/2412.04578

arXiv:2412.04578v1 Announce Type: cross 
Abstract: Koopman autoencoders are a prevalent architecture in operator learning. But, the loss functions and the form of the operator vary significantly in the literature. This paper presents a fair and systemic study of these options. Furthermore, it introduces novel loss terms.


---
# Deep Learning application for stellar parameters determination: III- Denoising Procedure

## 恒星参数确定的深度学习应用: III-去噪程序

Link: https://arxiv.org/abs/2412.04631

arXiv:2412.04631v1 Announce Type: cross 
Abstract: In this third paper in a series, we investigate the need of spectra denoising for the derivation of stellar parameters. We have used two distinct datasets for this work. The first one contains spectra in the range of 4450-5400 {\AA} at a resolution of 42000 and the second in the range of 8400-8800 {\AA} at a resolution of 11500. We constructed two denoising techniques, an autoencoder, and a Principal Component Analysis. Using random Gaussian noise added to synthetic spectra, we have trained a Neural Network to derive the stellar parameters Teff, log g, ve sin i, {\xi}t, and [M/H] of the denoised spectra. We find that, independently of the denoising technique, the stellar parameters accuracy values do not improve once we denoise the synthetic spectra. This is true with and without applying data augmentation to the stellar parameters Neural Network.


---
# Unveiling hole-facilitated amorphisation in pressure-induced phase transformation of silicon

## 在硅的压力诱导相变中揭示孔促进的非晶化

Link: https://arxiv.org/abs/2412.04732

arXiv:2412.04732v1 Announce Type: cross 
Abstract: Pressure-induced phase transformation occurs during silicon (Si) wafering processes. \b{eta}-tin (Si-II) phase is formed at high pressures, followed by the transformation to Si-XII, Si-III or/and amorphous Si ({\alpha}-Si) phases during the subsequent decompression. While the imposed pressure and its release rate are known to dictate the phase transformation of Si, the effect of charge carriers are ignored. Here, we experimentally unveil that the increased hole concentration facilitates the amorphization in the pressure-induced phase transformation of Si. The underlying mechanism is elucidated by the theoretical calculations based on machine-learning interatomic potentials. The hole-facilitated amorphization is also experimentally confirmed to occur in the indented Ge, GaAs or SiC. We discover that hole concentration is another determining factor for the pressure-induced phase transformations of the industrially important semiconductors.


---
# Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning

## 基于图卷积递归神经网络和残差学习的短期流量和洪水预报

Link: https://arxiv.org/abs/2412.04764

arXiv:2412.04764v1 Announce Type: cross 
Abstract: Accurate short-term streamflow and flood forecasting are critical for mitigating river flood impacts, especially given the increasing climate variability. Machine learning-based streamflow forecasting relies on large streamflow datasets derived from rating curves. Uncertainties in rating curve modeling could introduce errors to the streamflow data and affect the forecasting accuracy. This study proposes a streamflow forecasting method that addresses these data errors, enhancing the accuracy of river flood forecasting and flood modeling, thereby reducing flood-related risk. A convolutional recurrent neural network is used to capture spatiotemporal patterns, coupled with residual error learning and forecasting. The neural network outperforms commonly used forecasting models over 1-6 hours of forecasting horizons, and the residual error learners can further correct the residual errors. This provides a more reliable tool for river flood forecasting and climate adaptation in this critical 1-6 hour time window for flood risk mitigation efforts.


---
# DPGIIL: Dirichlet Process-Deep Generative Model-Integrated Incremental Learning for Clustering in Transmissibility-based Online Structural Anomaly Detection

## DPGIIL: Dirichlet过程-深度生成模型集成增量学习，用于基于传递性的在线结构异常检测中的聚类

Link: https://arxiv.org/abs/2412.04781

arXiv:2412.04781v1 Announce Type: cross 
Abstract: Clustering based on vibration responses, such as transmissibility functions (TFs), is promising in structural anomaly detection, but most existing approaches struggle with determining the optimal cluster number and handling high-dimensional streaming data, while their shallow structures also make them sensitive to manually-engineered feature quality. To bridge this gap, this work proposes the Dirichlet process-deep generative model-integrated incremental learning (DPGIIL) for clustering by combining the advantages of deep generative models (DGMs) in representation learning and the Dirichlet process mixture model (DPMM) in identifying distinct patterns in observed data. By introducing a DPMM prior into the latent space of DGMs, DPGIIL automatically captures dissimilarities in extracted latent representations, enabling both generative modeling and clustering. Within the context of variational Bayesian inference, a lower bound on the log marginal likelihood of DPGIIL, tighter than the evidence lower bound given sufficient training data, is derived analytically, which enables the joint optimization of DGM and DPMM parameters, thereby allowing the DPMM to regularize the DGM's feature extraction process. Additionally, a greedy split-merge scheme-based coordinate ascent variational inference method is devised to accelerate the optimization. The summary statistics of the DPMM, along with the network parameters, are used to retain information about previous data for incremental learning. Notably, this study uses variational autoencoder (VAE) within DPGIIL as an illustrative example, while this framework is adaptable to other DGMs. Two case studies show that the proposed method outperforms some state-of-the-art approaches in structural anomaly detection and clustering, while also dynamically generating new clusters to indicate the emergence of new structural conditions for online monitoring.


---
# Automatic Tissue Differentiation in Parotidectomy using Hyperspectral Imaging

## 使用高光谱成像在腮腺切除术中的自动组织分化

Link: https://arxiv.org/abs/2412.04879

arXiv:2412.04879v1 Announce Type: cross 
Abstract: In head and neck surgery, continuous intraoperative tissue differentiation is of great importance to avoid injury to sensitive structures such as nerves and vessels. Hyperspectral imaging (HSI) with neural network analysis could support the surgeon in tissue differentiation. A 3D Convolutional Neural Network with hyperspectral data in the range of $400-1000$ nm is used in this work. The acquisition system consisted of two multispectral snapshot cameras creating a stereo-HSI-system. For the analysis, 27 images with annotations of glandular tissue, nerve, muscle, skin and vein in 18 patients undergoing parotidectomy are included. Three patients are removed for evaluation following the leave-one-subject-out principle. The remaining images are used for training, with the data randomly divided into a training group and a validation group. In the validation, an overall accuracy of $98.7\%$ is achieved, indicating robust training. In the evaluation on the excluded patients, an overall accuracy of $83.4\%$ has been achieved showing good detection and identification abilities. The results clearly show that it is possible to achieve robust intraoperative tissue differentiation using hyperspectral imaging. Especially the high sensitivity in parotid or nerve tissue is of clinical importance. It is interesting to note that vein was often confused with muscle. This requires further analysis and shows that a very good and comprehensive data basis is essential. This is a major challenge, especially in surgery.


---
# Dirac-Equation Signal Processing: Physics Boosts Topological Machine Learning

## 狄拉克方程信号处理: 物理促进拓扑机器学习

Link: https://arxiv.org/abs/2412.05132

arXiv:2412.05132v1 Announce Type: cross 
Abstract: Topological signals are variables or features associated with both nodes and edges of a network. Recently, in the context of Topological Machine Learning, great attention has been devoted to signal processing of such topological signals. Most of the previous topological signal processing algorithms treat node and edge signals separately and work under the hypothesis that the true signal is smooth and/or well approximated by a harmonic eigenvector of the Hodge-Laplacian, which may be violated in practice. Here we propose Dirac-equation signal processing, a framework for efficiently reconstructing true signals on nodes and edges, also if they are not smooth or harmonic, by processing them jointly. The proposed physics-inspired algorithm is based on the spectral properties of the topological Dirac operator. It leverages the mathematical structure of the topological Dirac equation to boost the performance of the signal processing algorithm. We discuss how the relativistic dispersion relation obeyed by the topological Dirac equation can be used to assess the quality of the signal reconstruction. Finally, we demonstrate the improved performance of the algorithm with respect to previous algorithms. Specifically, we show that Dirac-equation signal processing can also be used efficiently if the true signal is a non-trivial linear combination of more than one eigenstate of the Dirac equation, as it generally occurs for real signals.


---
# Fast Laplace transforms on quantum computers

## 量子计算机上的快速拉普拉斯变换

Link: https://arxiv.org/abs/2412.05173

arXiv:2412.05173v1 Announce Type: cross 
Abstract: While many classical algorithms rely on Laplace transforms, it has remained an open question whether these operations could be implemented efficiently on quantum computers. In this work, we introduce the Quantum Laplace Transform (QLT), which enables the implementation of $N\times N$ discrete Laplace transforms on quantum states encoded in $\lceil \log_2(N)\rceil$-qubits. In many cases, the associated quantum circuits have a depth that scales with $N$ as $O(\log(\log(N)))$ and a size that scales as $O(\log(N))$, requiring exponentially fewer operations and double-exponentially less computational time than their classical counterparts. These efficient scalings open the possibility of developing a new class of quantum algorithms based on Laplace transforms, with potential applications in physics, engineering, chemistry, machine learning, and finance.


---
# Toward Routing River Water in Land Surface Models with Recurrent Neural Networks

## 使用递归神经网络在地表模型中路由河水

Link: https://arxiv.org/abs/2404.14212

arXiv:2404.14212v5 Announce Type: replace 
Abstract: Machine learning is playing an increasing role in hydrology, supplementing or replacing physics-based models. One notable example is the use of recurrent neural networks (RNNs) for forecasting streamflow given observed precipitation and geographic characteristics. Training of such a model over the continental United States (CONUS) has demonstrated that a single set of model parameters can be used across independent catchments, and that RNNs can outperform physics-based models. In this work, we take a next step and study the performance of RNNs for river routing in land surface models (LSMs). Instead of observed precipitation, the LSM-RNN uses instantaneous runoff calculated from physics-based models as an input. We train the model with data from river basins spanning the globe and test it using historical streamflow measurements. The model demonstrates skill at generalization across basins (predicting streamflow in catchments not used in training) and across time (predicting streamflow during years not used in training). We compare the predictions from the LSM-RNN to an existing physics-based model calibrated with a similar dataset and find that the LSM-RNN outperforms the physics-based model: a gain in median NSE from 0.56 to 0.64 (time-split experiment) and from 0.30 to 0.34 (basin-split experiment). Our results show that RNNs are effective for global streamflow prediction from runoff inputs and motivate the development of complete routing models that can capture nested sub-basis connections.


---
# Using skateboarding to develop a culturally relevant tutorial on static equilibrium

## 使用滑板开发静态平衡的文化相关教程

Link: https://arxiv.org/abs/2406.17625

arXiv:2406.17625v2 Announce Type: replace 
Abstract: Culturally relevant pedagogy (CRP), initially developed by Ladson-Billings, is an instructional framework for supporting diverse learners by drawing on their cultural backgrounds and experiences. In line with the CRP framework, we developed a tutorial on static equilibrium using skateboarding, a popular activity on university campuses, as a culturally relevant context. To address specific student conceptions about static equilibrium documented in the physics education research (PER) literature, we used the elicit-confront-resolve (ECR) strategy to develop the tutorial. In this paper, we provide a detailed account of how we operationalized the ECR strategy in designing the sequences of questions in the tutorial. Additionally, we present anecdotal evidence to show that the culturally relevant tutorial appears to effectively engage students and motivate their interest in learning physics.


---
# How polarization fields can be beneficial in nitride emitters

## 极化场如何在氮化物发射器中受益

Link: https://arxiv.org/abs/2410.23591

arXiv:2410.23591v2 Announce Type: replace 
Abstract: We revisit the prevailing notion that spontaneous and piezoelectric polarization fields are inherently detrimental to light emission in polar semiconductor heterostructures. Here, we demonstrate that polarization can actually enhance the overlap of electron and hole wave functions in III-nitride quantum wells, which are being considered for polychromatic micron-scale pixels in extended-reality and biomedical applications. By systematically exploring the design space of AlInGaN heterostructures with machine learning, we uncover that larger electric fields globally correlate with higher wave-function overlaps for red emitters. The key is the quantum-confined Stark effect, which enables a reduction in well width while avoiding the associated increase in In composition. Our work demonstrates the use of machine learning to reveal unexpected trends for informing the design of semiconductor heterostructures.


---
# Dreaming Learning

## 做梦学习

Link: https://arxiv.org/abs/2410.18156

arXiv:2410.18156v2 Announce Type: replace-cross 
Abstract: Incorporating novelties into deep learning systems remains a challenging problem. Introducing new information to a machine learning system can interfere with previously stored data and potentially alter the global model paradigm, especially when dealing with non-stationary sources. In such cases, traditional approaches based on validation error minimization offer limited advantages. To address this, we propose a training algorithm inspired by Stuart Kauffman's notion of the Adjacent Possible. This novel training methodology explores new data spaces during the learning phase. It predisposes the neural network to smoothly accept and integrate data sequences with different statistical characteristics than expected. The maximum distance compatible with such inclusion depends on a specific parameter: the sampling temperature used in the explorative phase of the present method. This algorithm, called Dreaming Learning, anticipates potential regime shifts over time, enhancing the neural network's responsiveness to non-stationary events that alter statistical properties. To assess the advantages of this approach, we apply this methodology to unexpected statistical changes in Markov chains and non-stationary dynamics in textual sequences. We demonstrated its ability to improve the auto-correlation of generated textual sequences by $\sim 29\%$ and enhance the velocity of loss convergence by $\sim 100\%$ in the case of a paradigm shift in Markov chains.


---
# Explainable Synthesizability Prediction of Inorganic Crystal Polymorphs using Large Language Models

## 使用大型语言模型对无机晶体多晶型物的可解释的可合成性预测

Link: https://dx.doi.org/10.26434/chemrxiv-2024-ltncz-v2?rft_dat=source%3Ddrss

We evaluate the ability of machine learning to predict whether a hypothetical crystal structure can be synthesized and explain those predictions to scientists. Fine-tuned large language models (LLMs) trained on a human-readable text description of the target crystal structure perform comparably to previous bespoke convolutional graph neural network methods, but better prediction quality can be achieved by training a positive-unlabeled learning model on a text-embedding representation of the structure. An LLM-based workflow can then be used to generate human-readable explanations for the types of factors governing synthesizability, extract the underlying physical rules, and assess the veracity of those rules. These explanations can guide chemists in modifying or optimizing non-synthesizable hypothetical structures to make them more feasible for materials design.


---
# Chat-Microreactor: A Large-Language-Model-Based Assistant for Designing Continuous Flow Systems

## Chat-微反应器: 用于设计连续流系统的基于大语言模型的助手

Link: https://dx.doi.org/10.26434/chemrxiv-2024-52g9l?rft_dat=source%3Ddrss

Continuous flow in microchannels play pivotal roles in advancing automated chemical synthesis. However, frequent multiphase reactions pose key challenges for designing reactors that efficiently disperse phases. Although effort has been directed toward automating development processes, the unique nature of each existing study offers limited opportunities for generalization; consequently applying this knowledge to new microreactor designs is difficult. In this study, we introduce a self-optimizing workflow that uses large language models (LLMs) to extract key microreactor-system parameters, such as density, velocity, and Capillary number, from the literature. Minimal training led to a reduction in extraction time from 24 to 16 s, with the collected data processed by ensemble learning models delivering F1 scores greater than 70% when classifying flow patterns. Through interpretability analysis, we confirmed the machine learning model's alignment with human expertise. We then applied the model to an oil-water dispersion system for controlled alumina microsphere preparation and a piperacillin synthesis system, achieving accuracy rates of 83% and 94%, respectively. This study offers synthetic chemists an LLM-based tool for the development of microreactor systems, thereby pioneering the use of machine learning in literature-sparse fields.


---
# Constructing Machine Learning-Based Risk Prediction Model for Osteoarthritis in Population Aged 45 and Above (NHANES 2011-2018)

## 构建基于机器学习的45岁及以上人群骨关节炎风险预测模型 (NHANES 2011-2018)

Link: https://www.researchsquare.com/article/rs-5310125/latest

Background: Osteoarthritis is a widespread chronic joint disease, becoming increasingly common in prevalence among individuals over the age of 45. This condition not only leads to joint pain and dysfunction but also significantly disrupts the patients&rsquo; daily life. Therefore, the objective of this study is to develop an interpretable machine learning model for predicting the risk of osteoarthritis in individuals aged 45 and above.
Methods: This study utilized data from the National Health and Nutrition Examination Survey(NHANES) from 2011 to 2018, including a total of 2980 individuals. The dataset was randomly divided into a training set (n=2235) and a validation set (n=745). Five machine learning algorithms were employed to develop the predictive model for osteoarthritis. The SHapley Additive exPlanation (SHAP) method was used to interpret the ML algorithms and identify the factors that made the most significant contribution to the prediction outcomes.
Results: A total of 2980 individuals were included, with an average age of 60 years, of whom 605 were diagnosed with osteoarthritis. Twenty-four variables were included in the modeling, and five machine learning algorithms were used to predict the risk of osteoarthritis. After feature selection using Recursive Feature Elimination(RFE), the CatBoost model with 20 variables showed the best prediction performance. The most influential predictors were Gender, Age, BMI, Waist circumference, and Race.
Conclusion: This study demonstrates that the CatBoost model with 20 variables can effectively predict the occurrence of osteoarthritis.


---
# Configurations of Training Transfer Performance in Near and Far Contexts: A Fuzzy-set Qualitative Comparative Analysis of Values-Driven Leadership Development

## 远近环境中培训转移绩效的配置: 价值观驱动的领导力发展的模糊集定性比较分析

Link: https://www.researchsquare.com/article/rs-5265692/latest

Modern enterprises frequently utilize various training activities to enhance employees&rsquo; job-related skills, and the success of training programs largely depends on effective training transfer. High training transfer rates&nbsp;are&nbsp;crucial for business development and achieving a favorable return on investment. Therefore, exploring pathways to achieve high&nbsp;training transfer holds substantial theoretical and practical significance.&nbsp;Through integrative theoretical perspectives, this study&nbsp;constructs a model of influencing factors of training transfer. Taking 216 members of the first and second phases of the State Grid Values-Driven Leadership Development Program&nbsp;as research objects, we employed a combination of NCA and fsQCA methods to identify various configurations that affect both&nbsp;near and far&nbsp;training transfer&nbsp;performance.&nbsp;The findings&nbsp;indicate that: (1) Transfer design is necessary for high training transfer performance in both near and far&nbsp;ends and plays an indispensable role in generating high training transfer performance.&nbsp;(2) Three configurations&nbsp;can generate high training transfer performance:&nbsp;organization leads&nbsp;to compensate for individual characteristics, organizational&nbsp;guidance to individuals, and individual-organization-environment co-driving. The latter configuration&nbsp;covers the largest number of participants, indicating the importance of fostering cooperation and mutual support among these three elements to enhance positive interactions and improve training outcomes.&nbsp;(3) The set composition of near and far ends&nbsp;configurations varies, with project identification&nbsp;and team learning atmosphere having a more substantial impact on the near&nbsp;end. At the same time, execution&nbsp;instrumentality&nbsp;and organizational support play a more critical role in the long term. This study offers valuable theoretical and practical insights for optimizing the Values-Driven Leadership Development Program&nbsp;system and achieving high-quality training transformation.


---
# Does automated 3D computed tomography bronchography and angiography improve anatomical teaching in pulmonary segmentectomy?

## 自动3D计算机断层扫描支气管造影和血管造影是否可以改善肺段切除术的解剖教学？

Link: https://www.researchsquare.com/article/rs-5403676/latest

Purpose
As pulmonary segmentectomy becomes increasingly common in the treatment of early-stage lung cancer, it is essential to provide relevant clinical training for residents. Three-dimensional CT bronchography and angiography (3D-CTBA) effectively illustrate the spatial relationships among the bronchi, arteries, and veins of pulmonary segments. This study aimed to evaluate the efficacy of automated 3D-CTBA technology in enhancing anatomical education for pulmonary segmentectomy training.
Methods
Fifty-two surgical residents were randomized into two groups: the 3D-CTBA group and the control group. The 3D-CTBA group utilized automated 3D-CTBA technology alongside specific case for segmentectomy training, while the control group relied on traditional teaching methods. After the training sessions, all participants completed a post-training assessment and questionnaires. Additionally, we collected feedback from instructors regarding the residents' performance through a separate questionnaire.
Results
Residents in the 3D-CTBA group achieved significantly higher scores on the post-training assessments compared to those in the control group (83.46&thinsp;&plusmn;&thinsp;6.75 vs. 68.27&thinsp;&plusmn;&thinsp;8.12, p&thinsp;&amp;lt;&thinsp;0.001). Subjective survey results indicated that automated 3D-CTBA technology greatly benefited residents in preoperatively identifying tumor locations, recognizing anatomical variations during surgery, and mastering relevant surgical techniques. Feedback from instructors indicated that residents in the 3D-CTBA group performed better intraoperatively than those in the control group. Furthermore, residents in the 3D-CTBA group expressed greater interest in learning and higher satisfaction with the course.
Conclusion&amp;nbsp;
Automated 3D-CTBA technology significantly enhanced residents' comprehension of the complex and variable anatomy of pulmonary segments, thereby improving their related surgical skills.


---
# Predicting 5-Year Survival in Gastric Cancer Patients Using Iliopsoas Muscle CT Radiomics and Machine Learning Techniques

## 使用髂腰肌CT影像组学和机器学习技术预测胃癌患者的5年生存率

Link: https://www.researchsquare.com/article/rs-5350805/latest

Objectives Sarcopenia, linked to postoperative survival in cancer patients, was investigated in this study. The research explored the relationship between CT imaging features of muscles in gastric cancer patients and their survival. Additionally, the study aimed to create a quantifiable survival prediction model using artificial intelligence.Methods In a retrospective study, 100 patients who underwent radical gastrectomy for gastric cancer were analyzed. After identifying sarcopenia using the psoas muscle index, clinical factors related to patient survival were investigated. Imaging features were extracted from manually delineated iliopsoas muscles and used in 11 machine learning algorithms. After completing the model training, we used a dataset comprising 34 patients from a secondary center as an external validation set to evaluate the model&amp;rsquo;s classification performance. After identifying the optimal model, we further explored the fusion methods of clinical omics and radiomics. Based on this, we constructed a predictive model for estimating the five-year survival rate of patients.Results Clinical survival analysis highlighted age and tumor M stage as relevant factors. For the task of predicting five-year survival, we found that the Logistic Regression (LR) model without clinical feature fusion exhibited the most balanced and superior performance. Specifically, the AUC (Area Under Curve) values of this model on the training set, internal validation set, and external validation set were 0.82, 0.72, and 0.69, respectively. Additionally, the model&amp;rsquo;s accuracy remained relatively stable, approximately around 70%.Conclusions In this study, we developed a machine learning model based on preoperative CT imaging data of gastric cancer patients to predict their five-year survival rate. The model can achieve about 70% accuracy. Additionally, we explored the necessity and rationale of incorporating clinical independent factors into this predictive model. The results indicated a significant correlation between muscle imaging features and overall patient survival, highlighting the importance of sarcopenia in the clinical management of gastric cancer patients.


---
# ISEBC: Using A Novel Breast Cancer Tertiary Lymphoid Structures Signature To Build An Immune-favourable Status Evaluator For Breast Cancer

## ISEBC: 使用一种新的乳腺癌三级淋巴结构特征来构建乳腺癌的免疫有利状态评估器

Link: https://www.researchsquare.com/article/rs-5376285/latest

Tertiary lymphoid structures (TLSs), as a special type of immune-infiltrated region in tumor tissues, plays an important role in benefiting from immunotherapy or improving immune state of breast cancer patient. However, breast cancer-specific TLS signature gene sets are still lacking. Therefore, we extracted gene features with machine learning algorithm LightGBM, and differential expression genes with statistical test on multiple spatial transcriptome datasets, to finally obtain a novel breast cancer-specific TLS gene set (NBCTS). Compared with previous gene sets, it has stronger characterization ability of TLS in breast cancer samples. Since TLS have unique immune characteristics, we classified three different immune states using this gene set for breast cancer patients and get an immune state. To better facilitate evaluating this immune statuses of breast cancer patients or samples, we developed a user-friendly web tool (Immune State Evaluator for Breast Cancer, (ISEBC),www.omegene.tech:3838/ISEBC) to make it more convenient for researchers and clinicians to use.


---
# Predictive Biomarkers for TNF Inhibitor Response in Rheumatoid Arthritis: A Proteomics-based Machine Learning Approach

## 类风湿关节炎中TNF抑制剂反应的预测生物标志物: 基于蛋白质组学的机器学习方法

Link: https://www.researchsquare.com/article/rs-5376956/latest

Rheumatoid arthritis (RA), a prevalent systemic autoimmune disease, affects 0.5&amp;ndash;1% of the global population and is characterized by persistent joint inflammation and potential bone damage. Despite the utilization of Disease-Modifying Antirheumatic Drugs (DMARDs) and TNF inhibitors (TNFi) to manage RA, approximately one-third of patients do not response to these treatments, underscoring the urgent need for more precise therapeutic approaches. This study presents a proteomics-based machine learning approach to identify serum biomarkers capable of predicting individual patient responses to TNFi therapy, specifically infliximab By analyzing serum samples from 71 responders and 122 non-responders using Data-Independent Acquisition mass spectrometry (DIA-MS) for comprehensive proteomic profiling, we identified a panel of 10 multi-biomarkers, SAA2, MBL2, CLU, F5, FCGBP, IGFBP3, FGA, PROS1 and PCOLCE. These biomarkers are closely linked to key biological processes in RA, such as inflammation (SAA2, MBL2), immune modulation (CLU, FCGBP), coagulation (F5, PROS1, FGA), and tissue remodeling (PCOLCE). A logistic regression model utilizing these biomarkers achieved an accuracy of 82%, with a sensitivity of 0.74 and a specificity of 0.87. These biomarkers correlating with RA disease activity and patient response to infliximab, have the potential to enable a predictive model for personalized treatment. The advancement suggests a future shift towards a more predictive, personalized approach in RA management, potentially Improving by reducing the reliance on the current trial-and-error method in therapy selection.


---
# Habitat Radiomics Analysis for Progression Free Survival and Immune-related Adverse Reaction Prediction in Non-small Cell Lung Cancer Treated by Immunotherapy

## Habitat放射组学分析免疫治疗非小细胞肺癌的无进展生存期及免疫相关不良反应预测

Link: https://www.researchsquare.com/article/rs-5058915/latest

Background Non-small cell lung cancer (NSCLC) is highly heterogeneous, leading to varied treatment responses and immune-related adverse reactions (irAEs) among patients. Habitat radiomics allows non-invasive quantitative assessment of intratumor heterogeneity (ITH). Therefore, our objective is to employ habitat radiomics techniques to develop a robust approach for predicting the efficacy of Immune checkpoint inhibitors (ICIs) and the likelihood of irAEs in advanced NSCLC patients.Methods In this retrospective two center study, two independent cohorts of patients with NSCLC were used to develop (n&amp;thinsp;=&amp;thinsp;248) and validate signatures (n&amp;thinsp;=&amp;thinsp;95). After applying four kinds of machine learning algorithms to select the key preoperative CT radiomic features, we used clinical, radiomics and habitat radiomic features to develop the clinical signature, radiomics signature and habitat radiomic signature for ICIs prognostics and irAEs prediction. By combining habitat radiomic features with corresponding clinicopathologic information, the nomogram signature was constructed in the training cohort. Next, the internal validation cohort (n&amp;thinsp;=&amp;thinsp;75) of patients, and the external validation cohort (n&amp;thinsp;=&amp;thinsp;20) of patients treated with ICIs were included to evaluate the predictive value of the four signatures, and their predictive performance was assessed by the area under operating characteristic curve (AUC).Results Our study introduces a radiomic nomogram model that integrates clinical and habitat radiomic features to identify patients who may benefit from ICIs or experience irAEs. The Radiomics Nomogram model exhibited superior predictive performance in the training, validation, and external validation sets, with AUCs of 0.923, 0.817, and 0.899, respectively. This model outperformed both the Whole-tumor Radiomics Signature model (AUCs of 0.870, 0.736, and 0.626) and the Habitat Signature model (AUCs of 0.900, 0.804, and 0.808). The radiomics model focusing on tumor sub-regional habitat showed better predictive performance than the model derived from the entire tumor. Decision Curve Analysis (DCA) and calibration curves confirmed the nomogram's effectiveness.Conclusion By leveraging machine learning to predict the outcomes of ICIs, we can move closer to achieving tailored ICIs for lung cancer. This advancement will assist physicians in selecting and managing subsequent treatment strategies, thereby facilitating clinical decision-making.


---
# RvD1 Combined with Exercise Promotes Mitophagy and Reduces Neuronal Apoptosis in Mice After Intracerebral Hemorrhage via the BDNF/TrkB/PI3K/AKT Pathway

## RvD1联合运动通过BDNF/TrkB/PI3K/AKT通路促进小鼠脑出血后线粒体吞噬并减少神经元凋亡

Link: https://www.researchsquare.com/article/rs-5092487/latest

Resolvin D1 (RvD1) is an endogenous anti-inflammatory mediator that can modulate the inflammatory response and promote inflammation resolution. RvD1 has been shown to exert neuroprotective effects in various central nervous system contexts; however, its role in the pathophysiological processes of Intracerebral hemorrhage (ICH) and the potential protective mechanisms when combined with exercise rehabilitation training remain unclear. In this study, we aimed to investigate whether RvD1 combined with exercise rehabilitation training could protect against neurological deficits in ICH mice by activating the BDNF/TrkB/PI3K/AKT signaling pathway, improve cognitive function, reduce neuronal apoptosis and inflammatory response, and explore its relationship with mitochondrial autophagy. A mouse model of ICH was established using collagenase, and treatment with RvD1 combined with three weeks of exercise rehabilitation significantly improved neurological deficits, muscle strength, learning and memory in the cerebral hemorrhage mice while reducing anxiety-like behavior. RvD1 combined with exercise rehabilitation training can up-regulate anti-inflammatory factors, inhibit inflammatory state and activate BDNF/TrkB/PI3K/ akt related pathway.TUNEL staining confirmed a decrease in residual apoptotic neurons, while transmission electron microscopy showed an increase in mitochondrial autophagosomes with combined treatment. Mendelian randomization and molecular docking further confirmed the association of RvD1 with targets related to mitophagy and inflammatory factors, thereby clarifying the mechanism of RvD1 involvement.In summary, RvD1 combined with exercise rehabilitation can activate the BDNF/TrkB/PI3K/AKT signaling pathway, effectively reduce neuronal apoptosis and inflammatory responses following ICH in mice, and participate in mitochondrial autophagy-related states. This comprehensive therapeutic strategy promotes neurological recovery and provides insights for the clinical management of this condition.


---
# Support Vector Machines for Optimal Channel Decoding

## 用于最优信道解码的支持向量机

Link: https://www.researchsquare.com/article/rs-5282189/latest

In this work, we investigate channel decoding techniques based on machine learning, and more specifically, on Support Vector Machines (SVM). Existing SVM-based decoders suffer from a scalability problem, characterized by the exponential growth of both the number of classifiers required to decode and the size of the training dataset as a function of the code dimension. This phenomenon, often referred to as the curse of dimensionality, renders existing SVM approaches impractical for larger codes. To address this limitation, we introduce a novel bit-wise SVM decoding strategy coupled with a noiseless optimization framework, which significantly reduces the computational burden. Specifically, for a code of length $n$ and dimension $k$, our approach decreases the number of SVM classifiers from an exponential dependence to a linear in $k$, while the required training dataset is minimized to a single noiseless codeword per class. We formulate the resulting optimization problem and derive its analytical solution. Moreover, we demonstrate that, under specific conditions, the solution of the optimization process produced by the proposed framework is equivalent to the optimal Maximum Likelihood (ML) decoding rule when applied to transmissions over Additive White Gaussian Noise (AWGN) channels.


---
# Neural-Network-Assisted Detection of Superconducting Topological Semimetals

## 超导拓扑半金属的神经网络辅助检测

Link: https://www.researchsquare.com/article/rs-5368971/latest

Diagnosing nontrivial topology is one of the core pursuits of modern condensed matter physics. Up to date, a wide range of theoretical techniques have been developed for this purpose. However, the majority of these are tailored for analyzing theoretical models, rather than actual experiments. Here, we propose a machine-learning-based protocol for the identification of two-dimensional superconducting topological semimetals using superfluid stiffness data as an input. In their normal phase, these superconductors contain band touching points (BTPs) which carry nonzero topological charges, i.e., vorticities. Our method relies on detecting certain vorticity-associated patterns encoded in heat maps of the superfluid stiffness obtained by varying the chemical potential and an applied Zeeman field. We show that our neural network attains a notably high accuracy in predicting the energy-resolved total absolute vorticity of BTPs. We reach to this conclusion by testing our approach against superfluid stiffness data theoretically-obtained from suitable extended-Dirac and graphene models.


---
# User wants, needs and resistance in the postdigital university: prioritizing pedagogical concerns in learning analytics design

## 后数字大学的用户需求，需求和阻力: 在学习分析设计中优先考虑教学问题

Link: https://www.researchsquare.com/article/rs-5561942/latest

Despite the increasing interest in learning analytics over the past decade, there remains relatively little integration with pedagogical practice in higher education. The limited engagement of teachers in the design and development of teacher facing dashboards has been cited as a significant issue. As the purpose of a teacher facing dashboard is to enable deep insights into student learning as a basis for data-driven decision making, successful integration depends on compatibility with pedagogical needs and intentions. In this paper, we outline findings from a series of focus groups with nautical simulator instructors (n=12) from three different universities in Sweden, Norway and Finland. During focus groups, the design concept of multimodal learning analytics was presented and discussed, with focus on the usefulness of a teacher-facing learning analytics dashboard in addressing typical instructional concerns during simulation-based training. In the analysis, we focus on the juxtaposition between user wants, needs and resistance, prioritizing the simulator instructors&rsquo; pedagogical concerns in learning analytics design. The findings highlight a crucial gap between the technological capabilities of learning analytics and the practical, everyday challenges of teaching in simulation-based environments. To bridge this gap, it is essential to design dashboards that are not only professionally intuitive and data-rich but also adaptable to the specific pedagogical strategies of instructors. Ultimately, successful implementation depends on a user-centered design process that integrates instructors&rsquo; perspectives, ensuring that learning analytics tools align with the complexities of simulation-based training.


---
# Revealing drivers of green technology adoption through explainable AI

## 通过可解释的AI揭示绿色技术采用的驱动因素

Link: https://www.researchsquare.com/article/rs-5367657/latest

Effective governance of energy system transformations away from fossil resources requires a quantitative understanding of the diffusion of green technologies and its key influencing factors. In this article, we propose a novel machine learning approach to diffusion research focusing on actual decisions and spatial aspects complementing research on intentions and temporal dynamics. We develop machine learning models that predict regional differences in the accumulated peak power of household-scale photovoltaic systems and the share of battery electric vehicles from a large set of demographic, geographic, political, and socio-economic features. Tools from explainable artificial intelligence enable a consistent identification of the key influencing factors and quantify their impact. Focusing on data from German municipal associations, we identify common themes and differences in the diffusion of green technologies.

