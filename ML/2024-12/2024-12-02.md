# Photonic processor could enable ultrafast AI computations with extreme energy efficiency

## 光子处理器可以实现具有极高能效的超快AI计算

Link: https://phys.org/news/2024-12-photonic-processor-enable-ultrafast-ai.html

The deep neural network models that power today's most demanding machine-learning applications have grown so large and complex that they are pushing the limits of traditional electronic computing hardware.


---
# Evolving learning styles

## 不断发展的学习风格

Link: https://www.nature.com/articles/s41557-024-01679-7

<p>Nature Chemistry, Published online: 02 December 2024; <a href="https://www.nature.com/articles/s41557-024-01679-7">doi:10.1038/s41557-024-01679-7</a></p>In grad school, there is time to focus on learning about your field and your project — and to keep up with the literature. Now, as an assistant professor, Shira Joudan explains how learning science is necessarily different as they manage multiple projects and a busy schedule.


---
# AI in biomaterials discovery: generating self-assembling peptides with resource-efficient deep learning

## 生物材料发现中的人工智能: 通过资源高效的深度学习生成自组装肽

Link: https://www.nature.com/articles/s42256-024-00936-1

<p>Nature Machine Intelligence, Published online: 02 December 2024; <a href="https://www.nature.com/articles/s42256-024-00936-1">doi:10.1038/s42256-024-00936-1</a></p>Recurrent neural networks are efficient and capable agents for discovering new peptides with strong self-organizing capabilities.


---
# Optical computing and artificial intelligence

## 光学计算和人工智能

Link: https://www.nature.com/articles/s41566-024-01582-0

<p>Nature Photonics, Published online: 02 December 2024; <a href="https://www.nature.com/articles/s41566-024-01582-0">doi:10.1038/s41566-024-01582-0</a></p>Light-based processing and machine learning featured heavily in San Diego at the 2024 SPIE Optics + Photonics conference. Enthusiasm was coupled with questions related to the real-world applicability and the merits of linear vs non-linear, and all-optical vs hybrid, approaches.


---
# [ASAP] A Universal Method for Fingerprinting Multiplexed Bacteria: Evolving Pruned Sensor Arrays via Machine Learning-Driven Combinatorial Group-Specificity Strategy

## [ASAP] 指纹识别多重细菌的通用方法: 通过机器学习驱动的组合组特异性策略进化修剪的传感器阵列

Link: http://dx.doi.org/10.1021/acsnano.4c10203

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acsnano.4c10203/asset/images/medium/nn4c10203_0008.gif" /></p><div><cite>ACS Nano</cite></div><div>DOI: 10.1021/acsnano.4c10203</div>


---
# [ASAP] Machine Learning-Assisted, Dual-Channel CRISPR/Cas12a Biosensor-In-Microdroplet for Amplification-Free Nucleic Acid Detection for Food Authenticity Testing

## [ASAP] 机器学习辅助的双通道CRISPR/Cas12a生物传感器-微液滴，用于无扩增核酸检测，用于食品真实性测试

Link: http://dx.doi.org/10.1021/acsnano.4c10823

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acsnano.4c10823/asset/images/medium/nn4c10823_0008.gif" /></p><div><cite>ACS Nano</cite></div><div>DOI: 10.1021/acsnano.4c10823</div>


---
# Kinetics of orbital ordering in cooperative Jahn-Teller models: Machine-learning enabled large-scale simulations

## 合作jahn-teller模型中轨道排序的动力学: 机器学习支持的大规模模拟

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.8.123602

Author(s): Supriyo Ghosh, Sheng Zhang, Chen Cheng, and Gia-Wei Chern<br /><p>We present a scalable machine-learning (ML) force-field model for the adiabatic dynamics of cooperative Jahn-Teller (JT) systems. Large-scale dynamical simulations of the JT model also shed light on the orbital ordering dynamics in colossal magnetoresistance manganites. The JT effect in these materi…</p><br />[Phys. Rev. Materials 8, 123602] Published Mon Dec 02, 2024


---
# Deep learning of spectra: Predicting the dielectric function of semiconductors

## 光谱的深度学习: 预测半导体的介电函数

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.8.L122201

Author(s): Malte Grunert, Max Großmann, and Erich Runge<br /><p>Predicting spectra and related properties such as the dielectric function of crystalline materials based on machine learning has a huge, hitherto unexplored, technological potential. For this reason, we create an <i>ab initio</i> database of 9915 dielectric tensors of semiconductors and insulators calculat…</p><br />[Phys. Rev. Materials 8, L122201] Published Mon Dec 02, 2024


---
# Predictive evaluation of hydrogen diffusion coefficient on Pd(111) surface by path integral simulations using neural network potential

## 基于神经网络势的路径积分模拟预测Pd(111) 表面氢扩散系数

Link: http://link.aps.org/doi/10.1103/PhysRevResearch.6.043224

Author(s): Yuta Kataoka, Jun Haruyama, Osamu Sugino, and Motoyuki Shiga<br /><p>Quantum diffusion of hydrogen (H) on palladium (Pd) (111) was studied using two types of path integral simulations: quantum transition state theory (QTST) and ring polymer molecular dynamics (RPMD). The use of an artificial neural network potential trained by density functional theory calculations h…</p><br />[Phys. Rev. Research 6, 043224] Published Mon Dec 02, 2024


---
# Nonlinear transformation of complex amplitudes via quantum singular value transformation

## 基于量子奇异值变换的复振幅非线性变换

Link: http://link.aps.org/doi/10.1103/PhysRevResearch.6.043227

Author(s): Naixu Guo, Kosuke Mitarai, and Keisuke Fujii<br /><p>Due to the linearity of quantum operations, it is not straightforward to implement nonlinear transformations on a quantum computer, making some practical tasks like a neural network hard to achieve. In this paper, we define a task called <i>nonlinear transformation of complex amplitudes</i> and provide an …</p><br />[Phys. Rev. Research 6, 043227] Published Mon Dec 02, 2024


---
# Shock compression pathways to pyrite silica from machine learning simulations

## 从机器学习模拟到黄铁矿二氧化硅的冲击压缩途径

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.224101

Author(s): Shuning Pan, Jiuyang Shi, Zhixin Liang, Cong Liu, Junjie Wang, Yong Wang, Hui-Tian Wang, Dingyu Xing, and Jian Sun<br /><p>Silica is a fundamental component of planetary interiors, and the knowledge of its high-pressure polymorphs is essential for constructing planetary models. The pyrite silica has been synthesized in static compression with diamond anvil cells, however, it has never been observed in dynamic compressio…</p><br />[Phys. Rev. B 110, 224101] Published Mon Dec 02, 2024


---
# Globally stable and metastable crystal structure enumeration using polynomial machine learning potentials for elemental As, Bi, Ga, In, La, P, Sb, Sn, and Te

## 使用多项式机器学习潜力对元素As，Bi，Ga，In，La，P，Sb，Sn和Te进行全局稳定和亚稳态晶体结构枚举

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.224102

Author(s): Atsuto Seko<br /><p>Machine learning potentials (MLPs) have become indispensable for conducting accurate large-scale atomistic simulations and for the efficient prediction of crystal structures. Polynomial MLPs, defined by polynomial rotational invariants, have been systematically developed for a wide range of elementa…</p><br />[Phys. Rev. B 110, 224102] Published Mon Dec 02, 2024


---
# Coarsening of chiral domains in itinerant electron magnets: A machine learning force-field approach

## 巡回电子磁体中手性域的粗化: 机器学习力场方法

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.245105

Author(s): Yunhao Fan, Sheng Zhang, and Gia-Wei Chern<br /><p>Frustrated itinerant magnets often exhibit complex noncollinear or noncoplanar magnetic orders which support topological electronic structures. A canonical example is the anomalous quantum Hall state with a chiral spin order stabilized by electron-spin interactions on a triangular lattice. While a l…</p><br />[Phys. Rev. B 110, 245105] Published Mon Dec 02, 2024


---
# Machine learning materials properties with accurate predictions, uncertainty estimates, domain guidance, and persistent online accessibility

## 具有准确预测、不确定性估计、领域指导和持续在线可访问性的机器学习材料属性

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad95db

One compelling vision of the future of materials discovery and design involves the use of machine learning (ML) models to predict materials properties and then rapidly find materials tailored for specific applications. However, realizing this vision requires both providing detailed uncertainty quantification (model prediction errors and domain of applicability) and making models readily usable. At present, it is common practice in the community to assess ML model performance only in terms of prediction accuracy (e.g. mean absolute error), while neglecting detailed uncertainty quantification and robust model accessibility and usability. Here, we demonstrate a practical method for realizing both uncertainty and accessibility features with a large set of models. We develop random forest ML models for 33 materials properties spanning an array of data sources (computational and experimental) and property types (electrical, mechanical, thermodynamic, etc). All models have calibrated ensemble error bars to quantify prediction uncertainty and domain of applicability guidance enabled by kernel-density-estimate-based feature distance measures. All data and models are publicly hosted on the Garden-AI infrastructure, which provides an easy-to-use, persistent interface for model dissemination that permits models to be invoked with only a few lines of Python code. We demonstrate the power of this approach by using our models to conduct a fully ML-based materials discovery exercise to search for new stable, highly active perovskite oxide catalyst materials.


---
# Decoding Non-Linearity and Complexity: Deep Tabular Learning Approaches for Materials Science

## 解码非线性和复杂性: 材料科学的深度表格学习方法

Link: https://arxiv.org/abs/2411.18717

arXiv:2411.18717v1 Announce Type: new 
Abstract: Materials data, especially those related to high-temperature properties, pose significant challenges for machine learning models due to extreme skewness, wide feature ranges, modality, and complex relationships. While traditional models like tree-based ensembles (e.g., XGBoost, LightGBM) are commonly used for tabular data, they often struggle to fully capture the subtle interactions inherent in materials science data. In this study, we leverage deep learning techniques based on encoder-decoder architectures and attention-based models to handle these complexities. Our results demonstrate that XGBoost achieves the best loss value and the fastest trial duration, but deep encoder-decoder learning like Disjunctive Normal Form architecture (DNF-nets) offer competitive performance in capturing non-linear relationships, especially for highly skewed data distributions. However, convergence rates and trial durations for deep model such as CNN is slower, indicating areas for further optimization. The models introduced in this study offer robust and hybrid solutions for enhancing predictive accuracy in complex materials datasets.


---
# A Machine Learning Approach Capturing Hidden Parameters in Autonomous Thin-Film Deposition

## 一种自动薄膜沉积中隐藏参数的机器学习方法

Link: https://arxiv.org/abs/2411.18721

arXiv:2411.18721v1 Announce Type: new 
Abstract: The integration of machine learning and robotics into thin film deposition is transforming material discovery and optimization. However, challenges remain in achieving a fully autonomous cycle of deposition, characterization, and decision-making. Additionally, the inherent sensitivity of thin film growth to hidden parameters such as substrate conditions and chamber conditions can compromise the performance of machine learning models. In this work, we demonstrate a fully autonomous physical vapor deposition system that combines in-situ optical spectroscopy, a high-throughput robotic sample handling system, and Gaussian Process Regression models. By employing a calibration layer to account for hidden parameter variations and an active learning algorithm to optimize the exploration of the parameter space, the system fabricates silver thin films with optical reflected power ratios within 2.5% of the target in an average of 2.3 attempts. This approach significantly reduces the time and labor required for thin film deposition, showcasing the potential of machine learning-driven automation in accelerating material development.


---
# Physics-informed neural network model for quantum impurity problems based on Lehmann representation

## 基于Lehmann表示的量子杂质问题的物理神经网络模型

Link: https://arxiv.org/abs/2411.18835

arXiv:2411.18835v1 Announce Type: new 
Abstract: We propose a physics-informed neural network (PINN) model to efficiently predict the self-energy of Anderson impurity models (AIMs) based on the Lehmann representation. As an example, we apply the PINN model to a single-orbital AIM (SAIM) for a noninteracting electron bath with a semicircular density of states. Trained across a wide range of onsite Coulomb interactions $U$ and hybridization strengths $V$, the PINN model demonstrates high accuracy in both $U$-$V$ and Matsubara-frequency spaces. Additionally, we investigate the effectiveness of physical constraints implemented in the PINN model. For example, We show that the Lehmann representation allows the PINN model to reduce the maximum test error in an electron filling by a factor of approximately 7.8.


---
# Autonomous materials search using machine learning and ab initio calculations for L10-FePt-based quaternary alloys

## 使用机器学习和从头计算对L10-FePt-based四元合金进行自主材料搜索

Link: https://arxiv.org/abs/2411.18907

arXiv:2411.18907v1 Announce Type: new 
Abstract: The efficient exploration of expansive material spaces remains a significant challenge in materials science. To address this issue, autonomous material search methods that combine machine learning with ab initio calculations have emerged as a promising solution. These approaches offer a systematic and rapid means of discovering new materials, particularly when the material space is too large. This requirement is particularly important in the development of L10-structured alloys as magnetic recording media. These materials require a high magnetic moment (M) and magnetocrystalline anisotropy energy (EMCA) to satisfy the demands of next-generation data storage technologies. Although autonomous search methods have been successfully applied to various material systems, quaternary L10 alloys with optimized magnetic properties remain an open and underexplored frontier. In this study, we present a simulation-based autonomous search method aimed at identifying quaternary L10 alloys with enhanced M and EMCA values. Over a continuous 100-day search, our system suggested the FeMnPtEr alloy system as a promising candidate, exhibiting superior values for both M and EMCA. Although further experimental validation is required, this study underscores the potential of autonomous search methods to accelerate the discovery of advanced materials. Keywords: L10, FePt, machine learning, ab initio calculations, Bayesian optimization


---
# Inverse-design topology optimization of magnonic devices using level-set method

## 基于水平集方法的磁振子器件逆设计拓扑优化

Link: https://arxiv.org/abs/2411.19109

arXiv:2411.19109v1 Announce Type: new 
Abstract: The inverse design approach in magnonics exploits the wave nature of magnons and machine learning to develop novel logical devices with unique functionalities that exceed the capabilities of analytical methods. Despite its potential in analog, Boolean, and neuromorphic computing, existing implementations are limited by memory usage, restricting computational depth and the design of complex devices. This study introduces a level-set parameterization approach for topology optimization, coupled with an adjoint-state method for memory-efficient solution of magnetization dynamics equations. The simulation platform employed is $\texttt{neuralmag}$, a GPU-accelerated micromagnetic software that features a unique nodal finite-difference discretization scheme integrated with automatic differentiation tools. To validate the proposed inverse design method, we first addressed a magnetic nanoparticle shape optimization task, demonstrating how additional constraints on the objective function can control the design solution space and govern the optimization process. Subsequently, the functionality of a magnonic demultiplexer was realized using a 300-nm-wide yttrium iron garnet conduit. This device achieves spatial frequency-selective separation of spin waves into distinct outputs. This task demonstrates the algorithm's efficiency in identifying local minima of the objective function across various initial topologies, establishing its effectiveness as a versatile inverse design tool for creating magnonic logic device designs.


---
# Machine learning the Ising transition: A comparison between discriminative and generative approaches

## 机器学习伊辛过渡: 区分方法和生成方法之间的比较

Link: https://arxiv.org/abs/2411.19370

arXiv:2411.19370v1 Announce Type: new 
Abstract: The detection of phase transitions is a central task in many-body physics. To automate this process, the task can be phrased as a classification problem. Classification problems can be approached in two fundamentally distinct ways: through either a discriminative or a generative method. In general, it is unclear which of these two approaches is most suitable for a given problem. The choice is expected to depend on factors such as the availability of system knowledge, dataset size, desired accuracy, computational resources, and other considerations. In this work, we answer the question of how one should approach the solution of phase-classification problems by performing a numerical case study on the thermal phase transition in the classical two-dimensional square-lattice ferromagnetic Ising model.


---
# Adaptive dynamics of Ising spins in one dimension leveraging Reinforcement Learning

## 利用强化学习的一维Ising自旋的自适应动力学

Link: https://arxiv.org/abs/2411.19602

arXiv:2411.19602v1 Announce Type: new 
Abstract: A one-dimensional flocking model using active Ising spins is studied, where the system evolves through the reinforcement learning approach \textit{via} defining state, action, and cost function for each spin. The orientation of spin with respect to its neighbouring spins defines its state. The state of spin is updated by altering its spin orientation in accordance with the $\varepsilon$-greedy algorithm (action) and selecting a finite step from a uniform distribution to update position. The $\varepsilon$ parameter is analogous to the thermal noise in the system. The cost function addresses cohesion among the spins. By exploring the system in the plane of the self-propulsion speed and $\varepsilon$ parameter, four distinct phases are found: disorder, flocking, flipping, and oscillatory. In the flipping phase, a condensed flock reverses its direction of motion stochastically. The mean reversal time $\langle T \rangle $ exponentially decays with $\varepsilon$. A new phase, an oscillatory phase, is also found, which is a chaotic phase with a positive Lyapunov exponent.
  The findings obtained from the reinforcement learning approach for the active Ising model system exhibit similarities with the outcomes of other conventional techniques, even without defining any explicit interaction among the spins.


---
# Materials Learning Algorithms (MALA): Scalable Machine Learning for Electronic Structure Calculations in Large-Scale Atomistic Simulations

## 材料学习算法 (MALA): 用于大规模原子模拟中电子结构计算的可扩展机器学习

Link: https://arxiv.org/abs/2411.19617

arXiv:2411.19617v1 Announce Type: new 
Abstract: We present the Materials Learning Algorithms (MALA) package, a scalable machine learning framework designed to accelerate density functional theory (DFT) calculations suitable for large-scale atomistic simulations. Using local descriptors of the atomic environment, MALA models efficiently predict key electronic observables, including local density of states, electronic density, density of states, and total energy. The package integrates data sampling, model training and scalable inference into a unified library, while ensuring compatibility with standard DFT and molecular dynamics codes. We demonstrate MALA's capabilities with examples including boron clusters, aluminum across its solid-liquid phase boundary, and predicting the electronic structure of a stacking fault in a large beryllium slab. Scaling analyses reveal MALA's computational efficiency and identify bottlenecks for future optimization. With its ability to model electronic structures at scales far beyond standard DFT, MALA is well suited for modeling complex material systems, making it a versatile tool for advanced materials research.


---
# Inverse Design of Mechanical Metamaterials Using a Point-Cloud-Based Deep Generative Model

## 使用基于点云的深度生成模型对机械超材料进行逆设计

Link: https://arxiv.org/abs/2411.19681

arXiv:2411.19681v1 Announce Type: new 
Abstract: Mechanical metamaterials have garnered attention for their engineered mechanical properties, enabling control over specific behaviors. Advances in additive manufacturing have expanded design freedom for complex metamaterials. However, the design process remains challenging due to vast design space and numerous parameters. While artificial intelligence (AI) aids design, current approaches are often restricted to predefined, parameterized structures. This study introduces a parameter-free design strategy for 3D mechanical metamaterials using point-cloud-based deep generative networks. A library of widely known metamaterial structures was constructed to train the machine learning model. The trained latent space forms clusters of unit cell topologies with similar properties, enabling efficient exploration and smooth interpolation. Additionally, mechanical properties can be predicted more faster than with conventional methods. This approach created metamaterials with targeted properties, unrestricted by parameterized constraints. Computational and experimental validations confirmed alignment with desired properties within acceptable error margins. We believe this work significantly enhances design flexibility in AI-driven metamaterials, expanding their potential applications across various fields.


---
# Chirality-Dependent Kinetics of Single-Walled Carbon Nanotubes from Machine-Learning Force Fields

## 机器学习力场中单壁碳纳米管的手性相关动力学

Link: https://arxiv.org/abs/2411.19764

arXiv:2411.19764v1 Announce Type: new 
Abstract: The origin of the chirality of single-walled carbon nanotubes (SWCNTs) has been a long-standing dispute. Molecular dynamics (MD) simulations driven by machine-learning force fields (MLFF), which can study the interface dynamics under near ab-initio accuracy, provides a powerful technique to reveal the formation mechanism of SWCNTs. Here, we develop a cobalt-carbon MLFF and perform growth simulations on a cobalt catalyst to investigate the chirality preference of the growth of SWCNTs under the vapor-liquid-solid (VLS) regime. Through microkinetic modeling, we reproduce the observed growth and defect kinetics, demonstrating their dependence on the chirality. It is observed that while the initial chirality assignment is likely related to the configurational degeneracy of the nanotube caps, pentagon defects immediately form and resolve after nucleation. Such processes, which we name as diameter control mechanisms, not only control the diameter toward an optimum but also shift the chirality distribution drastically. Our work therefore offers a microkinetic modeling workflow for the chirality-dependent kinetics of the SWCNTs, highlighting the important contribution of the defect kinetics to the chirality origination.


---
# Machine learning force-field model for kinetic Monte Carlo simulations of itinerant Ising magnets

## 用于流动磁体动力学蒙特卡洛模拟的机器学习力场模型

Link: https://arxiv.org/abs/2411.19780

arXiv:2411.19780v1 Announce Type: new 
Abstract: We present a scalable machine learning (ML) framework for large-scale kinetic Monte Carlo (kMC) simulations of itinerant electron Ising systems. As the effective interactions between Ising spins in such itinerant magnets are mediated by conducting electrons, the calculation of energy change due to a local spin update requires solving an electronic structure problem. Such repeated electronic structure calculations could be overwhelmingly prohibitive for large systems. Assuming the locality principle, a convolutional neural network (CNN) model is developed to directly predict the effective local field and the corresponding energy change associated with a given spin update based on Ising configuration in a finite neighborhood. As the kernel size of the CNN is fixed at a constant, the model can be directly scalable to kMC simulations of large lattices. Our approach is reminiscent of the ML force-field models widely used in first-principles molecular dynamics simulations. Applying our ML framework to a square-lattice double-exchange Ising model, we uncover unusual coarsening of ferromagnetic domains at low temperatures. Our work highlights the potential of ML methods for large-scale modeling of similar itinerant systems with discrete dynamical variables.


---
# Integrated Artificial Neurons from Metal Halide Perovskites

## 来自金属卤化物钙钛矿的集成人工神经元

Link: https://arxiv.org/abs/2411.19820

arXiv:2411.19820v1 Announce Type: new 
Abstract: Hardware neural networks could perform certain computational tasks orders of magnitude more energy-efficiently than conventional computers. Artificial neurons are a key component of these networks and are currently implemented with electronic circuits based on capacitors and transistors. However, artificial neurons based on memristive devices are a promising alternative, owing to their potentially smaller size and inherent stochasticity. But despite their promise, demonstrations of memristive artificial neurons have so far been limited. Here we demonstrate a fully on-chip artificial neuron based on microscale electrodes and halide perovskite semiconductors as the active layer. By connecting a halide perovskite memristive device in series with a capacitor, the device demonstrates stochastic leaky integrate-and-fire behavior, with an energy consumption of 20 to 60 pJ per spike, lower than that of a biological neuron. We simulate populations of our neuron and show that the stochastic firing allows the detection of sub-threshold inputs. The neuron can easily be integrated with previously-demonstrated halide perovskite artificial synapses in energy-efficient neural networks.


---
# Probing quantum critical phase from neural network wavefunction

## 从神经网络波函数探测量子临界相位

Link: https://arxiv.org/abs/2411.19938

arXiv:2411.19938v1 Announce Type: new 
Abstract: One-dimensional (1D) systems and models provide a versatile platform for emergent phenomena induced by strong electron correlation. In this work, we extend the newly developed real space neural network quantum Monte Carlo methods to study the quantum phase transition of electronic and magnetic properties. Hydrogen chains of different interatomic distances are explored systematically with both open and periodic boundary conditions, and fully correlated ground state many-body wavefunction is achieved via unsupervised training of neural networks. We demonstrate for the first time that neural networks are capable of capturing the quantum critical behavior of Tomonaga- Luttinger liquid (TLL), which is known to dominate 1D quantum systems. Moreover, we reveal the breakdown of TLL phase and the emergence of a Fermi liquid behavior, evidenced by abrupt changes in the spin structure and the momentum distribution. Such behavior is absent in commonly studied 1D lattice models and is likely due to the involvement of high-energy orbitals of hydrogen atoms. Our work highlights the powerfulness of neural networks for representing complex quantum phases.


---
# Effective temperature in approximate quantum many-body states

## 近似量子多体态中的有效温度

Link: https://arxiv.org/abs/2411.18921

arXiv:2411.18921v1 Announce Type: cross 
Abstract: In the pursuit of numerically identifying the ground state of quantum many-body systems, approximate quantum wavefunction ansatzes are commonly employed. This study focuses on the spectral decomposition of these approximate quantum many-body states into exact eigenstates of the target Hamiltonian. The energy spectral decomposition could reflect the intricate physics at the interplay between quantum systems and numerical algorithms. Here we examine various parameterized wavefunction ansatzes constructed from neural networks, tensor networks, and quantum circuits, employing differentiable programming to numerically approximate ground states and imaginary-time evolved states. Our findings reveal a consistent exponential decay pattern in the spectral contributions of approximate quantum states across different ansatzes, optimization objectives, and quantum systems, characterized by small decay rates denoted as inverse effective temperatures. The effective temperature is related to ansatz expressiveness and accuracy and shows phase transition behaviors in learning imaginary-time evolved states. The universal picture and unique features suggest the significance and potential of the effective temperature in characterizing approximate quantum states.


---
# A potassium ion channel simulated with a universal neural network potential

## 用通用神经网络电位模拟的钾离子通道

Link: https://arxiv.org/abs/2411.18931

arXiv:2411.18931v1 Announce Type: cross 
Abstract: Potassium ion channels are critical components of biology. They conduct potassium ions across the cell membrane with remarkable speed and selectivity. Understanding how they do this is crucially important for applications in neuroscience, medicine, and materials science. However, many fundamental questions about the mechanism they use remain unresolved, partly because it is extremely difficult to computationally model due to the scale and complexity of the necessary simulations. Here, the selectivity filter (SF) of the KcsA potassium ion channel is simulated using Orb-D3, a recently released universal neural network potential. A previously unreported hydrogen bond between water in the SF and the T75 hydroxyl side group at the entrance to the SF is observed. This hydrogen bond appears to stabilize water in the SF, enabling a soft knock-on transport mechanism where water is co-transported through the SF with a reasonable conductivity (80 $\pm$ 20 pS). Carbonyl backbone flipping is also observed at new sites in the SF. This work demonstrates the potential of universal neural network potentials to provide insights into previously intractable questions about complex systems far outside their training data distribution.


---
# Training the parametric interactions in an analog bosonic quantum neural network with Fock basis measurement

## 用Fock基测量训练模拟玻色子量子神经网络中的参数相互作用

Link: https://arxiv.org/abs/2411.19112

arXiv:2411.19112v1 Announce Type: cross 
Abstract: Quantum neural networks have the potential to be seamlessly integrated with quantum devices for the automatic recognition of quantum states. However, performing complex tasks requires a large number of neurons densely connected through trainable, parameterized weights - a challenging feat when using qubits. To address this, we propose leveraging bosonic modes and performing Fock basis measurements, enabling the extraction of an exponential number of features relative to the number of modes. Unlike qubits, bosons can be coupled through multiple parametric drives, with amplitudes, phases, and frequency detunings serving dual purposes: data encoding and trainable parameters. We demonstrate that these parameters, despite their differing physical dimensions, can be trained cohesively using backpropagation to solve benchmark tasks of increasing complexity. Furthermore, we show that training significantly reduces the number of measurements required for feature extraction compared to untrained quantum neural networks, such as quantum reservoir computing.


---
# Deep Learning for GWP Prediction: A Framework Using PCA, Quantile Transformation, and Ensemble Modeling

## 用于GWP预测的深度学习: 使用PCA，分位数变换和集成建模的框架

Link: https://arxiv.org/abs/2411.19124

arXiv:2411.19124v1 Announce Type: cross 
Abstract: Developing environmentally sustainable refrigerants is critical for mitigating the impact of anthropogenic greenhouse gases on global warming. This study presents a predictive modeling framework to estimate the 100-year global warming potential (GWP 100) of single-component refrigerants using a fully connected neural network implemented on the Multi-Sigma platform. Molecular descriptors from RDKit, Mordred, and alvaDesc were utilized to capture various chemical features. The RDKit-based model achieved the best performance, with a Root Mean Square Error (RMSE) of 481.9 and an R2 score of 0.918, demonstrating superior predictive accuracy and generalizability. Dimensionality reduction through Principal Component Analysis (PCA) and quantile transformation were applied to address the high-dimensional and skewed nature of the dataset,enhancing model stability and performance. Factor analysis identified vital molecular features, including molecular weight, lipophilicity, and functional groups, such as nitriles and allylic oxides, as significant contributors to GWP values. These insights provide actionable guidance for designing environmentally sustainable refrigerants. Integrating RDKit descriptors with Multi-Sigma's framework, which includes PCA, quantile transformation, and neural networks, provides a scalable solution for the rapid virtual screening of low-GWP refrigerants. This approach can potentially accelerate the identification of eco-friendly alternatives, directly contributing to climate mitigation by enabling the design of next-generation refrigerants aligned with global sustainability objectives.


---
# Quantum feedback control with a transformer neural network architecture

## 具有变压器神经网络架构的量子反馈控制

Link: https://arxiv.org/abs/2411.19253

arXiv:2411.19253v1 Announce Type: cross 
Abstract: Attention-based neural networks such as transformers have revolutionized various fields such as natural language processing, genomics, and vision. Here, we demonstrate the use of transformers for quantum feedback control through a supervised learning approach. In particular, due to the transformer's ability to capture long-range temporal correlations and training efficiency, we show that it can surpass some of the limitations of previous control approaches, e.g.~those based on recurrent neural networks trained using a similar approach or reinforcement learning. We numerically show, for the example of state stabilization of a two-level system, that our bespoke transformer architecture can achieve unit fidelity to a target state in a short time even in the presence of inefficient measurement and Hamiltonian perturbations that were not included in the training set. We also demonstrate that this approach generalizes well to the control of non-Markovian systems. Our approach can be used for quantum error correction, fast control of quantum states in the presence of colored noise, as well as real-time tuning, and characterization of quantum devices.


---
# Memristive Nanowire Network for Energy Efficient Audio Classification: Pre-Processing-Free Reservoir Computing with Reduced Latency

## 用于节能音频分类的忆阻纳米线网络: 具有减少延迟的无预处理存储计算

Link: https://arxiv.org/abs/2411.19611

arXiv:2411.19611v1 Announce Type: cross 
Abstract: Speech recognition is a key challenge in natural language processing, requiring low latency, efficient computation, and strong generalization for real-time applications. While software-based artificial neural networks (ANNs) excel at this task, they are computationally intensive and depend heavily on data pre-processing. Neuromorphic computing, with its low-latency and energy-efficient advantages, holds promise for audio classification. Memristive nanowire networks, combined with pre-processing techniques like Mel-Frequency Cepstrum Coefficient extraction, have been widely used for associative learning, but such pre-processing can be power-intensive, undermining latency benefits. This study pioneers the use of memristive and spatio-temporal properties of nanowire networks for audio signal classification without pre-processing. A nanowire network simulation is paired with three linear classifiers for 10-class MNIST audio classification and binary speaker generalization tests. The hybrid system achieves significant benefits: excellent data compression with only 3% of nanowire output utilized, a 10-fold reduction in computational latency, and up to 28.5% improved classification accuracy (using a logistic regression classifier). Precision and recall improve by 10% and 17% for multispeaker datasets, and by 24% and 17% for individual speaker datasets, compared to raw data classifiers.This work provides a foundational proof of concept for utilizing memristive nanowire networks (NWN) in edge-computing devices, showcasing their potential for efficient, real-time audio signal processing with reduced computational overhead and power consumption, and enabling the development of advanced neuromorphic computing solutions.


---
# Neural information processing and time-series prediction with only two dynamical memristors

## 仅使用两个动态忆阻器的神经信息处理和时间序列预测

Link: https://arxiv.org/abs/2307.13320

arXiv:2307.13320v2 Announce Type: replace 
Abstract: Memristive devices are commonly benchmarked by the multi-level programmability of their resistance states. Neural networks utilizing memristor crossbar arrays as synaptic layers largely rely on this feature. However, the dynamical properties of memristors, such as the adaptive response times arising from the exponential voltage dependence of the resistive switching speed remain largely unexploited. Here, we propose an information processing scheme which fundamentally relies on the latter. We realize simple dynamical memristor circuits capable of complex temporal information processing tasks. We demonstrate an artificial neural circuit with one nonvolatile and one volatile memristor which can detect a neural spike pattern in a very noisy environment, fire a single voltage pulse upon successful detection and reset itself in an entirely autonomous manner. Furthermore, we implement a circuit with only two nonvolatile memristors which can learn the operation of an external dynamical system and perform the corresponding time-series prediction with high accuracy.


---
# Transformer Wave Function for two dimensional frustrated magnets: emergence of a Spin-Liquid Phase in the Shastry-Sutherland Model

## 二维受挫磁体的变压器波函数: shastr-sutherland模型中自旋液相的出现

Link: https://arxiv.org/abs/2311.16889

arXiv:2311.16889v3 Announce Type: replace 
Abstract: Understanding quantum magnetism in two-dimensional systems represents a lively branch in modern condensed-matter physics. In the presence of competing super-exchange couplings, magnetic order is frustrated and can be suppressed down to zero temperature. Still, capturing the correct nature of the exact ground state is a highly complicated task, since energy gaps in the spectrum may be very small and states with different physical properties may have competing energies. Here, we introduce a variational Ansatz for two-dimensional frustrated magnets by leveraging the power of representation learning. The key idea is to use a particular deep neural network with real-valued parameters, a so-called Transformer, to map physical spin configurations into a high-dimensional feature space. Within this abstract space, the determination of the ground-state properties is simplified and requires only a shallow output layer with complex-valued parameters. We illustrate the efficacy of this variational Ansatz by studying the ground-state phase diagram of the Shastry-Sutherland model, which captures the low-temperature behavior of SrCu$_2$(BO$_3$)$_2$ with its intriguing properties. With highly accurate numerical simulations, we provide strong evidence for the stabilization of a spin-liquid between the plaquette and antiferromagnetic phases. In addition, a direct calculation of the triplet excitation at the $\Gamma$ point provides compelling evidence for a gapless spin liquid. Our findings underscore the potential of Neural-Network Quantum States as a valuable tool for probing uncharted phases of matter, and open up new possibilities for establishing the properties of many-body systems.


---
# Solution space and storage capacity of fully connected two-layer neural networks with generic activation functions

## 具有通用激活函数的完全连接的两层神经网络的解空间和存储容量

Link: https://arxiv.org/abs/2404.13404

arXiv:2404.13404v2 Announce Type: replace 
Abstract: The storage capacity of a binary classification model is the maximum number of random input-output pairs per parameter that the model can learn. It is one of the indicators of the expressive power of machine learning models and is important for comparing the performance of various models. In this study, we analyze the structure of the solution space and the storage capacity of fully connected two-layer neural networks with general activation functions using the replica method from statistical physics. Our results demonstrate that the storage capacity per parameter remains finite even with infinite width and that the weights of the network exhibit negative correlations, leading to a 'division of labor'. In addition, we find that increasing the dataset size triggers a phase transition at a certain transition point where the permutation symmetry of weights is broken, resulting in the solution space splitting into disjoint regions. We identify the dependence of this transition point and the storage capacity on the choice of activation function. These findings contribute to understanding the influence of activation functions and the number of parameters on the structure of the solution space, potentially offering insights for selecting appropriate architectures based on specific objectives.


---
# Tensor networks and efficient descriptions of classical data

## 张量网络与经典数据的有效描述

Link: https://arxiv.org/abs/2103.06872

arXiv:2103.06872v2 Announce Type: replace-cross 
Abstract: We investigate the potential of tensor network based machine learning methods to scale to large image and text data sets. For that, we study how the mutual information between a subregion and its complement scales with the subsystem size $L$, similarly to how it is done in quantum many-body physics. We find that for text, the mutual information scales as a power law $L^\nu$ with a close to volume law exponent, indicating that text cannot be efficiently described by 1D tensor networks. For images, the scaling is close to an area law, hinting at 2D tensor networks such as PEPS could have an adequate expressibility. For the numerical analysis, we introduce a mutual information estimator based on autoregressive networks, and we also use convolutional neural networks in a neural estimator method.


---
# Bias-inducing geometries: an exactly solvable data model with fairness implications

## 引起偏差的几何形状: 具有公平性含义的完全可解决的数据模型

Link: https://arxiv.org/abs/2205.15935

arXiv:2205.15935v4 Announce Type: replace-cross 
Abstract: Machine learning (ML) may be oblivious to human bias but it is not immune to its perpetuation. Marginalisation and iniquitous group representation are often traceable in the very data used for training, and may be reflected or even enhanced by the learning models. In the present work, we aim at clarifying the role played by data geometry in the emergence of ML bias. We introduce an exactly solvable high-dimensional model of data imbalance, where parametric control over the many bias-inducing factors allows for an extensive exploration of the bias inheritance mechanism. Through the tools of statistical physics, we analytically characterise the typical properties of learning models trained in this synthetic framework and obtain exact predictions for the observables that are commonly employed for fairness assessment. Despite the simplicity of the data model, we retrace and unpack typical unfairness behaviour observed on real-world datasets. We also obtain a detailed analytical characterisation of a class of bias mitigation strategies. We first consider a basic loss-reweighing scheme, which allows for an implicit minimisation of different unfairness metrics, and quantify the incompatibilities between some existing fairness criteria. Then, we consider a novel mitigation strategy based on a matched inference approach, consisting in the introduction of coupled learning models. Our theoretical analysis of this approach shows that the coupled strategy can strike superior fairness-accuracy trade-offs.


---
# Stochastic Resetting Mitigates Latent Gradient Bias of SGD from Label Noise

## 随机重置减轻了标签噪声对SGD的潜在梯度偏差

Link: https://arxiv.org/abs/2406.00396

arXiv:2406.00396v2 Announce Type: replace-cross 
Abstract: Giving up and starting over may seem wasteful in many situations such as searching for a target or training deep neural networks (DNNs). Our study, though, demonstrates that resetting from a checkpoint can significantly improve generalization performance when training DNNs with noisy labels. In the presence of noisy labels, DNNs initially learn the general patterns of the data but then gradually memorize the corrupted data, leading to overfitting. By deconstructing the dynamics of stochastic gradient descent (SGD), we identify the behavior of a latent gradient bias induced by noisy labels, which harms generalization. To mitigate this negative effect, we apply the stochastic resetting method to SGD, inspired by recent developments in the field of statistical physics achieving efficient target searches. We first theoretically identify the conditions where resetting becomes beneficial, and then we empirically validate our theory, confirming the significant improvements achieved by resetting. We further demonstrate that our method is both easy to implement and compatible with other methods for handling noisy labels. Additionally, this work offers insights into the learning dynamics of DNNs from an interpretability perspective, expanding the potential to analyze training methods through the lens of statistical physics.


---
# Multi-Task Learning for Integrated Automated Contouring and Voxel-Based Dose Prediction in Radiotherapy

## 用于放射治疗中集成自动轮廓和基于体素的剂量预测的多任务学习

Link: https://arxiv.org/abs/2411.18767

arXiv:2411.18767v1 Announce Type: new 
Abstract: Deep learning-based automated contouring and treatment planning has been proven to improve the efficiency and accuracy of radiotherapy. However, conventional radiotherapy treatment planning process has the automated contouring and treatment planning as separate tasks. Moreover in deep learning (DL), the contouring and dose prediction tasks for automated treatment planning are done independently. In this study, we applied the multi-task learning (MTL) approach in order to seamlessly integrate automated contouring and voxel-based dose prediction tasks, as MTL can leverage common information between the two tasks and be able able to increase the efficiency of the automated tasks. We developed our MTL framework using the two datasets: in-house prostate cancer dataset and the publicly available head and neck cancer dataset, OpenKBP. Compared to the sequential DL contouring and treatment planning tasks, our proposed method using MTL improved the mean absolute difference of dose volume histogram metrics of prostate and head and neck sites by 19.82% and 16.33%, respectively. Our MTL model for automated contouring and dose prediction tasks demonstrated enhanced dose prediction performance while maintaining or sometimes even improving the contouring accuracy. Compared to the baseline automated contouring model with the dice score coefficients of 0.818 for prostate and 0.674 for head and neck datasets, our MTL approach achieved average scores of 0.824 and 0.716 for these datasets, respectively. Our study highlights the potential of the proposed automated contouring and planning using MTL to support the development of efficient and accurate automated treatment planning for radiotherapy.


---
# Assessing the potential of state-of-the-art machine learning and physics-informed machine learning in predicting sea surface temperature

## 评估最先进的机器学习和物理信息机器学习在预测海面温度方面的潜力

Link: https://arxiv.org/abs/2411.19031

arXiv:2411.19031v1 Announce Type: new 
Abstract: The growing adoption of machine learning (ML) in modelling atmospheric and oceanic processes offers a promising alternative to traditional numerical methods. It is essential to benchmark the performance of both ML and physics-informed ML (PINN) models to evaluate their predictive skill, particularly for short- to medium-term forecasting. In this study, we utilize gridded sea surface temperature (SST) data and six atmospheric predictors (cloud cover, relative humidity, solar radiation, surface pressure, u-component of velocity, and v-component of velocity) to capture both spatial and temporal patterns in SST predictions.


---
# An unstructured adaptive mesh refinement for steady flows based on physics-informed neural networks

## 基于物理信息神经网络的稳定流非结构化自适应网格细化

Link: https://arxiv.org/abs/2411.19200

arXiv:2411.19200v1 Announce Type: new 
Abstract: Mesh generation is essential for accurate and efficient computational fluid dynamics simulations. To resolve critical features in the flow, adaptive mesh refinement (AMR) is routinely employed in certain regions of the computational domain, where gradients or error estimates of the solution are often considered as the refining criteria. In many scenarios, however, these indicators can lead to unnecessary refinement over a large region, making the process a matter of trial and error and resulting in slow convergence of the computation. To this end, we propose a heuristic strategy that employs the residuals of the governing partial differential equations (PDEs) as a novel criterion to adaptively guide the mesh refining process. In particular, we leverage on the physics-informed neural networks (PINNs) to integrate imprecise data obtained on a coarse mesh and the governing PDEs. Once trained, PINNs are capable of identifying regions of highest residuals of the Navier-Stokes/Euler equations and suggesting new potential vertices for the coarse mesh cells. Moreover, we put forth two schemes to maintain the quality of the refined mesh through the strategic insertion of vertices and the implementation of Delaunay triangulation. By applying the residuals-guided AMR to address a multitude of typical incompressible/compressible flow problems and comparing the outcomes with those of gradient-based methods, we illustrate that the former effectively attains a favorable balance between the computational accuracy and cost.


---
# Learning Surrogate Rainfall-driven Inundation Models with Few Data

## 具有少量数据的学习替代降雨驱动的淹没模型

Link: https://arxiv.org/abs/2411.19323

arXiv:2411.19323v1 Announce Type: new 
Abstract: Flood hazard assessment demands fast and accurate predictions. Hydrodynamic models are detailed but computationally intensive, making them impractical for quantifying uncertainty or identifying extremes. In contrast, machine learning surrogates can be rapid, but training on scarce simulated or observed extreme data can also be ineffective. This work demonstrates the development of an effective surrogate model for flood hazard prediction by initializing deep learning (ResNet-18) with ensemble-approximated Conditional Gaussian Processes (EnsCGP) and finalizing it with a bias correction. The proposed methodology couples EnsCGP with a ResNet-18 architecture to estimate flood depth and uses ensemble optimal estimation for bias correction. The surrogate model was trained and evaluated using rainfall data from Daymet and hydrodynamic simulations from LISFLOOD-FP, spanning the period from 1981 to 2019. The training involved using data up to a certain year and testing on the subsequent year, iteratively progressing through the dataset. This process required approximately 100 training iterations and extensive data. Inundation depths are estimated rapidly at runtime (approximately 0.006 seconds per event). Results over multiple years in the current climate over Chicago demonstrate an average R-squared greater than 0.96, with median relative errors in flood depth estimates of about 1 percent.


---
# Hierarchical Framework for Retrosynthesis Prediction with Enhanced Reaction Center Localization

## 具有增强的反应中心定位的逆向综合预测的层次框架

Link: https://arxiv.org/abs/2411.19503

arXiv:2411.19503v1 Announce Type: new 
Abstract: Retrosynthesis is essential for designing synthetic pathways for complex molecules and can be revolutionized by AI to automate and accelerate chemical synthesis planning for drug discovery and materials science. Here, we propose a hierarchical framework for retrosynthesis prediction that systematically integrates reaction center identification, action prediction, and termination decision into a unified pipeline. Leveraging a molecular encoder pretrained with contrastive learning, the model captures both atom and bond level representations, enabling accurate identification of reaction centers and prediction of chemical actions. The framework addresses the scarcity of multiple reaction center data through augmentation strategies, enhancing the ability of the model to generalize to diverse reaction scenarios. The proposed approach achieves competitive performance across benchmark datasets, with notably high topk accuracy and exceptional reaction center identification capabilities, demonstrating its robustness in handling complex transformations. These advancements position the framework as a promising tool for future applications in material design and drug discovery.


---
# OpenQDC: Open Quantum Data Commons

## OpenQDC: 开放量子数据共享

Link: https://arxiv.org/abs/2411.19629

arXiv:2411.19629v1 Announce Type: new 
Abstract: Machine Learning Interatomic Potentials (MLIPs) are a highly promising alternative to force-fields for molecular dynamics (MD) simulations, offering precise and rapid energy and force calculations. However, Quantum-Mechanical (QM) datasets, crucial for MLIPs, are fragmented across various repositories, hindering accessibility and model development. We introduce the openQDC package, consolidating 37 QM datasets from over 250 quantum methods and 400 million geometries into a single, accessible resource. These datasets are meticulously preprocessed, and standardized for MLIP training, covering a wide range of chemical elements and interactions relevant in organic chemistry. OpenQDC includes tools for normalization and integration, easily accessible via Python. Experiments with well-known architectures like SchNet, TorchMD-Net, and DimeNet reveal challenges for those architectures and constitute a leaderboard to accelerate benchmarking and guide novel algorithms development. Continuously adding datasets to OpenQDC will democratize QM dataset access, foster more collaboration and innovation, enhance MLIP development, and support their adoption in the MD field.


---
# Neural Network Potential with Multi-Resolution Approach Enables Accurate Prediction of Reaction Free Energies in Solution

## 具有多分辨率方法的神经网络电势可以准确预测溶液中的反应自由能

Link: https://arxiv.org/abs/2411.19728

arXiv:2411.19728v1 Announce Type: new 
Abstract: We present design and implementation of a novel neural network potential (NNP) and its combination with an electrostatic embedding scheme, commonly used within the context of hybrid quantum-mechanical/molecular-mechanical (QM/MM) simulations. Substitution of a computationally expensive QM Hamiltonian by a NNP with the same accuracy largely reduces the computational cost and enables efficient sampling in prospective MD simulations, the main limitation faced by traditional QM/MM set-ups. The model relies on the recently introduced anisotropic message passing (AMP) formalism to compute atomic interactions and encode symmetries found in QM systems. AMP is shown to be highly efficient in terms of both data and computational costs, and can be readily scaled to sample systems involving more than 350 solute and 40'000 solvent atoms for hundreds of nanoseconds using umbrella sampling. The performance and broad applicability of our approach are showcased by calculating the free-energy surface of alanine dipeptide, the preferred ligation states of nickel phosphine complexes, and dissociation free energies of charged pyridine and quinoline dimers. Results with this ML/MM approach show excellent agreement with experimental data. In contrast, free energies calculated with static high-level QM calculations paired with implicit solvent models or QM/MM MD simulations using cheaper semi-empirical methods show up to ten times higher deviation from the experimental ground truth and sometimes even fail to reproduce qualitative trends.


---
# Improving sub-seasonal wind-speed forecasts in Europe with a non-linear model

## 使用非线性模型改善欧洲的亚季节风速预测

Link: https://arxiv.org/abs/2411.19077

arXiv:2411.19077v1 Announce Type: cross 
Abstract: Sub-seasonal wind speed forecasts provide valuable guidance for wind power system planning and operations, yet the forecasting skills of surface winds decrease sharply after two weeks. However, large-scale variables exhibit greater predictability on this time scale. This study explores the potential of leveraging non-linear relationships between 500 hPa geopotential height (Z500) and surface wind speed to improve subs-seasonal wind speed forecasting skills in Europe. Our proposed framework uses a Multiple Linear Regression (MLR) or a Convolutional Neural Network (CNN) to regress surface wind speed from Z500. Evaluations on ERA5 reanalysis indicate that the CNN performs better due to their non-linearity. Applying these models to sub-seasonal forecasts from the European Centre for Medium-Range Weather Forecasts, various verification metrics demonstrate the advantages of non-linearity. Yet, this is partly explained by the fact that these statistical models are under-dispersive since they explain only a fraction of the target variable variance. Introducing stochastic perturbations to represent the stochasticity of the unexplained part from the signal helps compensate for this issue. Results show that the perturbed CNN performs better than the perturbed MLR only in the first weeks, while the perturbed MLR's performance converges towards that of the perturbed CNN after two weeks. The study finds that introducing stochastic perturbations can address the issue of insufficient spread in these statistical models, with improvements from the non-linearity varying with the lead time of the forecasts.


---
# Inverse-design topology optimization of magnonic devices using level-set method

## 基于水平集方法的磁振子器件逆设计拓扑优化

Link: https://arxiv.org/abs/2411.19109

arXiv:2411.19109v1 Announce Type: cross 
Abstract: The inverse design approach in magnonics exploits the wave nature of magnons and machine learning to develop novel logical devices with unique functionalities that exceed the capabilities of analytical methods. Despite its potential in analog, Boolean, and neuromorphic computing, existing implementations are limited by memory usage, restricting computational depth and the design of complex devices. This study introduces a level-set parameterization approach for topology optimization, coupled with an adjoint-state method for memory-efficient solution of magnetization dynamics equations. The simulation platform employed is $\texttt{neuralmag}$, a GPU-accelerated micromagnetic software that features a unique nodal finite-difference discretization scheme integrated with automatic differentiation tools. To validate the proposed inverse design method, we first addressed a magnetic nanoparticle shape optimization task, demonstrating how additional constraints on the objective function can control the design solution space and govern the optimization process. Subsequently, the functionality of a magnonic demultiplexer was realized using a 300-nm-wide yttrium iron garnet conduit. This device achieves spatial frequency-selective separation of spin waves into distinct outputs. This task demonstrates the algorithm's efficiency in identifying local minima of the objective function across various initial topologies, establishing its effectiveness as a versatile inverse design tool for creating magnonic logic device designs.


---
# Wavelet Scattering Transform for Gravitational Waves Analysis. An Application to Glitch Characterization

## 小波散射变换在引力波分析中的应用.在毛刺表征中的应用

Link: https://arxiv.org/abs/2411.19122

arXiv:2411.19122v1 Announce Type: cross 
Abstract: Gravitational waves, first predicted by Albert Einstein within the framework of general relativity, were confirmed in 2015 by the LIGO/Virgo collaboration, marking a pivotal breakthrough in astrophysics. Despite this achievement, a key challenge remains in distinguishing true gravitational wave signals from noise artifacts, or "glitches," which can distort data and affect the quality of observations. Current state-of-the-art methods, such as the Q-transform, are widely used for signal processing, but face limitations when addressing certain types of signals. In this study, we investigate the Wavelet Scattering Transform (WST), a recent signal analysis method, as a complementary approach. Theoretical motivation for WST arises from its stability under signal deformations and its equivariance properties, which make it particularly suited for the complex nature of gravitational wave data. Our experiments on the LIGO O1a dataset show that WST simplifies classification tasks and enables the use of more efficient architectures compared to traditional methods. Furthermore, we explore the potential benefits of integrating WST with the Q-transform, demonstrating that ensemble methods exploiting both techniques can capture complementary features of the signal and improve overall performance. This work contributes to advancing machine learning applications in gravitational wave analysis, introducing refined preprocessing techniques that improve signal detection and classification.


---
# Deep Learning for GWP Prediction: A Framework Using PCA, Quantile Transformation, and Ensemble Modeling

## 用于GWP预测的深度学习: 使用PCA，分位数变换和集成建模的框架

Link: https://arxiv.org/abs/2411.19124

arXiv:2411.19124v1 Announce Type: cross 
Abstract: Developing environmentally sustainable refrigerants is critical for mitigating the impact of anthropogenic greenhouse gases on global warming. This study presents a predictive modeling framework to estimate the 100-year global warming potential (GWP 100) of single-component refrigerants using a fully connected neural network implemented on the Multi-Sigma platform. Molecular descriptors from RDKit, Mordred, and alvaDesc were utilized to capture various chemical features. The RDKit-based model achieved the best performance, with a Root Mean Square Error (RMSE) of 481.9 and an R2 score of 0.918, demonstrating superior predictive accuracy and generalizability. Dimensionality reduction through Principal Component Analysis (PCA) and quantile transformation were applied to address the high-dimensional and skewed nature of the dataset,enhancing model stability and performance. Factor analysis identified vital molecular features, including molecular weight, lipophilicity, and functional groups, such as nitriles and allylic oxides, as significant contributors to GWP values. These insights provide actionable guidance for designing environmentally sustainable refrigerants. Integrating RDKit descriptors with Multi-Sigma's framework, which includes PCA, quantile transformation, and neural networks, provides a scalable solution for the rapid virtual screening of low-GWP refrigerants. This approach can potentially accelerate the identification of eco-friendly alternatives, directly contributing to climate mitigation by enabling the design of next-generation refrigerants aligned with global sustainability objectives.


---
# Real-time Anomaly Detection at the L1 Trigger of CMS Experiment

## CMS实验L1触发器的实时异常检测

Link: https://arxiv.org/abs/2411.19506

arXiv:2411.19506v1 Announce Type: cross 
Abstract: We present the preparation, deployment, and testing of an autoencoder trained for unbiased detection of new physics signatures in the CMS experiment Global Trigger (GT) test crate FPGAs during LHC Run 3. The GT makes the final decision whether to readout or discard the data from each LHC collision, which occur at a rate of 40 MHz, within a 50 ns latency. The Neural Network makes a prediction for each event within these constraints, which can be used to select anomalous events for further analysis. The GT test crate is a copy of the main GT system, receiving the same input data, but whose output is not used to trigger the readout of CMS, providing a platform for thorough testing of new trigger algorithms on live data, but without interrupting data taking. We describe the methodology to achieve ultra low latency anomaly detection, and present the integration of the DNN into the GT test crate, as well as the monitoring, testing, and validation of the algorithm during proton collisions.


---
# Memristive Nanowire Network for Energy Efficient Audio Classification: Pre-Processing-Free Reservoir Computing with Reduced Latency

## 用于节能音频分类的忆阻纳米线网络: 具有减少延迟的无预处理存储计算

Link: https://arxiv.org/abs/2411.19611

arXiv:2411.19611v1 Announce Type: cross 
Abstract: Speech recognition is a key challenge in natural language processing, requiring low latency, efficient computation, and strong generalization for real-time applications. While software-based artificial neural networks (ANNs) excel at this task, they are computationally intensive and depend heavily on data pre-processing. Neuromorphic computing, with its low-latency and energy-efficient advantages, holds promise for audio classification. Memristive nanowire networks, combined with pre-processing techniques like Mel-Frequency Cepstrum Coefficient extraction, have been widely used for associative learning, but such pre-processing can be power-intensive, undermining latency benefits. This study pioneers the use of memristive and spatio-temporal properties of nanowire networks for audio signal classification without pre-processing. A nanowire network simulation is paired with three linear classifiers for 10-class MNIST audio classification and binary speaker generalization tests. The hybrid system achieves significant benefits: excellent data compression with only 3% of nanowire output utilized, a 10-fold reduction in computational latency, and up to 28.5% improved classification accuracy (using a logistic regression classifier). Precision and recall improve by 10% and 17% for multispeaker datasets, and by 24% and 17% for individual speaker datasets, compared to raw data classifiers.This work provides a foundational proof of concept for utilizing memristive nanowire networks (NWN) in edge-computing devices, showcasing their potential for efficient, real-time audio signal processing with reduced computational overhead and power consumption, and enabling the development of advanced neuromorphic computing solutions.


---
# PACMANN: Point Adaptive Collocation Method for Artificial Neural Networks

## PACMANN: 人工神经网络的点自适应配置方法

Link: https://arxiv.org/abs/2411.19632

arXiv:2411.19632v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) are an emerging tool for approximating the solution of Partial Differential Equations (PDEs) in both forward and inverse problems. PINNs minimize a loss function which includes the PDE residual determined for a set of collocation points. Previous work has shown that the number and distribution of these collocation points have a significant influence on the accuracy of the PINN solution. Therefore, the effective placement of these collocation points is an active area of research. Specifically, adaptive collocation point sampling methods have been proposed, which have been reported to scale poorly to higher dimensions. In this work, we address this issue and present the Point Adaptive Collocation Method for Artificial Neural Networks (PACMANN). Inspired by classic optimization problems, this approach incrementally moves collocation points toward regions of higher residuals using gradient-based optimization algorithms guided by the gradient of the squared residual. We apply PACMANN for forward and inverse problems, and demonstrate that this method matches the performance of state-of-the-art methods in terms of the accuracy/efficiency tradeoff for the low-dimensional problems, while outperforming available approaches for high-dimensional problems; the best performance is observed for the Adam optimizer. Key features of the method include its low computational cost and simplicity of integration in existing physics-informed neural network pipelines.


---
# Chirality-Dependent Kinetics of Single-Walled Carbon Nanotubes from Machine-Learning Force Fields

## 机器学习力场中单壁碳纳米管的手性相关动力学

Link: https://arxiv.org/abs/2411.19764

arXiv:2411.19764v1 Announce Type: cross 
Abstract: The origin of the chirality of single-walled carbon nanotubes (SWCNTs) has been a long-standing dispute. Molecular dynamics (MD) simulations driven by machine-learning force fields (MLFF), which can study the interface dynamics under near ab-initio accuracy, provides a powerful technique to reveal the formation mechanism of SWCNTs. Here, we develop a cobalt-carbon MLFF and perform growth simulations on a cobalt catalyst to investigate the chirality preference of the growth of SWCNTs under the vapor-liquid-solid (VLS) regime. Through microkinetic modeling, we reproduce the observed growth and defect kinetics, demonstrating their dependence on the chirality. It is observed that while the initial chirality assignment is likely related to the configurational degeneracy of the nanotube caps, pentagon defects immediately form and resolve after nucleation. Such processes, which we name as diameter control mechanisms, not only control the diameter toward an optimum but also shift the chirality distribution drastically. Our work therefore offers a microkinetic modeling workflow for the chirality-dependent kinetics of the SWCNTs, highlighting the important contribution of the defect kinetics to the chirality origination.


---
# Input-Output Optics as a Causal Time Series Mapping: A Generative Machine Learning Solution

## 输入输出光学作为因果时间序列映射: 生成式机器学习解决方案

Link: https://arxiv.org/abs/2411.19897

arXiv:2411.19897v1 Announce Type: cross 
Abstract: The response of many-body quantum systems to an optical pulse can be extremely challenging to model. Here we explore the use of neural networks, both traditional and generative, to learn and thus simulate the response of such a system from data. The quantum system can be viewed as performing a complex mapping from an input time-series (the optical pulse) to an output time-series (the systems response) which is often also an optical pulse. Using both the transverse and non-integrable Ising models as examples, we show that not only can temporal convolutional networks capture the input/output mapping generated by the system but can also be used to characterize the complexity of the mapping. This measure of complexity is provided by the size of the smallest latent space that is able to accurately model the mapping. We further find that a generative model, in particular a variational auto-encoder, significantly outperforms traditional auto-encoders at learning the complex response of many-body quantum systems. For the example that generated the most complex mapping, the variational auto-encoder produces outputs that have less than 10% error for more than 90% of inputs across our test data.


---
# Probing quantum critical phase from neural network wavefunction

## 从神经网络波函数探测量子临界相位

Link: https://arxiv.org/abs/2411.19938

arXiv:2411.19938v1 Announce Type: cross 
Abstract: One-dimensional (1D) systems and models provide a versatile platform for emergent phenomena induced by strong electron correlation. In this work, we extend the newly developed real space neural network quantum Monte Carlo methods to study the quantum phase transition of electronic and magnetic properties. Hydrogen chains of different interatomic distances are explored systematically with both open and periodic boundary conditions, and fully correlated ground state many-body wavefunction is achieved via unsupervised training of neural networks. We demonstrate for the first time that neural networks are capable of capturing the quantum critical behavior of Tomonaga- Luttinger liquid (TLL), which is known to dominate 1D quantum systems. Moreover, we reveal the breakdown of TLL phase and the emergence of a Fermi liquid behavior, evidenced by abrupt changes in the spin structure and the momentum distribution. Such behavior is absent in commonly studied 1D lattice models and is likely due to the involvement of high-energy orbitals of hydrogen atoms. Our work highlights the powerfulness of neural networks for representing complex quantum phases.


---
# Neural Networks-based Random Vortex Methods for Modelling Incompressible Flows

## 基于神经网络的不可压缩流动建模的随机涡旋方法

Link: https://arxiv.org/abs/2405.13691

arXiv:2405.13691v2 Announce Type: replace 
Abstract: In this paper we introduce a novel Neural Networks-based approach for approximating solutions to the (2D) incompressible Navier--Stokes equations, which is an extension of so called Deep Random Vortex Methods (DRVM), that does not require the knowledge of the Biot--Savart kernel associated to the computational domain. Our algorithm uses a Neural Network (NN), that approximates the vorticity based on a loss function that uses a computationally efficient formulation of the Random Vortex Dynamics. The neural vorticity estimator is then combined with traditional numerical PDE-solvers, which can be considered as a final implicit linear layer of the network, for the Poisson equation to compute the velocity field. The main advantage of our method compared to the standard DRVM and other NN-based numerical algorithms is that it strictly enforces physical properties, such as incompressibility or (no slip) boundary conditions, which might be hard to guarantee otherwise. The approximation abilities of our algorithm, and its capability for incorporating measurement data, are validated by several numerical experiments.


---
# Machine-Learning based photon counting for PMT waveforms and its application to the improvement of the energy resolution in large liquid scintillator detectors

## 基于机器学习的PMT波形光子计数及其在提高大型液体闪烁体探测器能量分辨率中的应用

Link: https://arxiv.org/abs/2405.18720

arXiv:2405.18720v3 Announce Type: replace 
Abstract: Photomultiplier tubes (PMTs) are widely used in particle experiments for photon detection. PMT waveform analysis is crucial for high-precision measurements of the position and energy of incident particles in liquid scintillator (LS) detectors. A key factor contributing to the energy resolution in large liquid scintillator detectors with PMTs is the charge smearing of PMTs. This paper presents a machine-learning-based photon counting method for PMT waveforms and its application to the energy reconstruction, using the JUNO experiment as an example. The results indicate that leveraging the photon counting information from the machine learning model can partially mitigate the impact of PMT charge smearing and lead to a relative 2.0% to 2.8% improvement on the energy resolution in the energy range of [1, 9] MeV.


---
# Integrating audiological datasets via federated merging of Auditory Profiles

## 通过听觉剖面的联合合并来整合听觉数据集

Link: https://arxiv.org/abs/2407.20765

arXiv:2407.20765v2 Announce Type: replace 
Abstract: Audiological datasets contain valuable knowledge about hearing loss in patients, which can be uncovered using data-driven, federated learning techniques. Our previous approach summarized patient information from one audiological dataset into distinct Auditory Profiles (APs). To obtain a better estimate of the audiological patient population, however, patient patterns must be analyzed across multiple, separated datasets, and finally, be integrated into a combined set of APs.
  This study aimed at extending the existing profile generation pipeline with an AP merging step, enabling the combination of APs from different datasets based on their similarity across audiological measures. The 13 previously generated APs (NA=595) were merged with 31 newly generated APs from a second dataset (NB=1272) using a similarity score derived from the overlapping densities of common features across the two datasets. To ensure clinical applicability, random forest models were created for various scenarios, encompassing different combinations of audiological measures.
  A new set with 13 combined APs is proposed, providing separable profiles, which still capture detailed patient information from various test outcome combinations. The classification performance across these profiles is satisfactory. The best performance was achieved using a combination of loudness scaling, audiogram and speech test information, while single measures performed worst.
  The enhanced profile generation pipeline demonstrates the feasibility of combining APs across datasets, which should generalize to all datasets and could lead to an interpretable global profile set in the future. The classification models maintain clinical applicability.


---
# Deep potential for interaction between hydrated Cs+ and graphene

## 水合Cs与石墨烯相互作用的深层潜力

Link: https://arxiv.org/abs/2408.15797

arXiv:2408.15797v2 Announce Type: replace 
Abstract: The influence of hydrated cation-{\pi} interaction forces on the adsorption and filtration capabilities of graphene-based membrane materials is significant. However, the lack of interaction potential between hydrated Cs+ and graphene limits the scope of adsorption studies. Here, it is developed that a deep neural network potential function model to predict the interaction force between hydrated Cs+ and graphene. The deep potential has DFT-level accuracy, enabling accurate property prediction. This deep potential is employed to investigate the properties of the graphene surface solution, including the density distribution, mean square displacement, and vibrational power spectrum of water. Furthermore, calculations of the molecular orbital electron distributions indicate the presence of electron migration in the molecular orbitals of graphene and hydrated Cs+, resulting in a strong electrostatic interaction force. The method provides a powerful tool to study the adsorption behavior of hydrated cations on graphene surfaces and offers a new solution for handling radionuclides.


---
# Geographic Space as Manifolds

## 作为流形的地理空间

Link: https://arxiv.org/abs/2410.23559

arXiv:2410.23559v2 Announce Type: replace 
Abstract: The communications and interrelations between different locations on the Earth's surface have far-reaching implications for both social and natural systems. Effective spatial analytics ideally require a spatial representation, where geographic principles are succinctly expressed within a defined metric space. However, common spatial representations, including map-based or network-based approaches, fall short by incompletely or inaccurately defining this metric space. Here we show, by introducing an inverse friction factor that captures the spatial constraints in spatial networks, that a homogeneous, low-dimensional spatial representation - termed the Geographic Manifold - can be achieved. We illustrate the effectiveness of the Geographic Manifold in two classic scenarios of spatial analytics - location choice and propagation, where the otherwise complicated analyses are reduced to straightforward regular partitioning and concentric diffusing, respectively on the manifold with a high degree of accuracy. We further empirically explain and formally prove the general existence of the Geographic Manifold, which is grounded in the intrinsic Euclidean low-dimensional statistical physics properties of geographic phenomena. This work represents a step towards formalizing Tobler's famous First Law of Geography from a geometric approach, where a regularized geospace thereby yielded is expected to contribute in learning abstract spatial structure representations for understanding and optimization purposes.


---
# PINNs4Drops: Convolutional feature-enhanced physics-informed neural networks for reconstructing two-phase flows

## PINNs4Drops: 卷积特征增强的物理通知神经网络，用于重建两相流

Link: https://arxiv.org/abs/2411.15949

arXiv:2411.15949v2 Announce Type: replace 
Abstract: Two-phase flow phenomena play a key role in many engineering applications, including hydrogen fuel cells, spray cooling techniques and combustion. Specialized techniques like shadowgraphy and particle image velocimetry can reveal gas-liquid interface evolution and internal velocity fields; however, they are largely limited to planar measurements, while flow dynamics are inherently three-dimensional (3D). Deep learning techniques based on convolutional neural networks provide a powerful approach for volumetric reconstruction based on the experimental data by leveraging spatial structure of images and extracting context-rich features. Building on this foundation, Physics-informed neural networks (PINNs) offer a complementary and promising alternative integrating prior knowledge in the form of governing equations into the networks training process. This integration enables accurate predictions even with limited data. By combining the strengths of both approaches, we propose a novel convolutional feature-enhanced PINNs framework, designed for the spatio-temporal reconstruction of two-phase flows from color-coded shadowgraphy images. The proposed approach is first validated on synthetic data generated through direct numerical simulation, demonstrating high spatial accuracy in reconstructing the three-dimensional gas-liquid interface, along with the inferred velocity and pressure fields. Subsequently, we apply this method to interface reconstruction for an impinging droplet using planar experimental data, highlighting the practical applicability and significant potential of the proposed approach to real-world fluid dynamics analysis.


---
# Non-Linear Super-Stencils for Turbulence Model Corrections

## 用于湍流模型校正的非线性超级模板

Link: https://arxiv.org/abs/2411.16493

arXiv:2411.16493v2 Announce Type: replace 
Abstract: Accurate simulation of turbulent flows remains a challenge due to the high computational cost of direct numerical simulations (DNS) and the limitations of traditional turbulence models. This paper explores a novel approach to augmenting standard models for Reynolds-Averaged Navier-Stokes (RANS) simulations using a Non-Linear Super-Stencil (NLSS). The proposed method introduces a fully connected neural network that learns a mapping from the local mean flow field to a corrective force term, which is added to a standard RANS solver in order to align its solution with high-fidelity data. A procedure is devised to extract training data from reference DNS and large eddy simulations (LES). To reduce the complexity of the non-linear mapping, the dimensionless local flow data is aligned with the local mean velocity, and the local support domain is scaled by the turbulent integral length scale. After being trained on a single periodic hill case, the NLSS-corrected RANS solver is shown to generalize to different periodic hill geometries and different Reynolds numbers, producing significantly more accurate solutions than the uncorrected RANS simulations.


---
# An Interpretable Approach to Load Profile Forecasting in Power Grids using Galerkin-Approximated Koopman Pseudospectra

## 使用Galerkin近似的Koopman伪谱预测电网负荷分布的可解释方法

Link: https://arxiv.org/abs/2304.07832

arXiv:2304.07832v2 Announce Type: replace-cross 
Abstract: This paper presents an interpretable machine learning approach that characterizes load dynamics within an operator-theoretic framework for electricity load forecasting in power grids. We represent the dynamics of load data using the Koopman operator, which provides a linear, infinite-dimensional representation of the nonlinear dynamics, and approximate a finite version that remains robust against spectral pollutions due to truncation. By computing $\epsilon$-approximate Koopman eigenfunctions using dynamics-adapted kernels in delay coordinates, we decompose the load dynamics into coherent spatiotemporal patterns that evolve quasi-independently. Our approach captures temporal coherent patterns due to seasonal changes and finer time scales, such as time of day and day of the week. This method allows for a more nuanced understanding of the complex interactions within power grids and their response to various exogenous factors. We assess our method using a large-scale dataset from a renewable power system in the continental European electricity system. The results indicate that our Koopman-based method surpasses a separately optimized deep learning (LSTM) architecture in both accuracy and computational efficiency, while providing deeper insights into the underlying dynamics of the power grid\footnote{The code is available at \href{https://github.com/Shakeri-Lab/Power-Grids}{github.com/Shakeri-Lab/Power-Grids}.


---
# Finite-difference-informed graph network for solving steady-state incompressible flows on block-structured grids

## 用于在块结构网格上求解稳态不可压缩流的有限差分通知图网络

Link: https://arxiv.org/abs/2406.10534

arXiv:2406.10534v3 Announce Type: replace-cross 
Abstract: Advances in deep learning have enabled physics-informed neural networks to solve partial differential equations. Numerical differentiation using the finite-difference (FD) method is efficient in physics-constrained designs, even in parameterized settings. In traditional computational fluid dynamics(CFD), body-fitted block-structured grids are often employed for complex flow cases when obtaining FD solutions. However, convolution operators in convolutional neural networks for FD are typically limited to single-block grids. To address this issue, \blueText{graphs and graph networks are used} to learn flow representations across multi-block-structured grids. \blueText{A graph convolution-based FD method (GC-FDM) is proposed} to train graph networks in a label-free physics-constrained manner, enabling differentiable FD operations on unstructured graph outputs. To demonstrate model performance from single- to multi-block-structured grids, \blueText{the parameterized steady incompressible Navier-Stokes equations are solved} for a lid-driven cavity flow and the flows around single and double circular cylinder configurations. When compared to a CFD solver under various boundary conditions, the proposed method achieves a relative error in velocity field predictions on the order of $10^{-3}$. Furthermore, the proposed method reduces training costs by approximately 20\% compared to a physics-informed neural network. \blueText{To} further verify the effectiveness of GC-FDM in multi-block processing, \blueText{a 30P30N airfoil geometry is considered} and the \blueText{predicted} results are reasonable compared with those given by CFD. \blueText{Finally, the applicability of GC-FDM to three-dimensional (3D) case is tested using a 3D cavity geometry.


---
# Quantum Algorithm for a Stochastic Multicloud Model

## 随机多云模型的量子算法

Link: https://arxiv.org/abs/2406.11350

arXiv:2406.11350v2 Announce Type: replace-cross 
Abstract: Quantum computers have attracted much attention in recent years. This is because the development of the actual quantum machine is accelerating. Research on how to use quantum computers is active in the fields such as quantum chemistry and machine learning, where vast amounts of computation are required. However, in weather and climate simulations, less research has been done despite similar computational demands. In this study, a quantum computing algorithm is applied to a problem of the atmospheric science. The effectiveness of the proposed algorithm is evaluated using a quantum simulator. The results show that it can achieve the same simulations as a conventional algorithm designed for classical computers. More specifically, the stochastically fluctuating behavior of a multi-cloud model was obtained using classical Monte Carlo method, and comparable results are also achieved by utilizing probabilistic outputs of computed quantum states. Our results show that quantum computers have a potential to be useful for the atmospheric and oceanic science, in which stochasticity is widely inherent.


---
# Multi-modal graph neural networks for localized off-grid weather forecasting

## 多模态图神经网络在局部离网天气预报中的应用

Link: https://arxiv.org/abs/2410.12938

arXiv:2410.12938v2 Announce Type: replace-cross 
Abstract: Urgent applications like wildfire management and renewable energy generation require precise, localized weather forecasts near the Earth's surface. However, weather forecast products from machine learning or numerical weather models are currently generated on a global regular grid, on which a naive interpolation cannot accurately reflect fine-grained weather patterns close to the ground. In this work, we train a heterogeneous graph neural network (GNN) end-to-end to downscale gridded forecasts to off-grid locations of interest. This multi-modal GNN takes advantage of local historical weather observations (e.g., wind, temperature) to correct the gridded weather forecast at different lead times towards locally accurate forecasts. Each data modality is modeled as a different type of node in the graph. Using message passing, the node at the prediction location aggregates information from its heterogeneous neighbor nodes. Experiments using weather stations across the Northeastern United States show that our model outperforms a range of data-driven and non-data-driven off-grid forecasting methods. Our approach demonstrates how the gap between global large-scale weather models and locally accurate predictions can be bridged to inform localized decision-making.


---
# Beyond DNA: ML-Empowered Nanopore Base-Calling of 12-Letter Genetic Alphabets

## 超越DNA: ML授权的纳米孔碱基调用12个字母的遗传字母

Link: https://dx.doi.org/10.26434/chemrxiv-2024-xv61j?rft_dat=source%3Ddrss

The standard 4-letter genetic code (A, T, G, C) is the blueprint of life on earth. However, beyond this foundational framework lies a realm of artificial genetics, which has now expanded the genetic code up to 12-letter (A, T, G, C, B, S, P, Z, X, K, J, V). Strikingly, at a time when detection methods for genomics and transcriptomics have progressed to their “fourth generation” with successful commercialization, the field of artificial genetics is still in its nascent stage, the “zeroth generation”. Herein, in the framework of DFT and machine learning (ML), we report a next-generation solid-state nanopore sequencing to both assess and decode the DNA code with expanded alphabets. For assessing, we leverage the ML regression tools, which predict the transmission signatures of each natural and xenonucleobase with low mean squared error as validated through DFT. Parameterizing SMILES (simplified molecular input line entry system) strings of expanded alphabets, including isomers, allows the structural, molecular, and bonding configuration of nucleobases to be meticulously incorporated during predictions. Further, custom ML classification tools are developed, and each standard, isoG/isoC, hachimoji, and supernumerary code is decoded with SHAP (Shapley Additive exPlanations) explainability. By introducing ML accelerated nanopore sequencing of supernumerary DNA, we pave the way for rapid analysis of expanded alphabets, offering insights into life’s possibilities across the cosmos.


---
# General Chemically Intuitive Atom- and Bond-level DFT Descriptors for Machine Learning Approaches to Reaction Condition Prediction

## 通用化学直观的原子和键级DFT描述符，用于反应条件预测的机器学习方法

Link: https://dx.doi.org/10.26434/chemrxiv-2024-wbxp6?rft_dat=source%3Ddrss

We demonstrate the usefulness of general atom- and bond-level DFT descriptors to enhance the performance of neural networks for general reaction condition prediction. We treat reaction condition prediction as a multi-class classification task and report the performance of neural networks trained on 59,512 reactions with 283 distinct reaction condition classes and varying input embedding compositions. We show that by combining structural and general DFT descriptors in optimized ratios, models with input size up to 15% smaller than their purely structural counterparts can provide comparable recall, top-1 and top-3 accuracies. Moreover, we report improvements of up to 6%, 7% and 9% in weighted F1 score, top-1 accuracy and weighted recall, respectively, for neural networks trained on combined general DFT and structural descriptors when compared to purely structural models with equivalent architectures and input sizes. Remarkably, these results were achieved using a training set containing 267 times fewer data points than the one used for generating and embedding structural descriptors, despite both embedding strategies being similar unsupervised learning algorithms.


---
# Enhancing Marine Wildlife Observations: The Application of Tethered Balloon Systems and Advanced Imaging Sensors for Sustainable Marine Energy Development

## 加强海洋野生动物观测: 系留气球系统和先进成像传感器在可持续海洋能源开发中的应用

Link: https://www.researchsquare.com/article/rs-5349011/latest

This study investigates the capabilities of a tethered balloon system (TBS) for detecting and monitoring marine wildlife, primarily focusing on gray whales (Eschrichtius robustus) and various avian species. Over 55.7 h of aerial and surface footage were collected, yielding significant findings regarding the detection rates of marine mammals and seabirds. A total of 59 gray whale, 100 avian, and 6 indistinguishable marine mammal targets were identified by the airborne TBS, while surface-based observations recorded 1,409 gray whales, 1,342 avian targets, and several other marine mammals. When the airborne and surface cameras were operating simultaneously, 21% of airborne whale and 34% of airborne avian detections were captured with the airborne TBS camera and undetected with the surface-based camera. The TBS was most effective at altitudes between 50 to 200 m above ground, with variable-pitch scanning patterns providing superior detection of whale blows compared to fixed-pitch and loitering methods. Notably, instances of airborne detections not corroborated by surface observations underscore the benefits of combining aerial monitoring with traditional survey techniques. Additionally, the integration of machine-learning (ML) algorithms into video analysis enhances our capacity for processing large datasets, paving the way for real-time wildlife monitoring. Of the total number of blows detected by an ML algorithm, the percentage of blows identified by a human analyst was greater than that uniquely detected by the algorithm. Notably, more unique detections by the ML algorithm occurred during daylight, suggesting that sun artifacts may hinder human detection performance, thereby highlighting the added value of ML under these conditions. This research lays the groundwork for future studies in marine biodiversity monitoring, emphasizing the importance of innovative aerial surveillance technologies and advanced imaging methodologies in understanding species behavior and informing conservation strategies for sustainable marine energy, offshore wind development, and other marine resource management efforts.


---
# An EfficientNet-global attention mechanism model based on road pavement type identification for vehicles

## 基于车辆路面类型识别的efficientnet-global注意力机制模型

Link: https://www.researchsquare.com/article/rs-5424300/latest

This study presents an enhanced road pavement-type identification method for vehicles to address the challenge posed by the complex texture characteristics of various road surfaces. First, a comprehensive dataset, including seven pavement types, i.e., dry and wet asphalt, immersed asphalt, dry and wet concrete, and icy and snowy roads, was constructed based on the existing open-source road surface classification dataset and road testing experiments. Second, an EfficientNet-GAM model was developed, and a global attention mechanism (GAM) was incorporated to streamline the model&amp;rsquo;s complexity while preserving the global feature representation. Then, label smoothing was applied to the cross-entropy loss function, and a cosine learning rate decay strategy was employed to accelerate model convergence to improve the model&amp;rsquo;s learning of similar pavement information. Finally, the experimental results demonstrate the model&amp;rsquo;s effectiveness in identifying various pavement types with high accuracy (98.11%) and computational efficiency.


---
# Machine learning algorithms prediction of methyl orange removal by Fenton oxidation process

## Fenton氧化去除甲基橙的机器学习算法预测

Link: https://www.researchsquare.com/article/rs-5392978/latest

The Fenton oxidation process (Fe2+/H2O2) was applied formethyl orange (MO) removal under different operating conditions. The treatment efficiency was monitored by Chemical Oxygen Demand (COD) analysis. The Fenton process effectively mitigates the damaging impacts of MO on ecosystems by regulating and reducing dye levels. The aim of this study is the prediction of MO Fenton oxidation using four different models of machine learning: Gaussian Process Regression (GPR), Multilayer Perceptron (MLP), Decision Tree (DT), and Support Vector Machine (SVM). The four models were developed using42 experimental data.Experimental work showed that 99% of the COD was removed. The evaluation of these models' accuracy and predictive capacity for COD removal of MO was made using statistical metrics; correlation coefficient R2 and Residual Root Mean Square Error (RMSE). All the used models gave a strong correlation with R2 greater than 0.91 but Predicting the efficacy of COD removal showedthatthe Gaussian Process Regression model was the most effective with the highest correlation coefficient (R2=0.97). The study of the relative importance of the different input characteristics showed that the reaction time is the most important characteristic. The results of this work could have a major impact on water treatment and therefore, on the possibilities for water reuse, which is crucial, particularly in arid and semi-arid zones.


---
# Short-Term Load Forecasting for Smart Grid based on Bidirectional-LSTM Recurrent Neural Network

## 基于双向LSTM递归神经网络的智能电网短期负荷预测

Link: https://www.researchsquare.com/article/rs-5458984/latest

The traditional power grid is evolving into a smart grid, integrating advanced two-way communication technologies and a greater proportion of renewable energy sources, resulting in a more dynamic and flexible network. Accurate load forecasting is crucial for effective operation, planning, and management of the smart grid. Short-term load forecasting (STLF) is particularly challenging due to the high variability and unpredictability in individual consumer behavior, which can impact forecasting accuracy and complicate daily operations and scheduling. Advanced deep learning techniques offer a promising solution to this problem by improving the accuracy of STLF. In this paper, we introduce an ensemble forecasting framework that combines the convolutional neural network (CNN) with a bidirectional long short-term memory (BiLSTM) recurrent neural network with dynamic weight adjustment (DWA). The CNN layers extract features from the data, the DWA layer multiplies the extracted features by their respective dynamic weights before passing them to the BiLSTM model which enhances the forecasting accuracy by capturing both past and future temporal dependencies. We evaluate this framework using a high-resolution real residential smart meter readings dataset and compare its performance against standalone and hybrid models. Our results demonstrate that the BiLSTM-based framework outperforms LSTM-based and traditional approaches in key metrics, including mean absolute percentage error (MAPE) with an improvement of MAPE by 1.99% against the benchmark CNN-LSTM model. This underscores our model's superior accuracy and reliability for STLF, marking a significant advancement over traditional methods. Our model effectively enhances forecasting accuracy in smart grid applications.


---
# Wearable Sensors and Artificial Intelligence for sleep apnea detection: A Systematic Review

## 用于睡眠呼吸暂停检测的可穿戴传感器和人工智能: 系统综述

Link: https://www.researchsquare.com/article/rs-5431207/latest

Sleep apnea, a prevalent disorder affecting millions of people worldwide, has attracted increasing attention in recent years due to its significant impact on public health and quality of life. The integration of wearable devices and artificial intelligence technologies has revolutionized the treatment and diagnosis of sleep apnea. Leveraging the portability and sensors of wearable devices, coupled with AI algorithms, has enabled real-time monitoring and accurate analysis of sleep patterns, facilitating early detection and personalized interventions for people suffering from sleep apnea. This review of articles presents a systematic review of the current state of the art in identifying the latest artificial intelligence techniques, wearable devices, data types, and preprocessing methods employed in the diagnosis of sleep apnea. Four databases were used and the results before screening report 249 studies published between 2020 and 2024. After screening, 28 studies met the inclusion criteria.  This review reveals a trend in recent years where methodologies involving patches, clocks and rings have been increasingly integrated with convolutional neural networks, producing promising results, particularly when combined with transfer learning techniques. We observed that the outcomes of various algorithms and their combinations also rely on the quantity and type of data utilized for training. The findings suggest that employing multiple combinations of different neural networks with convolutional layers contributes to the development of a more precise system for early diagnosis of sleep apnea.


---
# MBO-DeBERTa : High Performance Fake Review Detection using pretrained DeBERTa Optimized with Monarch Butterfly paradigm

## Mbo-deberta: 使用经过君主蝴蝶范式优化的预训练的DeBERTa进行高性能虚假评论检测

Link: https://www.researchsquare.com/article/rs-5302560/latest

In this era of internet, e-commerce has grown tremendously and the customers are increasingly relying on reviews for product information. As these reviews influence the purchasing ability of the future customer, it can give a positive or negative impact on the businesses. The effectiveness of online reviews is compromised by fake reviews that provide false information about the product. Fake reviews can not only impact the reputation of the businesses but also involve financial losses. Thus, detection of fake reviews is essential to solve the problem for maintaining the integrity of online reviews. Existing Machine learning models often struggle with deep contextual understanding. Scaling machine learning models while maintaining accuracy and efficiency becomes increasingly challenging as the volume of online reviews continues to grow. Hence, this research work introduces a novel MBO-DeBERTa ,a deep neural network with Monarch Butterfly Optimizer. The proposed model improves the capacity to differentiate between overlapping characteristics of fake and authentic reviews. MBO-DeBERTa attained a classification accuracy of 98% for detecting the fake reviews. The proposed framework is tested on three different datasets such as Amazon, Fake Review and Deceptive Opinion Spam containing 21000,40000 and 1600 reviews respectively which are publicly available in Kaggle. The results show that the suggested model outperforms the current models showing increased accuracy, precision, recall, F1 score and reduced loss rate.


---
# Structured pre-briefing: the impact on medical students&rsquo; anxiety and learning experience in simulation

## 结构化预简报: 模拟对医学生焦虑和学习体验的影响

Link: https://www.researchsquare.com/article/rs-5360110/latest

Introduction: The expansion of simulation-based learning in undergraduate education is mounting, an approach that can reduce the anxiety of learners is emphasized. Methods: This study is conducted in the Medical Skills and Simulation Center (MSSC) to identify the effects of using structured pre-briefing (concept mapping) on final-year medical students&amp;rsquo; anxiety levels and the relationship with perception after simulation. Design: Eighty-four fifth-year medical students in Arabian Gulf University on Jan 2021, over three months intervals. Students were divided into two groups: the interventional group of 44 students who received structured pre-briefing, including a concept map, and the control group, which included 40 students that received traditional pre-briefing. At the end of the session, each student completed a sheet of six items: State-Trait Anxiety Inventory (STAI-6) as a tool for measuring anxiety and a questionnaire to evaluate students&amp;rsquo; perception (understanding) of simulation. Linear correlation coefficient was measured between anxiety level and students&amp;rsquo; understanding or perception of experience. Results: Anxiety level measured by the STAI-6 score was higher in the control group than the interventional group of 48.9&amp;thinsp;&amp;plusmn;&amp;thinsp;15.5 versus 34.9&amp;thinsp;&amp;plusmn;&amp;thinsp;11.3, P&amp;thinsp;&amp;lt;&amp;thinsp;0.001. The perception of experience was shown to be greater for the interventional group than for the control group of 46.5&amp;thinsp;&amp;plusmn;&amp;thinsp;6.2 versus 41.7&amp;thinsp;&amp;plusmn;&amp;thinsp;9.7, P,0.001. There was a significant negative correlation between the anxiety level and the students&amp;rsquo; understanding (perception) of the pre-briefing (P&amp;thinsp;=&amp;thinsp;-&amp;thinsp;r: 0.004). The implication of anxiety reduction was clear among medical students using the concept mapping as the awareness and perception of the elements of environments improved significantly. Conclusion: Structured pre-briefing using concept mapping decreases their anxiety level, which leads to improve the understanding and perception during simulated clinical experience.


---
# Accurate POI Recommendation for Random Groups With Improved Graph Neural Networks and Multi-negotiation Model

## 基于改进图神经网络和多协商模型的随机群体POI精确推荐

Link: https://www.researchsquare.com/article/rs-5297395/latest

In recent years, the growing prevalence of group activities has increased interest in Point of Interest (POI) recommendations for groups. While progress has been made in recommending POIs for fixed groups, research on personality-aware recommendations for random groups is relatively scarce. Moreover, existing works always recommend a POI list for the group, and let the group to make further choice to determine the optimal POI, which results in poor experience. To solve the above problems, this work proposes a model for Accurate POI Recommendation for Random Group with improved Graph Neural Networks and Multi-negotiation Model (termed as APRRGM). Specifically, APRRGM first produces the fitted feature of the random group based on members' personalities and members' POI interaction data. Then, &nbsp;APRRGM learns POIs' features from the bipartite graph of user and POI with an improved Graph Neural Networks (GNN) while considering members' personalities. Next, APRRGM recommends a POI sequence based on the fitted feature of the random group and the features of POIs. Finally, based on the recommended POI list and members' personalities, APRRGM determines the optimal POI for the random group with an improved multi-negotiation model. Extensive experiments has been conducted on three public benchmark datasets (Yelp, Gowalla and Foursquare), and experimental results have proved that APRRGM has better performance than that of other baseline models.


---
# FONDUE - Fine-tuned Optimization: Nurturing Data Usability &amp;amp; Efficiency

## 火锅-微调优化: 培养数据可用性和效率

Link: https://www.researchsquare.com/article/rs-5182530/latest

To provide good results and decisions in data-driven systems, data quality must be ensured as a primary consideration. An important aspect of this is data cleaning. Although many different algorithms and tools already exist for data cleaning, an end-to-end data quality solution is still needed. In this paper, we present FONDUE, our vision of a well-founded end-to-end data quality optimizer. In contrast to many studies that consider data cleaning in the context of machine learning, our approach focuses on various scenarios, such as when preprocessing and downstream analysis are separated. As an adaptive and easily extendable framework, FONDUE operates similarly to proven methods of database query optimization. Analogously, it consists of the following parts: Rule-based optimization, where the appropriate data cleaning algorithms are selected based on use case constraints, optimizer hints in the form of best practices, and cost-based optimization, where the costs are measured in terms of data quality. Accordingly, the result is an optimized data cleaning pipeline. The choice of different optimization goals enables further flexibility, e.g. for environments with limited resources. As a first building block of FONDUE, we present CheDDaR, which is used to detect errors and measure data quality. Both are important tasks for improving data quality with FONDUE.


---
# Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with Variational Quantum Circuits

## 利用预训练的神经网络通过变分量子电路增强机器学习

Link: https://www.researchsquare.com/article/rs-5442273/latest

Quantum Machine Learning (QML) offers tremendous potential but is currently limited by the availability of qubits. We introduce an innovative approach that utilizes pre-trained neural networks to enhance Variational Quantum Circuits (VQC). This technique effectively separates approximation error from qubit count and removes the need for restrictive conditions, making QML more viable for real-world applications. Our method significantly improves parameter optimization for VQC while delivering notable gains in representation and generalization capabilities, as evidenced by rigorous theoretical analysis and extensive empirical testing on quantum dot classification tasks. Moreover, our results extend to applications such as human genome analysis, demonstrating the broad applicability of our approach. By addressing the constraints of current quantum hardware, our work paves the way for a new era of advanced QML applications, unlocking the full potential of quantum computing in fields such as machine learning, materials science, medicine, mimetics, and various interdisciplinary areas.


---
# SemiHMER: Semi-supervised HandwrittenMathematical Expression Recognition using pseudo-labels

## SemiHMER: 使用伪标签的半监督手写数学表达式识别

Link: https://www.researchsquare.com/article/rs-5452866/latest

In recent years, deep learning with Convolutional Neural Networks (CNNs) has achieved remarkable results in Handwritten Mathematical Expression Recognition(HMER). However, improving the performance with limited labeled training data remains challenging. This paper presents, for the first time, a simple yet effective semi-supervised HMER framework by introducing dual-branch semi-supervised learning. Specifically, we simplify the conventional deep co-training from consistency regularization to cross-supervised learning, where the prediction of one branch is used as a pseudo-label to supervise the other branch directly end-to-end. Considering that the learning of the two branches tends to converge in the later stages of model optimization, we also incorporate a weak-to-strong strategy by applying different levels of augmentation to each branch, which expands the training data and improves the quality of network training. Meanwhile, We propose a novel module, called Global Dynamic Counting Module(GDCM), to enhance the performance of the HMER decoder, which alleviates recognition inaccuracies in long-distance formula recognition and the occurrence of repeated characters. We will release our code at https://github.com/chenkehua/SemiHMER.


---
# Optimizing Performance, Combustion and Emission characteristics of Mahua Biodiesel included GO and ZnO Nanoparticles: An ANN-RSM Approach

## 优化包含GO和ZnO纳米颗粒的Mahua生物柴油的性能，燃烧和排放特性: ANN-RSM方法

Link: https://www.researchsquare.com/article/rs-5442487/latest

The present study focuses on the use of artificial neural networks (ANNs) and response surface methodology (RSM) with GO and ZnO nanoparticles placed in Mahua oil biodiesel blend (B20) are utilized to fuel direct injection diesel engines. These approaches are used to forecast the engine's operating characteristics. At a concentration of 75 ppm, GO and ZnO nanoparticles were taken into consideration. Additionally, a dispersant (TWEEN 80) and surfactant (CTAB) were mixed respectively at a ratio of 1:1. Using a spectrophotometer, stability analysis was carried out on a variety of nanofuel samples, and a study based on experiments was done on a diesel engine. The output factors that were examined at were BSFC, BTE, NHRR, CP, UHC, CO, NOx, and smoke visibility. These metrics were based on combustion, emissions and performance. Input parameters such as gasoline samples, injection pressure, and engine load were considered. The injection pressures were 200, 225, and 250 bars, whereas the loads were considered to be 5%, 50%, 75%, and 100%, respectively. When compared to other samples, the dispersion ZnO and GO nanoparticles in B20 shown amazing performance. The B20&amp;thinsp;+&amp;thinsp;GO 75 ppm&amp;thinsp;+&amp;thinsp;TWEEN 80 75 ppm combination has shown a 5.293% decrease in BSFC and a 5.067% improvement in BTE at 250 bars. Furthermore, 3.13% and 43.50% improvements were made to combustion parameters including CP and NHRR, respectively. Smoke opacity, CO, UHC, and NOx were all reduced by around 38.55%, 11.07%, 37.63%, and 27.77%, respectively. Finally, the correlation coefficient (R2) for all parameters ranged from 0.93 to 0.99 using ANNs and RSM predictions.


---
# Deep Learning for Motion Classification in Ankle Exoskeletons Using Surface EMG and IMU Signals

## 基于表面肌电图和IMU信号的踝关节外骨骼运动分类深度学习

Link: https://www.researchsquare.com/article/rs-5446652/latest

Ankle exoskeletons have garnered considerable interest for their potential to enhance mobility and reduce fall risks, particularly among the aging population. The efficacy of these devices relies on accurate real-time prediction of the user&rsquo;s intended movements through sensor-based inputs. This paper presents a novel motion prediction framework that integrates three Inertial Measurement Units (IMUs) and eight surface Electromyography (sEMG) sensors to capture both kinematic and muscular activity data. A comprehensive set of activities, representative of everyday movements in barrier-free environments, was recorded for the purpose. Our findings reveal that Convolutional Neural Networks (CNNs) slightly outperform Long Short-Term Memory (LSTM) networks on a dataset of five motion tasks, achieving classification accuracies of 96.5&deg;&aelig;0.8% and 87.5&deg;&aelig;2.9%, respectively. Furthermore, we demonstrate the system&rsquo;s proficiency in transfer learning, enabling accurate motion classification for new subjects using just ten samples per class for finetuning. The robustness of the model is demonstrated by its resilience to sensor failures resulting in absent signals, maintaining reliable performance in real-world scenarios. These results underscore the potential of deep learning algorithms to enhance the functionality and safety of ankle exoskeletons, ultimately improving their usability in daily life.


---
# From mesh to neural nets: A multi-method evaluation of physics informed neural network and galerkin finite element method for solving nonlinear convection-reaction-diffusion equations

## 从网格到神经网络: 求解非线性对流反应扩散方程的物理信息神经网络和galerkin有限元方法的多方法评估

Link: https://www.researchsquare.com/article/rs-5447948/latest

Non-linear convection-reaction-diffusion (CRD) partial differential equations (PDEs) are crucial for modeling complex phenomena in fields such as biology, ecology, population dynamics, physics, and engineering. Numerical approximation of these non-linear systems is essential due to the challenges of obtaining exact solutions. Traditionally, the Galerkin finite element method (GFEM) has been the standard computational tool for solving these PDEs. With the advancements in machine learning, Physics-Informed Neural Network (PINN) has emerged as a promising alternative for approximating non-linear PDEs.In this study, we compare the performance of PINN and GFEM by solving four distinct one-dimensional CRD problems with varying initial and boundary conditions and evaluate the performance of PINN over GFEM. This evaluation metrics includes error estimates, and visual representations of the solutions, supported by statistical methods such as the root mean squared error (RMSE), the standard deviation of error, the the Wilcoxon Signed-Rank Test and the coefficient of variation (CV) test.Our findings reveal that while both methods achieve solutions close to the analytical results, PINN demonstrate superior accuracy and efficiency. PINN achieved significantly lower RMSE values and smaller standard deviations for Burgers' equation, Fisher's equation, and Newell-Whitehead-Segel equation, indicating higher accuracy and greater consistency. While GFEM shows slightly better accuracy for the Burgers-Huxley equation, its performance was less consistent over time. In contrast, PINN exhibit more reliable and robust performance, highlighting their potential as a cutting-edge approach for solving non-linear PDEs.


---
# Digital Monitoring of Tai Chi Balance Training in Older Adults Using Wearable Sensors and Machine Learning

## 使用可穿戴传感器和机器学习的老年人太极拳平衡训练的数字监测

Link: https://www.researchsquare.com/article/rs-5389927/latest

Tai Chi, an Asian martial art, is renowned for its health benefits, particularly in promoting healthy aging among older adults, improving balance, and reducing fall risk. However, methodological challenges hinder the objective measurement of adherence to and proficiency in performing a training protocol, critical for health outcomes. This study introduces a framework using wearable sensors and machine learning to monitor Tai Chi training adherence and proficiency. Data were collected from 32 participants with inertial measurement units (IMUs) while performing six Tai Chi movements evaluated and scored for adherence and proficiency by experts.
Our framework comprises a model for identifying the specific Tai Chi movement being performed and a model to assess performance proficiency, both employing Random Forest algorithms and features from IMU signals. The movement identification model achieved high accuracy (micro F1: 90.05%). Proficiency assessment models also achieved high accuracy (mean micro F1: 78.64%).
This study shows the feasibility of using IMUs and machine learning for detailed Tai Chi movement analysis, offering a scalable method for monitoring practice. This approach has the potential to objectively enhance the evaluation of Tai Chi training protocol adherence, learnability, progression in proficiency, and safety in Tai Chi programs, and thus inform training program parameters that are key to achieving optimal clinical outcomes.


---
# Deep Learning with Multiple Faces to Improve Intrusion Detection in Adaptive Internet of Things Networks Optimization

## 多人脸深度学习在自适应物联网网络优化入侵检测中的应用

Link: https://www.researchsquare.com/article/rs-5434635/latest

IoT net security can be improved, and cyber threats may be reduced by using Deep Learning (DL) techniques, which offer a potential method for effectively detecting defects in network data. In this paper, DL techniques are utilized to build an improved IDS in IoT platform. Initially, a pre-processing phase is employed to handle the missing values and to identify anomalous data points via MissForest and Local Outlier Factor (LOF). Besides, a ResNet-50 approach is employed to extract specific and statistical features in the IoT data. Once feature extraction is done, feature selection is carried out using Improved Mutual Information (MI) method. Then, the dimensionality issues are reduced by Locally Linear Embedding (LLE) and an AdaptNet is introduced for detecting IoT attack using the combination of Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), and Auto-Encoder (AE). By leveraging advanced DL techniques and methodologies across different stages of IDS, the expected outcome is a robust and efficient tool capable of effectively safeguarding IoT networks. Use, AVOA and ARO optimization for fine-tuning pre-trained models on large datasets. Python tool is used for implementing the proposed work and the accuracy range is 99.2%.


---
# Synergizing CNNs and Transformers for Accurate Face Age Estimation

## 协同cnn和Transformers进行准确的人脸年龄估计

Link: https://www.researchsquare.com/article/rs-5427570/latest

Estimating the actual and perceived age of human faces has garnered significant interest for its wide-ranging practical applications. Various intelligent scenarios stand to gain from these computational systems capable of accurately predicting individuals&rsquo; ages. Automated age estimation systems are particularly valuable in fields such as medical diagnostics, facial product development, casting for films, assessing the impact of cosmetic procedures, and anti-aging treatments. In the realm where deep networks have demonstrated their supremacy as the fron-trunners among machine learning tools, Our approach integrates Convolutional Neural Networks (CNN) with Transformers. This novel system enhances information extraction by utilizing transformer attention mechanisms, rather than solely depending on features extracted from convolutional neural networks for estimating age. Based on the experiments conducted, the system effectively captures the sequential progression and continuous nature of the aging process. Furthermore, the proposed model surpasses the cutting-edge model by delivering exceptional results, achieving the lowest mean absolute errors of 2.31 for MORPH II, 5.35 for CACD, and 2.91 for AFAD.


---
# Simulated learning interventions to improve communication and practice with deaf and hard of hearing patients: a systematic review and qualitative synthesis

## 模拟学习干预，以改善与聋人和听力障碍患者的沟通和实践: 系统回顾和定性综合

Link: https://www.researchsquare.com/article/rs-5366413/latest

Virtual and simulated patients are increasingly used in health professional education as learning about patient needs in a safe space greatly benefits student knowledge and skills and increases their empathy towards patients. Yet to date there has been limited focus on using simulated learning techniques in health professional education to promote learning about D/deaf and hard of hearing patients. We used systematic review methodology to search, identify, appraise and abstract relevant articles across CINAHL, MEDLINE, ASSIA and Proquest Central, Scopus, Web of Science and Cochrane databases yielding a total of 1112 papers. After removing duplicates, inclusion criteria were defined and applied, resulting in 132 articles retrieved for full-text review. Six articles met all inclusion criteria, addressing simulated learning methods for health professional students that provide educational opportunities about Deaf patient experiences. Findings suggest that a myriad of possible simulation modalities can be developed that include opportunities to learn about the D/deaf patient experience and to consider learning about communication and application of knowledge to a specific topic environment. This qualitative synthesis provides insight into potential methods and styles of delivery, whilst noting a very small number of studies in this area. Future research should focus on rigorous and longitudinal studies to understand more about student learning and how interventions impact on their communication and encounters with D/deaf patients.


---
# Deep Learning-Based Reconstruction for Three-Dimensional Volumetric Brain MRI: A Qualitative and Quantitative Assessment

## 基于深度学习的三维体积脑MRI重建: 定性和定量评估

Link: https://www.researchsquare.com/article/rs-5345149/latest

Background:To evaluate the performance of a deep learning reconstruction (DLR) based on Adaptive-Compressed sensing (CS)-Network for brain MRI and validate it in a clinical setting
Methods: Ten healthy volunteers and 22 consecutive patients were prospectively enrolled. Volunteers underwent 3D brain MRI including T1 without CS factor (9:16min, reference standard); with CS factor of 2 without DLR (CS2, 4:6min); with CS factor of 2 with DLR (DLR-CS2); with CS factor of 4 without DLR (CS4, 2:6min); and with CS factor of 4 with DLR (DLR-CS4). The patients&rsquo; MRI included the CS2 and DLR-CS4. The volumes of lateral ventricles, hippocampus, choroid plexus, and white matter hypointensity were calculated and compared among the sequences. Three radiologists independently assessed anatomical conspicuity, overall image quality, artifacts, signal-to-noise ratio (SNR), and sharpness using a 5-point scale for each sequence.
Results: Applying acceleration factors of 2 and 4 reduced the scan time to 65.4% and 33.5%, respectively, of that of the reference standard. Volumes of all the measured subregions showed no significant differences among different sequences in all participants. In qualitative analysis, the interrater agreement was excellent (&kappa;=0.844&ndash;0.926). In volunteers, quality of DLR-CS4 were comparable to those of CS2 for all metrics except for the overall image quality and SNR despite a 51.2% scan time reduction. In patients, DLR-CS4 showed quality comparable to that of CS2 for all metrics.
Conclusions:DLR allowedthe scan time reduction by at least half without sacrificing image quality and volumetric quantification accuracy, supporting its reliability and efficiency.


---
# Transoral Endoscopic Thyroidectomy Vestibular Approach:Analysis of the Learning Curve and Clinical Outcomes Evaluation

## 经口内镜甲状腺切除术前庭入路: 学习曲线分析和临床疗效评价

Link: https://www.researchsquare.com/article/rs-5246107/latest

Transoral endoscopic thyroidectomy vestibular approach (TOETVA) has the advantage of completely scarless on the body surface. Currently, there is still a lack of single-center large sample size analysis on the learning curve of TOETVA, especially for the treatment of thyroid cancer. This study from Zhengzhou University's First Affiliated Hospital analyzed 195 cases of TOETVA from June 2020 to June 2023 to assess the learning curve for this scarless thyroid surgery technique, particularly in thyroid cancer treatment. Using the CUSUM method, two learning phases were identified: exploration (58 cases) and maturation (137 cases). Results showed that the maturation phase had significantly shorter operation times, less bleeding, and fewer complications compared to the exploration phase. The study concludes that TOETVA is safe and feasible, capable of successfully completing complex cases after mastering the learning curve.

